{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a9c0cc-d87c-4f06-8929-ad2fd9918135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA drivers not available. GPU monitoring disabled.\n",
      "[JUmPER]: Perfmonitor extension loaded.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext jumper_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580d265b-156b-4b2d-8487-b020b30b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b68959-9b90-4c6a-b603-5be264bd145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JUmPER]: Performance monitoring started (PID: 989973, Interval: 1.0s)\n",
      "[JUmPER]: Measurements might not meet the desired interval time. Some measurements took longer.\r"
     ]
    }
   ],
   "source": [
    "%perfmonitor_start 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc491424-bb05-4813-8369-85e31ba01f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JUmPER]: Performance reports enabled for each cell (level: process)\n"
     ]
    }
   ],
   "source": [
    "%perfmonitor_enable_perfreports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a13dc3e-8584-4b81-87c6-193046abc9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JUmPER]:\n",
      "  CPUs: 8\n",
      "    CPU affinity: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "  Memory: 23.13 GB\n",
      "  GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "%perfmonitor_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2863575-0b3f-4dca-b4ec-2594b5e4e276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JUmPER]: No non-short cells found\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import math\n",
    "\n",
    "def throw_dart(iterations: int) -> int:\n",
    "    hits = 0\n",
    "    for i in range(iterations):\n",
    "        x = random()\n",
    "        y = random()\n",
    "        if (x * x) + (y * y) <= 1:\n",
    "            hits = hits + 1\n",
    "    return hits\n",
    "\n",
    "\n",
    "def compute_pi(iterations, process_count):\n",
    "    pool = Pool(processes=process_count)\n",
    "    trials_per_process = [int(iterations / process_count)] * process_count\n",
    "\n",
    "    hits = pool.map(throw_dart, trials_per_process)\n",
    "    pi = (sum(hits) * 4) / iterations\n",
    "\n",
    "    print(f\"Pi approximation: {pi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33df7e5c-e0f5-491f-8de1-5db46580db77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi approximation: 3.14149872\n",
      "----------------------------------------\n",
      "JUmPER Performance Report\n",
      "----------------------------------------\n",
      "Duration: 5.92s (1 cell)\n",
      "----------------------------------------\n",
      "Metric                    AVG      MIN      MAX      TOTAL   \n",
      "-----------------------------------------------------------------\n",
      "CPU Util (Across 8 CPUs)  62.64    0.00     98.31    -       \n",
      "Memory (GB)               0.04     0.02     0.05     23.13   \n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Utilizing all CPUs for 10**8 iterations\n",
    "compute_pi(10**8, multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182ea8d6-3ce3-4842-8e18-f7a98d38f144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807c7f34a7924ee096eee900a133dc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Plot Configuration:</b>'), Checkbox(value=False, description='Sho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%perfmonitor_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f1516fc-fdf9-4e0a-af20-4c646e586815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi approximation: 3.14158288\n",
      "----------------------------------------\n",
      "JUmPER Performance Report\n",
      "----------------------------------------\n",
      "Duration: 8.01s (1 cell)\n",
      "----------------------------------------\n",
      "Metric                    AVG      MIN      MAX      TOTAL   \n",
      "-----------------------------------------------------------------\n",
      "CPU Util (Across 8 CPUs)  47.60    37.46    50.68    -       \n",
      "Memory (GB)               0.05     0.05     0.05     23.13   \n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utilizing half of the CPUs for 10**8 iterations\n",
    "compute_pi(10**8, multiprocessing.cpu_count()//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624071aa-4b66-4ed7-b32c-98a3e807877f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df522c0deb7749de8333605ccee1dd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Plot Configuration:</b>'), Checkbox(value=False, description='Sho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%perfmonitor_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef992378-ddf5-43df-8d45-28c1d569cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling 2.5GB of main memory...\n",
      "Allocating 335544320 float64 elements (~2.50 GB)\n",
      "Created array 1\n",
      "Created array 2\n",
      "Created array 3\n",
      "Created array 4\n",
      "Created array 5\n",
      "Created array 6\n",
      "Created array 7\n",
      "Created array 8\n",
      "Created array 9\n",
      "Created array 10\n",
      "2.5GB memory allocation completed\n",
      "----------------------------------------\n",
      "JUmPER Performance Report\n",
      "----------------------------------------\n",
      "Duration: 2.57s (1 cell)\n",
      "----------------------------------------\n",
      "Metric                    AVG      MIN      MAX      TOTAL   \n",
      "-----------------------------------------------------------------\n",
      "CPU Util (Across 8 CPUs)  12.49    12.49    12.49    -       \n",
      "Memory (GB)               2.31     2.07     2.55     23.13   \n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Filling 2.5Gb of main memory\n",
    "def fill_memory_2_5gb():\n",
    "    \"\"\"Fill 2.5GB of main memory\"\"\"\n",
    "    print(\"Filling 2.5GB of main memory...\")\n",
    "    \n",
    "    # Calculate number of elements for 2.5GB (assuming float64 = 8 bytes each)\n",
    "    gb_size = 2.5 * 1024 * 1024 * 1024  # 2.5 GB in bytes\n",
    "    num_elements = int(gb_size / 8)  # 8 bytes per float64 element\n",
    "    \n",
    "    print(f\"Allocating {num_elements} float64 elements (~{2.5:.2f} GB)\")\n",
    "    \n",
    "    # Create large arrays\n",
    "    arrays = []\n",
    "    try:\n",
    "        # Create multiple arrays to avoid memory fragmentation issues\n",
    "        for i in range(10):\n",
    "            arr = np.ones(num_elements // 10, dtype=np.float64)\n",
    "            arrays.append(arr)\n",
    "            print(f\"Created array {i+1}\")\n",
    "        \n",
    "        # Force garbage collection to ensure memory is allocated\n",
    "        gc.collect()\n",
    "        \n",
    "        print(\"2.5GB memory allocation completed\")\n",
    "        return arrays\n",
    "        \n",
    "    except MemoryError:\n",
    "        print(\"Memory allocation failed!\")\n",
    "        return []\n",
    "\n",
    "# Fill memory\n",
    "allocated_arrays = fill_memory_2_5gb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761d93ce-6241-4489-b518-4b0da412ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbc6222c4d348148bae1fd969e716a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Plot Configuration:</b>'), Checkbox(value=False, description='Sho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%perfmonitor_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df2a9816-b3f0-47b5-8098-521f36c5fa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1GB write operation...\n",
      "Writing: 1.00 GB (1024 chunks), Speed: 55.44 MB/s\n",
      "Written 1.00 GB to disk\n",
      "Forcing OS to flush all buffers...\n",
      "Waiting 10 seconds...\n",
      "Reading 1GB data back (forced cache bypass)...\n",
      "Reading: 1.00 GB (1024 chunks), Speed: 80.61 MB/s\n",
      "Read 1.00 GB from disk\n",
      "Forcing OS to flush after reading...\n",
      "1GB forced write/read operation completed\n",
      "----------------------------------------\n",
      "JUmPER Performance Report\n",
      "----------------------------------------\n",
      "Duration: 41.21s (1 cell)\n",
      "----------------------------------------\n",
      "Metric                    AVG      MIN      MAX      TOTAL   \n",
      "-----------------------------------------------------------------\n",
      "CPU Util (Across 8 CPUs)  2.77     0.00     12.49    -       \n",
      "Memory (GB)               2.64     2.64     2.64     23.13   \n"
     ]
    }
   ],
   "source": [
    "# Write 1GB to disk in 10 seconds, force flush, wait 10sec, read back in 10 seconds\n",
    "def write_and_read_1gb_forced():\n",
    "    filename = \"large_data_forced.bin\"\n",
    "    data_size = 1024 * 1024 * 1024  # 1GB in bytes\n",
    "    chunk_size = 1024 * 1024  # 1MB chunks\n",
    "    \n",
    "    print(\"Starting 1GB write operation...\")\n",
    "    \n",
    "    # Calculate write rate: 1GB in 10 seconds = 100MB/s\n",
    "    target_rate_mb_per_sec = 100  # 100 MB/s\n",
    "    target_time_per_chunk = 1.0 / target_rate_mb_per_sec  # 0.01 seconds per chunk\n",
    "    \n",
    "    start_time = time.time()\n",
    "    written_bytes = 0\n",
    "    chunk_count = 0\n",
    "    \n",
    "    # Write data with forced flushing\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.flush()  # Ensure file is opened properly\n",
    "        \n",
    "        while written_bytes < data_size:\n",
    "            # Create chunk of random data\n",
    "            chunk = os.urandom(chunk_size)\n",
    "            \n",
    "            # Write chunk\n",
    "            f.write(chunk)\n",
    "            written_bytes += len(chunk)\n",
    "            chunk_count += 1\n",
    "            \n",
    "            # Force write to disk immediately\n",
    "            f.flush()\n",
    "            os.fsync(f.fileno())\n",
    "            \n",
    "            # Calculate progress\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time > 0:\n",
    "                current_speed = written_bytes / (1024 * 1024) / elapsed_time  # MB/s\n",
    "                print(f\"Writing: {written_bytes / (1024**3):.2f} GB ({chunk_count} chunks), \"\n",
    "                      f\"Speed: {current_speed:.2f} MB/s\", end='\\r')\n",
    "            \n",
    "            # Sleep to maintain 100MB/s rate (10ms per chunk)\n",
    "            time.sleep(target_time_per_chunk)\n",
    "    \n",
    "    print(f\"\\nWritten {os.path.getsize(filename) / (1024**3):.2f} GB to disk\")\n",
    "    \n",
    "    # Force OS to flush all buffers\n",
    "    print(\"Forcing OS to flush all buffers...\")\n",
    "    os.sync()\n",
    "    \n",
    "    # Wait 10 seconds\n",
    "    print(\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Read data back with forced cache bypass\n",
    "    print(\"Reading 1GB data back (forced cache bypass)...\")\n",
    "    start_time = time.time()\n",
    "    read_bytes = 0\n",
    "    read_chunk_count = 0\n",
    "    \n",
    "    # Method 1: Read with forced cache invalidation using posix_fadvise\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            while read_bytes < data_size:\n",
    "                # Read chunk\n",
    "                chunk = f.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                    \n",
    "                read_bytes += len(chunk)\n",
    "                read_chunk_count += 1\n",
    "                \n",
    "                # Force OS to read from disk, not cache\n",
    "                # This is the closest we can get to bypassing cache\n",
    "                try:\n",
    "                    os.posix_fadvise(f.fileno(), 0, 0, os.POSIX_FADV_DONTNEED)\n",
    "                except:\n",
    "                    # POSIX_FADV_DONTNEED not available on all systems\n",
    "                    pass\n",
    "                \n",
    "                # Calculate progress\n",
    "                elapsed_time = time.time() - start_time\n",
    "                if elapsed_time > 0:\n",
    "                    current_speed = read_bytes / (1024 * 1024) / elapsed_time  # MB/s\n",
    "                    print(f\"Reading: {read_bytes / (1024**3):.2f} GB ({read_chunk_count} chunks), \"\n",
    "                          f\"Speed: {current_speed:.2f} MB/s\", end='\\r')\n",
    "                \n",
    "                # Sleep to maintain 100MB/s rate\n",
    "                time.sleep(target_time_per_chunk)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during read: {e}\")\n",
    "        # Fallback: simple read without cache manipulation\n",
    "        with open(filename, 'rb') as f:\n",
    "            while read_bytes < data_size:\n",
    "                chunk = f.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                read_bytes += len(chunk)\n",
    "                read_chunk_count += 1\n",
    "                \n",
    "                # Calculate progress\n",
    "                elapsed_time = time.time() - start_time\n",
    "                if elapsed_time > 0:\n",
    "                    current_speed = read_bytes / (1024 * 1024) / elapsed_time  # MB/s\n",
    "                    print(f\"Reading: {read_bytes / (1024**3):.2f} GB ({read_chunk_count} chunks), \"\n",
    "                          f\"Speed: {current_speed:.2f} MB/s\", end='\\r')\n",
    "                \n",
    "                # Sleep to maintain 100MB/s rate\n",
    "                time.sleep(target_time_per_chunk)\n",
    "    \n",
    "    print(f\"\\nRead {read_bytes / (1024**3):.2f} GB from disk\")\n",
    "    \n",
    "    # Force OS to flush after reading\n",
    "    print(\"Forcing OS to flush after reading...\")\n",
    "    os.sync()\n",
    "    \n",
    "    # Clean up\n",
    "    os.remove(filename)\n",
    "    print(\"1GB forced write/read operation completed\")\n",
    "\n",
    "# Execute the forced write/read operation\n",
    "write_and_read_1gb_forced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac86273-b2ae-46fe-b2c9-bc004b24a931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4083f23fbf534ef2b09ca94cf9fae5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Plot Configuration:</b>'), Checkbox(value=False, description='Sho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%perfmonitor_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48391835-b0af-4644-b671-e43bde8c8370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch not installed, skipping CUDA operations\n",
      "----------------------------------------\n",
      "JUmPER Performance Report\n",
      "----------------------------------------\n",
      "Duration: 41.21s (1 cell)\n",
      "----------------------------------------\n",
      "Metric                    AVG      MIN      MAX      TOTAL   \n",
      "-----------------------------------------------------------------\n",
      "CPU Util (Across 8 CPUs)  2.77     0.00     12.49    -       \n",
      "Memory (GB)               2.64     2.64     2.64     23.13   \n"
     ]
    }
   ],
   "source": [
    "# Cell 6: CUDA Memory Operations (if CUDA available)\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    def cuda_memory_operations():\n",
    "        \"\"\"Fill 2GB of CUDA memory, wait 10sec, then empty it\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"CUDA not available, skipping CUDA memory operations\")\n",
    "            return\n",
    "            \n",
    "        print(\"CUDA available, performing memory operations...\")\n",
    "        device = torch.device('cuda')\n",
    "        \n",
    "        # Calculate number of elements for 2GB (assuming float32 = 4 bytes each)\n",
    "        gb_size = 2 * 1024 * 1024 * 1024  # 2 GB in bytes\n",
    "        num_elements = int(gb_size / 4)  # 4 bytes per float32 element\n",
    "        \n",
    "        print(f\"Allocating 2GB of CUDA memory ({num_elements} elements)\")\n",
    "        \n",
    "        # Allocate memory on GPU\n",
    "        tensor = torch.randn(num_elements, dtype=torch.float32, device=device)\n",
    "        print(f\"Allocated tensor size: {tensor.numel() * 4 / (1024**3):.2f} GB\")\n",
    "        \n",
    "        # Wait 10 seconds\n",
    "        print(\"Waiting 10 seconds...\")\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # Free memory\n",
    "        del tensor\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA memory freed\")\n",
    "        \n",
    "        print(\"CUDA memory operations completed\")\n",
    "    \n",
    "    # Execute CUDA memory operations\n",
    "    cuda_memory_operations()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed, skipping CUDA operations\")\n",
    "except Exception as e:\n",
    "    print(f\"CUDA operation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d8c129-431a-4ba7-8b60-5121888163ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b542dc0b9a471383124432e7bc0851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Plot Configuration:</b>'), Checkbox(value=False, description='Sho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%perfmonitor_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1859968d-24d6-44a8-9c40-ed5f13279992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch not installed, skipping CUDA heavy computation\n",
      "----------------------------------------\n",
      "JUmPER Performance Report\n",
      "----------------------------------------\n",
      "Duration: 41.21s (1 cell)\n",
      "----------------------------------------\n",
      "Metric                    AVG      MIN      MAX      TOTAL   \n",
      "-----------------------------------------------------------------\n",
      "CPU Util (Across 8 CPUs)  2.77     0.00     12.49    -       \n",
      "Memory (GB)               2.64     2.64     2.64     23.13   \n"
     ]
    }
   ],
   "source": [
    "# Cell 7: CUDA Heavy Computation (if CUDA available)\n",
    "try:\n",
    "    import torch\n",
    "    \n",
    "    def cuda_heavy_computation():\n",
    "        \"\"\"Perform heavy computation on CUDA device for 20 seconds\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"CUDA not available, skipping CUDA heavy computation\")\n",
    "            return\n",
    "            \n",
    "        print(\"CUDA available, performing heavy computation...\")\n",
    "        device = torch.device('cuda')\n",
    "        \n",
    "        # Create large tensors for computation\n",
    "        size = 10000  # Size of square matrices\n",
    "        iterations = 0\n",
    "        \n",
    "        print(f\"Starting heavy computation on CUDA for 20 seconds...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Continue computation until 20 seconds have passed\n",
    "        while time.time() - start_time < 20:\n",
    "            # Create random matrices\n",
    "            a = torch.randn(size, size, dtype=torch.float32, device=device)\n",
    "            b = torch.randn(size, size, dtype=torch.float32, device=device)\n",
    "            \n",
    "            # Matrix multiplication (heavy operation)\n",
    "            c = torch.matmul(a, b)\n",
    "            \n",
    "            # Additional computation to increase workload\n",
    "            d = torch.sin(c) + torch.cos(c)\n",
    "            \n",
    "            # More operations to keep GPU busy\n",
    "            e = torch.exp(d) * torch.log(d + 1e-8)\n",
    "            \n",
    "            # Increase iteration count\n",
    "            iterations += 1\n",
    "            \n",
    "            # Clear cache periodically to prevent memory issues\n",
    "            if iterations % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"Heavy computation completed in 20 seconds with {iterations} iterations\")\n",
    "        print(\"CUDA heavy computation completed\")\n",
    "    \n",
    "    # Execute CUDA heavy computation\n",
    "    cuda_heavy_computation()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed, skipping CUDA heavy computation\")\n",
    "except Exception as e:\n",
    "    print(f\"CUDA heavy computation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc5e9aa5-76f0-43de-8fd2-ef7c365b864a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d623e31dab849c8a6a4a5f250f1a487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Plot Configuration:</b>'), Checkbox(value=False, description='Sho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%perfmonitor_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75deb032-e362-4ca7-af64-1b62ff68c5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my kernel",
   "language": "python",
   "name": "my-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
