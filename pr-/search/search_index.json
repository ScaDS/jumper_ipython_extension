{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"JUmPER IPython Extension","text":"<p>Welcome to the documentation for the JUmPER IPython extension, a tool for monitoring the performance of code cells in IPython and Jupyter notebooks.</p> <p>JUmPER lets you:</p> <ul> <li>Collect CPU, memory, GPU, and I/O metrics for individual cells.</li> <li>View textual performance reports for entire sessions or selected cell ranges.</li> <li>Explore interactive plots of collected metrics over time.</li> <li>Export performance data and cell history for offline analysis.</li> </ul> <p>To get started quickly, follow the steps in the Installation and Quickstart guides. For detailed command descriptions and programmatic usage, refer to the Public API section.</p>"},{"location":"api/","title":"Overview","text":"<p>The JUmPER IPython extension exposes a layered public API that lets you work with performance monitoring at different levels:</p> <ul> <li>The Jupyter API provides IPython line magics for interactive use in notebooks and shells.</li> <li>The Python API exposes a programmatic interface centered around <code>PerfmonitorService</code> for use in scripts and libraries.</li> <li>The String Based API offers a thin adapter between textual magic commands and the Python service. It is also used by the script writer when generating reproducible monitoring scripts.</li> </ul> <p>The following subsections describe each of these layers and how they relate to each other.</p> <p>For architectural context and component diagrams, see the Architecture page in the Internals section.</p>"},{"location":"api/jupyter/","title":"Jupyter API","text":"<p>The Jupyter\u2011level API is built around IPython line magics that wrap the underlying Python service. These magics are registered when you load the extension and are implemented by <code>PerfmonitorMagics</code> in combination with <code>PerfmonitorMagicAdapter</code>.</p>"},{"location":"api/jupyter/#loading-the-extension","title":"Loading the extension","text":"<p>Enable the extension once per IPython or Jupyter session:</p> <pre><code>%load_ext jumper_extension\n</code></pre> <p>This binds the <code>%perfmonitor_*</code> commands and related helpers to the current shell.</p>"},{"location":"api/jupyter/#core-workflow-commands","title":"Core workflow commands","text":"<p>The most common magics mirror the quickstart workflow and control monitoring, reporting, and plotting.</p> <p>               Bases: <code>Magics</code></p> <p>IPython line magics for the JUmPER extension.</p> <p>This class defines the <code>%perfmonitor_*</code> family of magics and a few helpers. Each magic forwards its work to a :class:<code>PerfmonitorMagicAdapter</code> instance, which in turn delegates to :class:<code>PerfmonitorService</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shell</code> <code>Any</code> <p>The current IPython shell instance.</p> required <code>magic_adapter</code> <code>PerfmonitorMagicAdapter</code> <p>Adapter that implements the string-based public API used by these magics.</p> required <p>Examples:</p> <p>Load the extension in a notebook::</p> <pre><code>%load_ext jumper_extension\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@magics_class\nclass PerfmonitorMagics(Magics):\n    \"\"\"IPython line magics for the JUmPER extension.\n\n    This class defines the ``%perfmonitor_*`` family of magics and a\n    few helpers. Each magic forwards its work to a\n    :class:`PerfmonitorMagicAdapter` instance, which in turn delegates\n    to :class:`PerfmonitorService`.\n\n    Args:\n        shell: The current IPython shell instance.\n        magic_adapter: Adapter that implements the string-based public\n            API used by these magics.\n\n    Examples:\n        Load the extension in a notebook::\n\n            %load_ext jumper_extension\n    \"\"\"\n\n    def __init__(\n        self,\n        shell: Any,\n        magic_adapter: PerfmonitorMagicAdapter,\n    ) -&gt; None:\n        \"\"\"Initialize the magics wrapper.\n\n        Args:\n            shell: IPython shell the magics are registered on.\n            magic_adapter: Adapter used to execute the underlying\n                commands.\n        \"\"\"\n        super().__init__(shell)\n        self.magic_adapter = magic_adapter\n\n    def pre_run_cell(self, info: Any) -&gt; None:\n        \"\"\"Hook executed before each cell.\n\n        This inspects the raw cell source, extracts any magic commands,\n        and informs the underlying adapter so that monitoring and\n        reporting state can be updated.\n\n        Args:\n            info: IPython pre-run information object that contains\n                ``raw_cell``.\n        Returns:\n            None\n        \"\"\"\n        raw_cell = info.raw_cell\n        called_line_magics = get_called_line_magics(raw_cell)\n        should_skip_report = is_pure_line_magic_cell(raw_cell)\n        self.magic_adapter.on_pre_run_cell(\n            raw_cell,\n            called_line_magics,\n            should_skip_report,\n        )\n\n    def post_run_cell(self, result: Any) -&gt; None:\n        \"\"\"Hook executed after each cell has run.\n\n        Delegates to the magic adapter so that post-cell reporting and\n        bookkeeping can be performed.\n\n        Args:\n            result: IPython execution result object.\n        Returns:\n            None\n        \"\"\"\n        self.magic_adapter.on_post_run_cell(result.result)\n\n    @line_magic\n    def perfmonitor_resources(self, line: str) -&gt; None:\n        \"\"\"Show hardware resources available to the current session.\n\n        This magic prints CPUs, memory, and GPU information for either\n        a live or imported monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Show resources for the current session::\n\n                %perfmonitor_resources\n        \"\"\"\n        self.magic_adapter.perfmonitor_resources(line)\n\n    @line_magic\n    def perfmonitor_start(self, line: str) -&gt; None:\n        \"\"\"Start performance monitoring.\n\n        If an interval is provided as a single numeric argument, it is\n        interpreted as the sampling interval in seconds; otherwise the\n        default interval is used.\n\n        Args:\n            line: Optional interval argument, for example ``\"1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Start monitoring with the default interval::\n\n                %perfmonitor_start\n\n            Start monitoring with a 0.5 second interval::\n\n                %perfmonitor_start 0.5\n        \"\"\"\n        self.magic_adapter.perfmonitor_start(line)\n\n    @line_magic\n    def perfmonitor_stop(self, line: str) -&gt; None:\n        \"\"\"Stop the active performance monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_stop\n        \"\"\"\n        self.magic_adapter.perfmonitor_stop(line)\n\n    @line_magic\n    def perfmonitor_plot(self, line: str) -&gt; None:\n        \"\"\"Open an interactive performance plot.\n\n        This magic opens interactive widgets for exploring collected\n        performance data.\n\n        Args:\n            line: Raw argument string forwarded to the adapter.\n        Returns:\n            None\n\n        Examples:\n            Open an interactive plot for the current session::\n\n                %perfmonitor_plot\n        \"\"\"\n        self.magic_adapter.perfmonitor_plot(line)\n\n    @line_magic\n    def perfmonitor_enable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Enable automatic performance reports after each cell.\n\n        The line string is parsed for options such as monitoring level,\n        interval, and whether to use text or HTML output.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--level process --interval 1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Enable HTML reports at process level::\n\n                %perfmonitor_enable_perfreports --level process\n\n            Enable text reports for user level with custom interval::\n\n                %perfmonitor_enable_perfreports --level user --interval 0.5 --text\n        \"\"\"\n        self.magic_adapter.perfmonitor_enable_perfreports(line)\n\n\n    @line_magic\n    def perfmonitor_disable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Disable automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_disable_perfreports\n        \"\"\"\n        self.magic_adapter.perfmonitor_disable_perfreports(line)\n\n    @line_magic\n    def perfmonitor_perfreport(self, line: str) -&gt; None:\n        \"\"\"Show a performance report for the current session.\n\n        The line string may include cell range and monitoring level\n        options to restrict the report.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--cell 2:5 --level system\"``.\n        Returns:\n            None\n\n        Examples:\n            Show a report for all cells::\n\n                %perfmonitor_perfreport\n\n            Show a report for cells 2\u20135 at system level::\n\n                %perfmonitor_perfreport --cell 2:5 --level system\n        \"\"\"\n        self.magic_adapter.perfmonitor_perfreport(line)\n\n    @line_magic\n    def perfmonitor_export_perfdata(self, line: str) -&gt; None:\n        \"\"\"Export performance data or push it into the notebook.\n\n        If ``--file`` is provided, data is written to disk. Otherwise,\n        the resulting data frames are pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, such as\n                ``\"--file perf.csv --level process\"``.\n        Returns:\n            None\n\n        Examples:\n            Export process-level data to CSV::\n\n                %perfmonitor_export_perfdata --file perf.csv --level process\n\n            Push a DataFrame into the notebook::\n\n                %perfmonitor_export_perfdata --level user\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_export_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_export_cell_history(self, line: str) -&gt; None:\n        \"\"\"Export cell history or push it into the notebook.\n\n        If ``--file`` is provided, the cell history is written to disk.\n        Otherwise, a data frame is pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--file cells.csv\"``.\n        Returns:\n            None\n\n        Examples:\n            Export cell history to CSV::\n\n                %perfmonitor_export_cell_history --file cells.csv\n\n            Push the cell history DataFrame::\n\n                %perfmonitor_export_cell_history\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_export_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def perfmonitor_load_perfdata(self, line: str) -&gt; None:\n        \"\"\"Load performance data from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_perfdata --file perf.csv\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_load_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_load_cell_history(self, line: str) -&gt; None:\n        \"\"\"Load cell history from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_cell_history --file cells.csv\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_load_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def export_session(self, line: str) -&gt; None:\n        \"\"\"Export the full monitoring session to a directory or zip.\n\n        When the target ends with ``.zip``, a temporary directory is\n        created and compressed into that archive.\n\n        Args:\n            line: Raw argument string containing an optional target\n                path.\n        Returns:\n            None\n\n        Examples:\n            Export into a directory::\n\n                %export_session my_dir\n\n            Export into a zip archive::\n\n                %export_session my_session.zip\n        \"\"\"\n        self.magic_adapter.export_session(line)\n\n    @line_magic\n    def import_session(self, line: str) -&gt; None:\n        \"\"\"Import a monitoring session from a directory or zip.\n\n        Args:\n            line: Raw argument string with the source path.\n        Returns:\n            None\n\n        Examples:\n            %import_session my_session.zip\n        \"\"\"\n        self.magic_adapter.import_session(line)\n\n    @line_magic\n    def perfmonitor_fast_setup(self, line: str) -&gt; None:\n        \"\"\"Run a quick setup for interactive monitoring.\n\n        This helper enables ``ipympl`` interactive plots (if available),\n        starts monitoring, and turns on automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Quickly prepare interactive monitoring in a notebook::\n\n                %perfmonitor_fast_setup\n        \"\"\"\n        # Enable ipympl interactive plots\n        try:\n            self.shell.run_line_magic('matplotlib', 'ipympl')\n            print(\"[JUmPER]: Enabled ipympl interactive plots\")\n        except Exception as e:\n            logger.warning(f\"Failed to enable ipympl interactive plots: {e}\")\n        self.magic_adapter.perfmonitor_fast_setup(line)\n\n    @line_magic\n    def show_cell_history(self, line: str) -&gt; None:\n        \"\"\"Show an interactive table of executed cells.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %show_cell_history\n        \"\"\"\n        self.magic_adapter.show_cell_history(line)\n\n    @line_magic\n    def perfmonitor_help(self, line: str) -&gt; None:\n        \"\"\"Show comprehensive help for all available magics.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_help\n        \"\"\"\n        self.magic_adapter.perfmonitor_help(line)\n\n    @line_magic\n    def start_write_script(self, line: str) -&gt; None:\n        \"\"\"Start recording code from subsequent cells to a Python script.\n\n        If no path is provided, the script writer chooses a default\n        filename based on the current time.\n\n        Args:\n            line: Optional output path, for example\n                ``\\\"my_script.py\\\"``.\n\n        Examples:\n            Start recording to a generated filename::\n\n                %start_write_script\n\n            Record to a specific file::\n\n                %start_write_script my_script.py\n        \"\"\"\n        self.magic_adapter.start_write_script(line)\n\n    @line_magic\n    def end_write_script(self, line: str) -&gt; None:\n        \"\"\"Stop recording and save accumulated code to a script file.\n\n        Args:\n            line: Unused argument string.\n\n        Examples:\n            %end_write_script\n        \"\"\"\n        self.magic_adapter.end_write_script(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_start","title":"<code>perfmonitor_start(line)</code>","text":"<p>Start performance monitoring.</p> <p>If an interval is provided as a single numeric argument, it is interpreted as the sampling interval in seconds; otherwise the default interval is used.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Optional interval argument, for example <code>\"1.0\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Start monitoring with the default interval::</p> <pre><code>%perfmonitor_start\n</code></pre> <p>Start monitoring with a 0.5 second interval::</p> <pre><code>%perfmonitor_start 0.5\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_start(self, line: str) -&gt; None:\n    \"\"\"Start performance monitoring.\n\n    If an interval is provided as a single numeric argument, it is\n    interpreted as the sampling interval in seconds; otherwise the\n    default interval is used.\n\n    Args:\n        line: Optional interval argument, for example ``\"1.0\"``.\n    Returns:\n        None\n\n    Examples:\n        Start monitoring with the default interval::\n\n            %perfmonitor_start\n\n        Start monitoring with a 0.5 second interval::\n\n            %perfmonitor_start 0.5\n    \"\"\"\n    self.magic_adapter.perfmonitor_start(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_stop","title":"<code>perfmonitor_stop(line)</code>","text":"<p>Stop the active performance monitoring session.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_stop</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_stop(self, line: str) -&gt; None:\n    \"\"\"Stop the active performance monitoring session.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_stop\n    \"\"\"\n    self.magic_adapter.perfmonitor_stop(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_perfreport","title":"<code>perfmonitor_perfreport(line)</code>","text":"<p>Show a performance report for the current session.</p> <p>The line string may include cell range and monitoring level options to restrict the report.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, for example <code>\"--cell 2:5 --level system\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Show a report for all cells::</p> <pre><code>%perfmonitor_perfreport\n</code></pre> <p>Show a report for cells 2\u20135 at system level::</p> <pre><code>%perfmonitor_perfreport --cell 2:5 --level system\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_perfreport(self, line: str) -&gt; None:\n    \"\"\"Show a performance report for the current session.\n\n    The line string may include cell range and monitoring level\n    options to restrict the report.\n\n    Args:\n        line: Raw argument string, for example\n            ``\"--cell 2:5 --level system\"``.\n    Returns:\n        None\n\n    Examples:\n        Show a report for all cells::\n\n            %perfmonitor_perfreport\n\n        Show a report for cells 2\u20135 at system level::\n\n            %perfmonitor_perfreport --cell 2:5 --level system\n    \"\"\"\n    self.magic_adapter.perfmonitor_perfreport(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_plot","title":"<code>perfmonitor_plot(line)</code>","text":"<p>Open an interactive performance plot.</p> <p>This magic opens interactive widgets for exploring collected performance data.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string forwarded to the adapter.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Open an interactive plot for the current session::</p> <pre><code>%perfmonitor_plot\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_plot(self, line: str) -&gt; None:\n    \"\"\"Open an interactive performance plot.\n\n    This magic opens interactive widgets for exploring collected\n    performance data.\n\n    Args:\n        line: Raw argument string forwarded to the adapter.\n    Returns:\n        None\n\n    Examples:\n        Open an interactive plot for the current session::\n\n            %perfmonitor_plot\n    \"\"\"\n    self.magic_adapter.perfmonitor_plot(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_enable_perfreports","title":"<code>perfmonitor_enable_perfreports(line)</code>","text":"<p>Enable automatic performance reports after each cell.</p> <p>The line string is parsed for options such as monitoring level, interval, and whether to use text or HTML output.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, for example <code>\"--level process --interval 1.0\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Enable HTML reports at process level::</p> <pre><code>%perfmonitor_enable_perfreports --level process\n</code></pre> <p>Enable text reports for user level with custom interval::</p> <pre><code>%perfmonitor_enable_perfreports --level user --interval 0.5 --text\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_enable_perfreports(self, line: str) -&gt; None:\n    \"\"\"Enable automatic performance reports after each cell.\n\n    The line string is parsed for options such as monitoring level,\n    interval, and whether to use text or HTML output.\n\n    Args:\n        line: Raw argument string, for example\n            ``\"--level process --interval 1.0\"``.\n    Returns:\n        None\n\n    Examples:\n        Enable HTML reports at process level::\n\n            %perfmonitor_enable_perfreports --level process\n\n        Enable text reports for user level with custom interval::\n\n            %perfmonitor_enable_perfreports --level user --interval 0.5 --text\n    \"\"\"\n    self.magic_adapter.perfmonitor_enable_perfreports(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_disable_perfreports","title":"<code>perfmonitor_disable_perfreports(line)</code>","text":"<p>Disable automatic performance reports.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_disable_perfreports</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_disable_perfreports(self, line: str) -&gt; None:\n    \"\"\"Disable automatic performance reports.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_disable_perfreports\n    \"\"\"\n    self.magic_adapter.perfmonitor_disable_perfreports(line)\n</code></pre>"},{"location":"api/jupyter/#data-export-and-import","title":"Data export and import","text":"<p>You can export collected metrics and cell history for external analysis or later reuse.</p> <p>               Bases: <code>Magics</code></p> <p>IPython line magics for the JUmPER extension.</p> <p>This class defines the <code>%perfmonitor_*</code> family of magics and a few helpers. Each magic forwards its work to a :class:<code>PerfmonitorMagicAdapter</code> instance, which in turn delegates to :class:<code>PerfmonitorService</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shell</code> <code>Any</code> <p>The current IPython shell instance.</p> required <code>magic_adapter</code> <code>PerfmonitorMagicAdapter</code> <p>Adapter that implements the string-based public API used by these magics.</p> required <p>Examples:</p> <p>Load the extension in a notebook::</p> <pre><code>%load_ext jumper_extension\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@magics_class\nclass PerfmonitorMagics(Magics):\n    \"\"\"IPython line magics for the JUmPER extension.\n\n    This class defines the ``%perfmonitor_*`` family of magics and a\n    few helpers. Each magic forwards its work to a\n    :class:`PerfmonitorMagicAdapter` instance, which in turn delegates\n    to :class:`PerfmonitorService`.\n\n    Args:\n        shell: The current IPython shell instance.\n        magic_adapter: Adapter that implements the string-based public\n            API used by these magics.\n\n    Examples:\n        Load the extension in a notebook::\n\n            %load_ext jumper_extension\n    \"\"\"\n\n    def __init__(\n        self,\n        shell: Any,\n        magic_adapter: PerfmonitorMagicAdapter,\n    ) -&gt; None:\n        \"\"\"Initialize the magics wrapper.\n\n        Args:\n            shell: IPython shell the magics are registered on.\n            magic_adapter: Adapter used to execute the underlying\n                commands.\n        \"\"\"\n        super().__init__(shell)\n        self.magic_adapter = magic_adapter\n\n    def pre_run_cell(self, info: Any) -&gt; None:\n        \"\"\"Hook executed before each cell.\n\n        This inspects the raw cell source, extracts any magic commands,\n        and informs the underlying adapter so that monitoring and\n        reporting state can be updated.\n\n        Args:\n            info: IPython pre-run information object that contains\n                ``raw_cell``.\n        Returns:\n            None\n        \"\"\"\n        raw_cell = info.raw_cell\n        called_line_magics = get_called_line_magics(raw_cell)\n        should_skip_report = is_pure_line_magic_cell(raw_cell)\n        self.magic_adapter.on_pre_run_cell(\n            raw_cell,\n            called_line_magics,\n            should_skip_report,\n        )\n\n    def post_run_cell(self, result: Any) -&gt; None:\n        \"\"\"Hook executed after each cell has run.\n\n        Delegates to the magic adapter so that post-cell reporting and\n        bookkeeping can be performed.\n\n        Args:\n            result: IPython execution result object.\n        Returns:\n            None\n        \"\"\"\n        self.magic_adapter.on_post_run_cell(result.result)\n\n    @line_magic\n    def perfmonitor_resources(self, line: str) -&gt; None:\n        \"\"\"Show hardware resources available to the current session.\n\n        This magic prints CPUs, memory, and GPU information for either\n        a live or imported monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Show resources for the current session::\n\n                %perfmonitor_resources\n        \"\"\"\n        self.magic_adapter.perfmonitor_resources(line)\n\n    @line_magic\n    def perfmonitor_start(self, line: str) -&gt; None:\n        \"\"\"Start performance monitoring.\n\n        If an interval is provided as a single numeric argument, it is\n        interpreted as the sampling interval in seconds; otherwise the\n        default interval is used.\n\n        Args:\n            line: Optional interval argument, for example ``\"1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Start monitoring with the default interval::\n\n                %perfmonitor_start\n\n            Start monitoring with a 0.5 second interval::\n\n                %perfmonitor_start 0.5\n        \"\"\"\n        self.magic_adapter.perfmonitor_start(line)\n\n    @line_magic\n    def perfmonitor_stop(self, line: str) -&gt; None:\n        \"\"\"Stop the active performance monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_stop\n        \"\"\"\n        self.magic_adapter.perfmonitor_stop(line)\n\n    @line_magic\n    def perfmonitor_plot(self, line: str) -&gt; None:\n        \"\"\"Open an interactive performance plot.\n\n        This magic opens interactive widgets for exploring collected\n        performance data.\n\n        Args:\n            line: Raw argument string forwarded to the adapter.\n        Returns:\n            None\n\n        Examples:\n            Open an interactive plot for the current session::\n\n                %perfmonitor_plot\n        \"\"\"\n        self.magic_adapter.perfmonitor_plot(line)\n\n    @line_magic\n    def perfmonitor_enable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Enable automatic performance reports after each cell.\n\n        The line string is parsed for options such as monitoring level,\n        interval, and whether to use text or HTML output.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--level process --interval 1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Enable HTML reports at process level::\n\n                %perfmonitor_enable_perfreports --level process\n\n            Enable text reports for user level with custom interval::\n\n                %perfmonitor_enable_perfreports --level user --interval 0.5 --text\n        \"\"\"\n        self.magic_adapter.perfmonitor_enable_perfreports(line)\n\n\n    @line_magic\n    def perfmonitor_disable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Disable automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_disable_perfreports\n        \"\"\"\n        self.magic_adapter.perfmonitor_disable_perfreports(line)\n\n    @line_magic\n    def perfmonitor_perfreport(self, line: str) -&gt; None:\n        \"\"\"Show a performance report for the current session.\n\n        The line string may include cell range and monitoring level\n        options to restrict the report.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--cell 2:5 --level system\"``.\n        Returns:\n            None\n\n        Examples:\n            Show a report for all cells::\n\n                %perfmonitor_perfreport\n\n            Show a report for cells 2\u20135 at system level::\n\n                %perfmonitor_perfreport --cell 2:5 --level system\n        \"\"\"\n        self.magic_adapter.perfmonitor_perfreport(line)\n\n    @line_magic\n    def perfmonitor_export_perfdata(self, line: str) -&gt; None:\n        \"\"\"Export performance data or push it into the notebook.\n\n        If ``--file`` is provided, data is written to disk. Otherwise,\n        the resulting data frames are pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, such as\n                ``\"--file perf.csv --level process\"``.\n        Returns:\n            None\n\n        Examples:\n            Export process-level data to CSV::\n\n                %perfmonitor_export_perfdata --file perf.csv --level process\n\n            Push a DataFrame into the notebook::\n\n                %perfmonitor_export_perfdata --level user\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_export_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_export_cell_history(self, line: str) -&gt; None:\n        \"\"\"Export cell history or push it into the notebook.\n\n        If ``--file`` is provided, the cell history is written to disk.\n        Otherwise, a data frame is pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--file cells.csv\"``.\n        Returns:\n            None\n\n        Examples:\n            Export cell history to CSV::\n\n                %perfmonitor_export_cell_history --file cells.csv\n\n            Push the cell history DataFrame::\n\n                %perfmonitor_export_cell_history\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_export_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def perfmonitor_load_perfdata(self, line: str) -&gt; None:\n        \"\"\"Load performance data from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_perfdata --file perf.csv\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_load_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_load_cell_history(self, line: str) -&gt; None:\n        \"\"\"Load cell history from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_cell_history --file cells.csv\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_load_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def export_session(self, line: str) -&gt; None:\n        \"\"\"Export the full monitoring session to a directory or zip.\n\n        When the target ends with ``.zip``, a temporary directory is\n        created and compressed into that archive.\n\n        Args:\n            line: Raw argument string containing an optional target\n                path.\n        Returns:\n            None\n\n        Examples:\n            Export into a directory::\n\n                %export_session my_dir\n\n            Export into a zip archive::\n\n                %export_session my_session.zip\n        \"\"\"\n        self.magic_adapter.export_session(line)\n\n    @line_magic\n    def import_session(self, line: str) -&gt; None:\n        \"\"\"Import a monitoring session from a directory or zip.\n\n        Args:\n            line: Raw argument string with the source path.\n        Returns:\n            None\n\n        Examples:\n            %import_session my_session.zip\n        \"\"\"\n        self.magic_adapter.import_session(line)\n\n    @line_magic\n    def perfmonitor_fast_setup(self, line: str) -&gt; None:\n        \"\"\"Run a quick setup for interactive monitoring.\n\n        This helper enables ``ipympl`` interactive plots (if available),\n        starts monitoring, and turns on automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Quickly prepare interactive monitoring in a notebook::\n\n                %perfmonitor_fast_setup\n        \"\"\"\n        # Enable ipympl interactive plots\n        try:\n            self.shell.run_line_magic('matplotlib', 'ipympl')\n            print(\"[JUmPER]: Enabled ipympl interactive plots\")\n        except Exception as e:\n            logger.warning(f\"Failed to enable ipympl interactive plots: {e}\")\n        self.magic_adapter.perfmonitor_fast_setup(line)\n\n    @line_magic\n    def show_cell_history(self, line: str) -&gt; None:\n        \"\"\"Show an interactive table of executed cells.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %show_cell_history\n        \"\"\"\n        self.magic_adapter.show_cell_history(line)\n\n    @line_magic\n    def perfmonitor_help(self, line: str) -&gt; None:\n        \"\"\"Show comprehensive help for all available magics.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_help\n        \"\"\"\n        self.magic_adapter.perfmonitor_help(line)\n\n    @line_magic\n    def start_write_script(self, line: str) -&gt; None:\n        \"\"\"Start recording code from subsequent cells to a Python script.\n\n        If no path is provided, the script writer chooses a default\n        filename based on the current time.\n\n        Args:\n            line: Optional output path, for example\n                ``\\\"my_script.py\\\"``.\n\n        Examples:\n            Start recording to a generated filename::\n\n                %start_write_script\n\n            Record to a specific file::\n\n                %start_write_script my_script.py\n        \"\"\"\n        self.magic_adapter.start_write_script(line)\n\n    @line_magic\n    def end_write_script(self, line: str) -&gt; None:\n        \"\"\"Stop recording and save accumulated code to a script file.\n\n        Args:\n            line: Unused argument string.\n\n        Examples:\n            %end_write_script\n        \"\"\"\n        self.magic_adapter.end_write_script(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_export_perfdata","title":"<code>perfmonitor_export_perfdata(line)</code>","text":"<p>Export performance data or push it into the notebook.</p> <p>If <code>--file</code> is provided, data is written to disk. Otherwise, the resulting data frames are pushed into the user namespace.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, such as <code>\"--file perf.csv --level process\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Export process-level data to CSV::</p> <pre><code>%perfmonitor_export_perfdata --file perf.csv --level process\n</code></pre> <p>Push a DataFrame into the notebook::</p> <pre><code>%perfmonitor_export_perfdata --level user\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_export_perfdata(self, line: str) -&gt; None:\n    \"\"\"Export performance data or push it into the notebook.\n\n    If ``--file`` is provided, data is written to disk. Otherwise,\n    the resulting data frames are pushed into the user namespace.\n\n    Args:\n        line: Raw argument string, such as\n            ``\"--file perf.csv --level process\"``.\n    Returns:\n        None\n\n    Examples:\n        Export process-level data to CSV::\n\n            %perfmonitor_export_perfdata --file perf.csv --level process\n\n        Push a DataFrame into the notebook::\n\n            %perfmonitor_export_perfdata --level user\n    \"\"\"\n    perfdata = self.magic_adapter.perfmonitor_export_perfdata(line)\n    self.shell.push(perfdata)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_load_perfdata","title":"<code>perfmonitor_load_perfdata(line)</code>","text":"<p>Load performance data from disk and push it to the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string containing <code>--file</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_load_perfdata --file perf.csv</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_load_perfdata(self, line: str) -&gt; None:\n    \"\"\"Load performance data from disk and push it to the notebook.\n\n    Args:\n        line: Raw argument string containing ``--file``.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_load_perfdata --file perf.csv\n    \"\"\"\n    perfdata = self.magic_adapter.perfmonitor_load_perfdata(line)\n    self.shell.push(perfdata)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_export_cell_history","title":"<code>perfmonitor_export_cell_history(line)</code>","text":"<p>Export cell history or push it into the notebook.</p> <p>If <code>--file</code> is provided, the cell history is written to disk. Otherwise, a data frame is pushed into the user namespace.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, for example <code>\"--file cells.csv\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Export cell history to CSV::</p> <pre><code>%perfmonitor_export_cell_history --file cells.csv\n</code></pre> <p>Push the cell history DataFrame::</p> <pre><code>%perfmonitor_export_cell_history\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_export_cell_history(self, line: str) -&gt; None:\n    \"\"\"Export cell history or push it into the notebook.\n\n    If ``--file`` is provided, the cell history is written to disk.\n    Otherwise, a data frame is pushed into the user namespace.\n\n    Args:\n        line: Raw argument string, for example\n            ``\"--file cells.csv\"``.\n    Returns:\n        None\n\n    Examples:\n        Export cell history to CSV::\n\n            %perfmonitor_export_cell_history --file cells.csv\n\n        Push the cell history DataFrame::\n\n            %perfmonitor_export_cell_history\n    \"\"\"\n    cell_history_data = self.magic_adapter.perfmonitor_export_cell_history(line)\n    self.shell.push(cell_history_data)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_load_cell_history","title":"<code>perfmonitor_load_cell_history(line)</code>","text":"<p>Load cell history from disk and push it to the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string containing <code>--file</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_load_cell_history --file cells.csv</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_load_cell_history(self, line: str) -&gt; None:\n    \"\"\"Load cell history from disk and push it to the notebook.\n\n    Args:\n        line: Raw argument string containing ``--file``.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_load_cell_history --file cells.csv\n    \"\"\"\n    cell_history_data = self.magic_adapter.perfmonitor_load_cell_history(line)\n    self.shell.push(cell_history_data)\n</code></pre>"},{"location":"api/jupyter/#session-resources-and-helpers","title":"Session, resources, and helpers","text":"<p>Additional magics provide resources overview, session management, and script recording helpers.</p> <p>               Bases: <code>Magics</code></p> <p>IPython line magics for the JUmPER extension.</p> <p>This class defines the <code>%perfmonitor_*</code> family of magics and a few helpers. Each magic forwards its work to a :class:<code>PerfmonitorMagicAdapter</code> instance, which in turn delegates to :class:<code>PerfmonitorService</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shell</code> <code>Any</code> <p>The current IPython shell instance.</p> required <code>magic_adapter</code> <code>PerfmonitorMagicAdapter</code> <p>Adapter that implements the string-based public API used by these magics.</p> required <p>Examples:</p> <p>Load the extension in a notebook::</p> <pre><code>%load_ext jumper_extension\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@magics_class\nclass PerfmonitorMagics(Magics):\n    \"\"\"IPython line magics for the JUmPER extension.\n\n    This class defines the ``%perfmonitor_*`` family of magics and a\n    few helpers. Each magic forwards its work to a\n    :class:`PerfmonitorMagicAdapter` instance, which in turn delegates\n    to :class:`PerfmonitorService`.\n\n    Args:\n        shell: The current IPython shell instance.\n        magic_adapter: Adapter that implements the string-based public\n            API used by these magics.\n\n    Examples:\n        Load the extension in a notebook::\n\n            %load_ext jumper_extension\n    \"\"\"\n\n    def __init__(\n        self,\n        shell: Any,\n        magic_adapter: PerfmonitorMagicAdapter,\n    ) -&gt; None:\n        \"\"\"Initialize the magics wrapper.\n\n        Args:\n            shell: IPython shell the magics are registered on.\n            magic_adapter: Adapter used to execute the underlying\n                commands.\n        \"\"\"\n        super().__init__(shell)\n        self.magic_adapter = magic_adapter\n\n    def pre_run_cell(self, info: Any) -&gt; None:\n        \"\"\"Hook executed before each cell.\n\n        This inspects the raw cell source, extracts any magic commands,\n        and informs the underlying adapter so that monitoring and\n        reporting state can be updated.\n\n        Args:\n            info: IPython pre-run information object that contains\n                ``raw_cell``.\n        Returns:\n            None\n        \"\"\"\n        raw_cell = info.raw_cell\n        called_line_magics = get_called_line_magics(raw_cell)\n        should_skip_report = is_pure_line_magic_cell(raw_cell)\n        self.magic_adapter.on_pre_run_cell(\n            raw_cell,\n            called_line_magics,\n            should_skip_report,\n        )\n\n    def post_run_cell(self, result: Any) -&gt; None:\n        \"\"\"Hook executed after each cell has run.\n\n        Delegates to the magic adapter so that post-cell reporting and\n        bookkeeping can be performed.\n\n        Args:\n            result: IPython execution result object.\n        Returns:\n            None\n        \"\"\"\n        self.magic_adapter.on_post_run_cell(result.result)\n\n    @line_magic\n    def perfmonitor_resources(self, line: str) -&gt; None:\n        \"\"\"Show hardware resources available to the current session.\n\n        This magic prints CPUs, memory, and GPU information for either\n        a live or imported monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Show resources for the current session::\n\n                %perfmonitor_resources\n        \"\"\"\n        self.magic_adapter.perfmonitor_resources(line)\n\n    @line_magic\n    def perfmonitor_start(self, line: str) -&gt; None:\n        \"\"\"Start performance monitoring.\n\n        If an interval is provided as a single numeric argument, it is\n        interpreted as the sampling interval in seconds; otherwise the\n        default interval is used.\n\n        Args:\n            line: Optional interval argument, for example ``\"1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Start monitoring with the default interval::\n\n                %perfmonitor_start\n\n            Start monitoring with a 0.5 second interval::\n\n                %perfmonitor_start 0.5\n        \"\"\"\n        self.magic_adapter.perfmonitor_start(line)\n\n    @line_magic\n    def perfmonitor_stop(self, line: str) -&gt; None:\n        \"\"\"Stop the active performance monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_stop\n        \"\"\"\n        self.magic_adapter.perfmonitor_stop(line)\n\n    @line_magic\n    def perfmonitor_plot(self, line: str) -&gt; None:\n        \"\"\"Open an interactive performance plot.\n\n        This magic opens interactive widgets for exploring collected\n        performance data.\n\n        Args:\n            line: Raw argument string forwarded to the adapter.\n        Returns:\n            None\n\n        Examples:\n            Open an interactive plot for the current session::\n\n                %perfmonitor_plot\n        \"\"\"\n        self.magic_adapter.perfmonitor_plot(line)\n\n    @line_magic\n    def perfmonitor_enable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Enable automatic performance reports after each cell.\n\n        The line string is parsed for options such as monitoring level,\n        interval, and whether to use text or HTML output.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--level process --interval 1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Enable HTML reports at process level::\n\n                %perfmonitor_enable_perfreports --level process\n\n            Enable text reports for user level with custom interval::\n\n                %perfmonitor_enable_perfreports --level user --interval 0.5 --text\n        \"\"\"\n        self.magic_adapter.perfmonitor_enable_perfreports(line)\n\n\n    @line_magic\n    def perfmonitor_disable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Disable automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_disable_perfreports\n        \"\"\"\n        self.magic_adapter.perfmonitor_disable_perfreports(line)\n\n    @line_magic\n    def perfmonitor_perfreport(self, line: str) -&gt; None:\n        \"\"\"Show a performance report for the current session.\n\n        The line string may include cell range and monitoring level\n        options to restrict the report.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--cell 2:5 --level system\"``.\n        Returns:\n            None\n\n        Examples:\n            Show a report for all cells::\n\n                %perfmonitor_perfreport\n\n            Show a report for cells 2\u20135 at system level::\n\n                %perfmonitor_perfreport --cell 2:5 --level system\n        \"\"\"\n        self.magic_adapter.perfmonitor_perfreport(line)\n\n    @line_magic\n    def perfmonitor_export_perfdata(self, line: str) -&gt; None:\n        \"\"\"Export performance data or push it into the notebook.\n\n        If ``--file`` is provided, data is written to disk. Otherwise,\n        the resulting data frames are pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, such as\n                ``\"--file perf.csv --level process\"``.\n        Returns:\n            None\n\n        Examples:\n            Export process-level data to CSV::\n\n                %perfmonitor_export_perfdata --file perf.csv --level process\n\n            Push a DataFrame into the notebook::\n\n                %perfmonitor_export_perfdata --level user\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_export_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_export_cell_history(self, line: str) -&gt; None:\n        \"\"\"Export cell history or push it into the notebook.\n\n        If ``--file`` is provided, the cell history is written to disk.\n        Otherwise, a data frame is pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--file cells.csv\"``.\n        Returns:\n            None\n\n        Examples:\n            Export cell history to CSV::\n\n                %perfmonitor_export_cell_history --file cells.csv\n\n            Push the cell history DataFrame::\n\n                %perfmonitor_export_cell_history\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_export_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def perfmonitor_load_perfdata(self, line: str) -&gt; None:\n        \"\"\"Load performance data from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_perfdata --file perf.csv\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_load_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_load_cell_history(self, line: str) -&gt; None:\n        \"\"\"Load cell history from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_cell_history --file cells.csv\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_load_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def export_session(self, line: str) -&gt; None:\n        \"\"\"Export the full monitoring session to a directory or zip.\n\n        When the target ends with ``.zip``, a temporary directory is\n        created and compressed into that archive.\n\n        Args:\n            line: Raw argument string containing an optional target\n                path.\n        Returns:\n            None\n\n        Examples:\n            Export into a directory::\n\n                %export_session my_dir\n\n            Export into a zip archive::\n\n                %export_session my_session.zip\n        \"\"\"\n        self.magic_adapter.export_session(line)\n\n    @line_magic\n    def import_session(self, line: str) -&gt; None:\n        \"\"\"Import a monitoring session from a directory or zip.\n\n        Args:\n            line: Raw argument string with the source path.\n        Returns:\n            None\n\n        Examples:\n            %import_session my_session.zip\n        \"\"\"\n        self.magic_adapter.import_session(line)\n\n    @line_magic\n    def perfmonitor_fast_setup(self, line: str) -&gt; None:\n        \"\"\"Run a quick setup for interactive monitoring.\n\n        This helper enables ``ipympl`` interactive plots (if available),\n        starts monitoring, and turns on automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Quickly prepare interactive monitoring in a notebook::\n\n                %perfmonitor_fast_setup\n        \"\"\"\n        # Enable ipympl interactive plots\n        try:\n            self.shell.run_line_magic('matplotlib', 'ipympl')\n            print(\"[JUmPER]: Enabled ipympl interactive plots\")\n        except Exception as e:\n            logger.warning(f\"Failed to enable ipympl interactive plots: {e}\")\n        self.magic_adapter.perfmonitor_fast_setup(line)\n\n    @line_magic\n    def show_cell_history(self, line: str) -&gt; None:\n        \"\"\"Show an interactive table of executed cells.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %show_cell_history\n        \"\"\"\n        self.magic_adapter.show_cell_history(line)\n\n    @line_magic\n    def perfmonitor_help(self, line: str) -&gt; None:\n        \"\"\"Show comprehensive help for all available magics.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_help\n        \"\"\"\n        self.magic_adapter.perfmonitor_help(line)\n\n    @line_magic\n    def start_write_script(self, line: str) -&gt; None:\n        \"\"\"Start recording code from subsequent cells to a Python script.\n\n        If no path is provided, the script writer chooses a default\n        filename based on the current time.\n\n        Args:\n            line: Optional output path, for example\n                ``\\\"my_script.py\\\"``.\n\n        Examples:\n            Start recording to a generated filename::\n\n                %start_write_script\n\n            Record to a specific file::\n\n                %start_write_script my_script.py\n        \"\"\"\n        self.magic_adapter.start_write_script(line)\n\n    @line_magic\n    def end_write_script(self, line: str) -&gt; None:\n        \"\"\"Stop recording and save accumulated code to a script file.\n\n        Args:\n            line: Unused argument string.\n\n        Examples:\n            %end_write_script\n        \"\"\"\n        self.magic_adapter.end_write_script(line)\n</code></pre> <p>For a complete list of commands and brief descriptions, run:</p> <pre><code>%perfmonitor_help\n</code></pre> <p>Details on the underlying Python methods are provided in the Python API section.</p>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_resources","title":"<code>perfmonitor_resources(line)</code>","text":"<p>Show hardware resources available to the current session.</p> <p>This magic prints CPUs, memory, and GPU information for either a live or imported monitoring session.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Show resources for the current session::</p> <pre><code>%perfmonitor_resources\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_resources(self, line: str) -&gt; None:\n    \"\"\"Show hardware resources available to the current session.\n\n    This magic prints CPUs, memory, and GPU information for either\n    a live or imported monitoring session.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        Show resources for the current session::\n\n            %perfmonitor_resources\n    \"\"\"\n    self.magic_adapter.perfmonitor_resources(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.show_cell_history","title":"<code>show_cell_history(line)</code>","text":"<p>Show an interactive table of executed cells.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%show_cell_history</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef show_cell_history(self, line: str) -&gt; None:\n    \"\"\"Show an interactive table of executed cells.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        %show_cell_history\n    \"\"\"\n    self.magic_adapter.show_cell_history(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.export_session","title":"<code>export_session(line)</code>","text":"<p>Export the full monitoring session to a directory or zip.</p> <p>When the target ends with <code>.zip</code>, a temporary directory is created and compressed into that archive.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string containing an optional target path.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Export into a directory::</p> <pre><code>%export_session my_dir\n</code></pre> <p>Export into a zip archive::</p> <pre><code>%export_session my_session.zip\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef export_session(self, line: str) -&gt; None:\n    \"\"\"Export the full monitoring session to a directory or zip.\n\n    When the target ends with ``.zip``, a temporary directory is\n    created and compressed into that archive.\n\n    Args:\n        line: Raw argument string containing an optional target\n            path.\n    Returns:\n        None\n\n    Examples:\n        Export into a directory::\n\n            %export_session my_dir\n\n        Export into a zip archive::\n\n            %export_session my_session.zip\n    \"\"\"\n    self.magic_adapter.export_session(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.import_session","title":"<code>import_session(line)</code>","text":"<p>Import a monitoring session from a directory or zip.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string with the source path.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%import_session my_session.zip</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef import_session(self, line: str) -&gt; None:\n    \"\"\"Import a monitoring session from a directory or zip.\n\n    Args:\n        line: Raw argument string with the source path.\n    Returns:\n        None\n\n    Examples:\n        %import_session my_session.zip\n    \"\"\"\n    self.magic_adapter.import_session(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_fast_setup","title":"<code>perfmonitor_fast_setup(line)</code>","text":"<p>Run a quick setup for interactive monitoring.</p> <p>This helper enables <code>ipympl</code> interactive plots (if available), starts monitoring, and turns on automatic performance reports.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Quickly prepare interactive monitoring in a notebook::</p> <pre><code>%perfmonitor_fast_setup\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_fast_setup(self, line: str) -&gt; None:\n    \"\"\"Run a quick setup for interactive monitoring.\n\n    This helper enables ``ipympl`` interactive plots (if available),\n    starts monitoring, and turns on automatic performance reports.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        Quickly prepare interactive monitoring in a notebook::\n\n            %perfmonitor_fast_setup\n    \"\"\"\n    # Enable ipympl interactive plots\n    try:\n        self.shell.run_line_magic('matplotlib', 'ipympl')\n        print(\"[JUmPER]: Enabled ipympl interactive plots\")\n    except Exception as e:\n        logger.warning(f\"Failed to enable ipympl interactive plots: {e}\")\n    self.magic_adapter.perfmonitor_fast_setup(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.start_write_script","title":"<code>start_write_script(line)</code>","text":"<p>Start recording code from subsequent cells to a Python script.</p> <p>If no path is provided, the script writer chooses a default filename based on the current time.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Optional output path, for example <code>\"my_script.py\"</code>.</p> required <p>Examples:</p> <p>Start recording to a generated filename::</p> <pre><code>%start_write_script\n</code></pre> <p>Record to a specific file::</p> <pre><code>%start_write_script my_script.py\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef start_write_script(self, line: str) -&gt; None:\n    \"\"\"Start recording code from subsequent cells to a Python script.\n\n    If no path is provided, the script writer chooses a default\n    filename based on the current time.\n\n    Args:\n        line: Optional output path, for example\n            ``\\\"my_script.py\\\"``.\n\n    Examples:\n        Start recording to a generated filename::\n\n            %start_write_script\n\n        Record to a specific file::\n\n            %start_write_script my_script.py\n    \"\"\"\n    self.magic_adapter.start_write_script(line)\n</code></pre>"},{"location":"api/jupyter/#jumper_extension.ipython.magics.PerfmonitorMagics.end_write_script","title":"<code>end_write_script(line)</code>","text":"<p>Stop recording and save accumulated code to a script file.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Examples:</p> <p>%end_write_script</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef end_write_script(self, line: str) -&gt; None:\n    \"\"\"Stop recording and save accumulated code to a script file.\n\n    Args:\n        line: Unused argument string.\n\n    Examples:\n        %end_write_script\n    \"\"\"\n    self.magic_adapter.end_write_script(line)\n</code></pre>"},{"location":"api/python/","title":"Python API","text":"<p>The Python API is centered around <code>PerfmonitorService</code>, a standalone orchestration class defined in <code>jumper_extension.core.service</code>. It wires together monitoring, visualization, reporting, cell history, and session management and can be used directly from Python code without IPython magics.</p>"},{"location":"api/python/#constructing-a-service","title":"Constructing a service","text":"<p>The recommended entry point is the factory function <code>build_perfmonitor_service</code>:</p> <pre><code>from jumper_extension.core.service import build_perfmonitor_service\n\nservice = build_perfmonitor_service()\n</code></pre> <p>This function creates:</p> <ul> <li>A <code>Settings</code> instance holding monitoring and reporting configuration.</li> <li>A <code>PerformanceMonitor</code> for collecting metrics.</li> <li>A <code>CellHistory</code> tracker for executed cells.</li> <li>A <code>PerformanceVisualizer</code> and <code>PerformanceReporter</code> attached to the monitor and cell history.</li> <li>A <code>NotebookScriptWriter</code> for script recording.</li> </ul> <p>The returned <code>PerfmonitorService</code> exposes methods that mirror the high\u2011level commands used by the Jupyter API.</p>"},{"location":"api/python/#jumper_extension.core.service.build_perfmonitor_service","title":"<code>build_perfmonitor_service(plots_disabled=False, plots_disabled_reason='Plotting not available.', display_disabled=False, display_disabled_reason='Display not available.')</code>","text":"<p>Build a new :class:<code>PerfmonitorService</code> instance.</p> <p>This factory configures the default monitor, visualizer, reporter, cell history, and script writer for use in Python code.</p> <p>Parameters:</p> Name Type Description Default <code>plots_disabled</code> <code>bool</code> <p>If <code>True</code>, disable plotting in the visualizer.</p> <code>False</code> <code>plots_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when plots are disabled.</p> <code>'Plotting not available.'</code> <code>display_disabled</code> <code>bool</code> <p>If <code>True</code>, disable rich display for reports.</p> <code>False</code> <code>display_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when rich display is disabled.</p> <code>'Display not available.'</code> <p>Returns:</p> Name Type Description <code>PerfmonitorService</code> <code>PerfmonitorService</code> <p>A fully initialized service instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from jumper_extension.core.service import build_perfmonitor_service\n&gt;&gt;&gt; service = build_perfmonitor_service()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def build_perfmonitor_service(\n        plots_disabled: bool = False,\n        plots_disabled_reason: str = \"Plotting not available.\",\n        display_disabled: bool = False,\n        display_disabled_reason: str = \"Display not available.\"\n) -&gt; PerfmonitorService:\n    \"\"\"Build a new :class:`PerfmonitorService` instance.\n\n    This factory configures the default monitor, visualizer, reporter,\n    cell history, and script writer for use in Python code.\n\n    Args:\n        plots_disabled: If ``True``, disable plotting in the visualizer.\n        plots_disabled_reason: Human-readable reason shown when plots\n            are disabled.\n        display_disabled: If ``True``, disable rich display for reports.\n        display_disabled_reason: Human-readable reason shown when rich\n            display is disabled.\n\n    Returns:\n        PerfmonitorService: A fully initialized service instance.\n\n    Examples:\n        &gt;&gt;&gt; from jumper_extension.core.service import build_perfmonitor_service\n        &gt;&gt;&gt; service = build_perfmonitor_service()\n    \"\"\"\n    settings = Settings()\n    monitor = PerformanceMonitor()\n    cell_history = CellHistory()\n    visualizer = build_performance_visualizer(\n        cell_history,\n        plots_disabled=plots_disabled,\n        plots_disabled_reason=plots_disabled_reason,\n    )\n    reporter = build_performance_reporter(\n        cell_history,\n        display_disabled=display_disabled,\n        display_disabled_reason=display_disabled_reason,\n    )\n    script_writer = NotebookScriptWriter(cell_history)\n\n    return PerfmonitorService(\n        settings=settings,\n        monitor=monitor,\n        visualizer=visualizer,\n        reporter=reporter,\n        cell_history=cell_history,\n        script_writer=script_writer,\n    )\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.build_perfmonitor_magic_adapter","title":"<code>build_perfmonitor_magic_adapter(plots_disabled=False, plots_disabled_reason='Plotting not available.', display_disabled=False, display_disabled_reason='Display not available.')</code>","text":"<p>Build a new :class:<code>PerfmonitorMagicAdapter</code> instance.</p> <p>This factory constructs a :class:<code>PerfmonitorService</code> and wraps it with a string-based adapter suitable for IPython magics or other command-style interfaces.</p> <p>Parameters:</p> Name Type Description Default <code>plots_disabled</code> <code>bool</code> <p>If <code>True</code>, disable plotting in the visualizer.</p> <code>False</code> <code>plots_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when plots are disabled.</p> <code>'Plotting not available.'</code> <code>display_disabled</code> <code>bool</code> <p>If <code>True</code>, disable rich display for reports.</p> <code>False</code> <code>display_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when rich display is disabled.</p> <code>'Display not available.'</code> <p>Returns:</p> Name Type Description <code>PerfmonitorMagicAdapter</code> <code>PerfmonitorMagicAdapter</code> <p>Adapter instance wrapping the service.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from jumper_extension.core.service import (\n...     build_perfmonitor_magic_adapter,\n... )\n&gt;&gt;&gt; adapter = build_perfmonitor_magic_adapter()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def build_perfmonitor_magic_adapter(\n        plots_disabled: bool = False,\n        plots_disabled_reason: str = \"Plotting not available.\",\n        display_disabled: bool = False,\n        display_disabled_reason: str = \"Display not available.\"\n) -&gt; PerfmonitorMagicAdapter:\n    \"\"\"Build a new :class:`PerfmonitorMagicAdapter` instance.\n\n    This factory constructs a :class:`PerfmonitorService` and wraps it\n    with a string-based adapter suitable for IPython magics or other\n    command-style interfaces.\n\n    Args:\n        plots_disabled: If ``True``, disable plotting in the visualizer.\n        plots_disabled_reason: Human-readable reason shown when plots\n            are disabled.\n        display_disabled: If ``True``, disable rich display for reports.\n        display_disabled_reason: Human-readable reason shown when rich\n            display is disabled.\n\n    Returns:\n        PerfmonitorMagicAdapter: Adapter instance wrapping the service.\n\n    Examples:\n        &gt;&gt;&gt; from jumper_extension.core.service import (\n        ...     build_perfmonitor_magic_adapter,\n        ... )\n        &gt;&gt;&gt; adapter = build_perfmonitor_magic_adapter()\n    \"\"\"\n    service = build_perfmonitor_service(\n        plots_disabled=plots_disabled,\n        plots_disabled_reason=plots_disabled_reason,\n        display_disabled=display_disabled,\n        display_disabled_reason=display_disabled_reason,\n    )\n\n    parsers = ArgParsers(\n        perfreport=build_perfreport_parser(),\n        auto_perfreports=build_auto_perfreports_parser(),\n        perfmonitor_plot=build_perfmonitor_plot_parser(),\n        export_perfdata=build_export_perfdata_parser(),\n        export_cell_history=build_export_cell_history_parser(),\n        import_perfdata=build_import_perfdata_parser(),\n        import_cell_history=build_import_cell_history_parser(),\n        export_session=build_export_session_parser(),\n        import_session=build_import_session_parser(),\n    )\n\n    return PerfmonitorMagicAdapter(\n        service=service,\n        parsers=parsers,\n    )\n</code></pre>"},{"location":"api/python/#core-service-methods","title":"Core service methods","text":"<p>Core methods control monitoring, plotting, and automatic per\u2011cell reports.</p> <p>High-level performance monitoring service.</p> <p>This service wires together monitoring, visualization, reporting, cell history, and script recording. It is the main entry point for using JUmPER from pure Python code.</p> <p>Examples:</p> <p>Build a default service::</p> <pre><code>from jumper_extension.core.service import (\n    build_perfmonitor_service,\n)\n\nservice = build_perfmonitor_service()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>class PerfmonitorService:\n    \"\"\"High-level performance monitoring service.\n\n    This service wires together monitoring, visualization, reporting,\n    cell history, and script recording. It is the main entry point for\n    using JUmPER from pure Python code.\n\n    Examples:\n        Build a default service::\n\n            from jumper_extension.core.service import (\n                build_perfmonitor_service,\n            )\n\n            service = build_perfmonitor_service()\n    \"\"\"\n    def __init__(\n        self,\n        settings: Settings,\n        monitor: PerformanceMonitorProtocol,\n        visualizer: PerformanceVisualizerProtocol,\n        reporter: PerformanceReporter,\n        cell_history: CellHistory,\n        script_writer: NotebookScriptWriter,\n    ):\n        \"\"\"Initialize a PerfmonitorService instance.\n\n        Args:\n            settings: Extension settings to use for this service.\n            monitor: Performance monitor that will collect metrics.\n            visualizer: Visualizer attached to the monitor.\n            reporter: Reporter responsible for performance reports.\n            cell_history: Cell history tracker for executed cells.\n            script_writer: Script writer used for code recording.\n        \"\"\"\n        self.settings = settings\n        self.monitor = monitor\n        self.visualizer = visualizer\n        self.reporter = reporter\n        self.cell_history = cell_history\n        self.script_writer = script_writer\n        self._skip_report = False\n\n    def on_pre_run_cell(\n        self,\n        raw_cell: str,\n        cell_magics: List[str],\n        should_skip_report: bool,\n    ):\n        \"\"\"Prepare internal state before executing a cell.\n\n        Args:\n            raw_cell: Source code of the cell being executed.\n            cell_magics: List of magic commands detected in the cell.\n            should_skip_report: Whether automatic reporting should be\n                skipped for this cell.\n        \"\"\"\n        self.cell_history.start_cell(raw_cell, cell_magics)\n        self._skip_report = should_skip_report\n\n    def on_post_run_cell(self, result):\n        \"\"\"Handle post-cell execution, including automatic reports.\n\n        If automatic reports are enabled and monitoring is running,\n        this will emit either a text or HTML report for the last cell.\n\n        Args:\n            result: Execution result object returned by IPython.\n        \"\"\"\n        self.cell_history.end_cell(result)\n        if (\n                not self._skip_report\n                and self.monitor.running\n                and self.settings.perfreports.enabled\n        ):\n            if self.settings.perfreports.text:\n                self.reporter.print(\n                    cell_range=None, level=self.settings.perfreports.level\n                )\n            else:\n                self.reporter.display(\n                    cell_range=None, level=self.settings.perfreports.level\n                )\n\n    def show_resources(self) -&gt; None:\n        \"\"\"Display available hardware resources.\n\n        Prints information about CPUs, memory, and GPUs available to the\n        current or imported session.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.show_resources()\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        if self.monitor.is_imported:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_RESOURCES].format(\n                    source=self.monitor.session_source\n                )\n            )\n        print(\"[JUmPER]:\")\n        cpu_info = (\n            f\"  CPUs: {self.monitor.num_cpus}\\n    \"\n            f\"CPU affinity: {self.monitor.cpu_handles}\"\n        )\n        print(cpu_info)\n        mem_gpu_info = (\n            f\"  Memory: {self.monitor.memory_limits['system']} GB\\n  \"\n            f\"GPUs: {self.monitor.num_gpus}\"\n        )\n        print(mem_gpu_info)\n        if self.monitor.num_gpus:\n            print(f\"    {self.monitor.gpu_name}, {self.monitor.gpu_memory} GB\")\n\n    def show_cell_history(self) -&gt; None:\n        \"\"\"Show an interactive table of executed cells.\n\n        Displays the tracked cell history using an interactive table\n        widget, if available.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.show_cell_history()\n        \"\"\"\n        self.cell_history.show_itable()\n\n    def start_monitoring(\n        self,\n        interval: Optional[float] = None,\n    ) -&gt; Optional[ExtensionErrorCode]:\n        \"\"\"Start performance monitoring.\n\n        This method configures and starts the underlying performance\n        monitor. If an offline (imported) session is currently\n        attached, it is replaced with a new live monitor instance.\n\n        Args:\n            interval: Sampling interval in seconds. If ``None``, the\n                value from ``settings.monitoring.default_interval`` is\n                used.\n\n        Returns:\n            Optional[ExtensionErrorCode]: An error code if monitoring\n            was already running, otherwise ``None``.\n\n        Examples:\n            Start monitoring with the default interval::\n\n                service.start_monitoring()\n\n            Start monitoring with a custom interval::\n\n                service.start_monitoring(interval=0.5)\n        \"\"\"\n        # If an imported (offline) session is currently attached, swap to a live monitor\n        if self.monitor.is_imported:\n            self.monitor = PerformanceMonitor()\n\n        if self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.MONITOR_ALREADY_RUNNING]\n            )\n            return ExtensionErrorCode.MONITOR_ALREADY_RUNNING\n\n        if interval is None:\n            interval = self.settings.monitoring.default_interval\n        else:\n            self.settings.monitoring.user_interval = interval\n\n        self.monitor.start(interval)\n        self.settings.monitoring.running = self.monitor.running\n        self.visualizer.attach(self.monitor)\n        self.reporter.attach(self.monitor)\n        return None\n\n    def stop_monitoring(self) -&gt; None:\n        \"\"\"Stop the active performance monitoring session.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.stop_monitoring()\n        \"\"\"\n        if not self.monitor:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        self.monitor.stop()\n        self.settings.monitoring.running = False\n\n    def plot_performance(\n        self,\n        metrics: Optional[List[str]] = None,\n        cell_range: Optional[Tuple[int, int]] = None,\n        level: Optional[str] = None,\n        save_jpeg: Optional[str] = None,\n        pickle_file: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Open an interactive performance plot.\n\n        Works for both live and imported sessions. Uses the attached\n        visualizer to display metrics and interactive widgets. When\n        ``level`` is provided (or inferred for exports), the plot is\n        rendered directly without ipywidgets, which also enables JPEG\n        and pickle exports.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.plot_performance()\n            &gt;&gt;&gt; service.plot_performance(\n            ...     metrics=[\"cpu_summary\", \"memory\"],\n            ...     level=\"process\",\n            ...     cell_range=(0, 3),\n            ... )\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        if self.monitor.is_imported:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_PLOT].format(\n                    source=self.monitor.session_source\n                )\n            )\n\n        effective_level = level\n\n        if effective_level is None and (\n            metrics or save_jpeg or pickle_file\n        ):\n            # Default to configured level for direct plotting/export paths\n            effective_level = self.settings.perfreports.level\n\n        if effective_level is not None:\n            available_levels = get_available_levels()\n            if effective_level not in available_levels:\n                logger.warning(\n                    EXTENSION_ERROR_MESSAGES[\n                        ExtensionErrorCode.INVALID_LEVEL\n                    ].format(level=effective_level, levels=available_levels)\n                )\n                return\n\n        self.visualizer.plot(\n            metric_subsets=metrics,\n            cell_range=cell_range,\n            level=effective_level,\n            save_jpeg=save_jpeg,\n            pickle_file=pickle_file,\n        )\n\n    def enable_perfreports(\n        self,\n        level: str,\n        interval: Optional[float] = None,\n        text: bool = False\n    ) -&gt; None:\n        \"\"\"Enable automatic performance reports after each cell.\n\n        Args:\n            level: Monitoring level (``\\\"process\\\"``, ``\\\"user\\\"``,\n                ``\\\"system\\\"``, or ``\\\"slurm\\\"``).\n            interval: Sampling interval in seconds. If provided, this\n                value is used when starting monitoring.\n            text: If ``True``, use plain-text reports instead of HTML.\n\n        Returns:\n            None\n\n        Examples:\n            Enable HTML reports at process level::\n\n                service.enable_perfreports(level=\"process\")\n\n            Enable text reports with a custom interval::\n\n                service.enable_perfreports(\n                    level=\"user\",\n                    interval=0.5,\n                    text=True,\n                )\n        \"\"\"\n        self.settings.perfreports.enabled = True\n        self.settings.perfreports.level = level\n        self.settings.perfreports.text = text\n\n        format_message = \"text\" if text else \"html\"\n        options_message = f\"level: {level}, interval: {interval}, format: {format_message}\"\n\n        error_code = self.start_monitoring(interval)\n\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_REPORTS_ENABLED\n            ].format(\n                options_message=options_message,\n            )\n        )\n\n    def disable_perfreports(self) -&gt; None:\n        \"\"\"Disable automatic performance reports after cell execution.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.disable_perfreports()\n        \"\"\"\n        self.settings.perfreports.enabled = False\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_REPORTS_DISABLED\n            ]\n        )\n\n    def show_perfreport(\n        self,\n        cell_range: Optional[Tuple[int, int]] = None,\n        level: Optional[str] = None,\n        text: bool = False\n    ) -&gt; None:\n        \"\"\"Show a performance report for the current session.\n\n        Args:\n            cell_range: Optional tuple ``(start_idx, end_idx)`` limiting\n                the report to a subset of cells. If ``None``, all cells\n                are included.\n            level: Optional monitoring level override. If ``None``,\n                the default report level is used.\n            text: If ``True``, render a text report instead of HTML.\n\n        Returns:\n            None\n\n        Examples:\n            Show a report for all cells::\n\n                service.show_perfreport()\n\n            Show a report for cells 2 through 5 at system level::\n\n                service.show_perfreport(\n                    cell_range=(2, 5),\n                    level=\"system\",\n                )\n        \"\"\"\n        if not self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n\n        if text:\n            self.reporter.print(cell_range=cell_range, level=level)\n        else:\n            self.reporter.display(cell_range=cell_range, level=level)\n\n    def export_perfdata(\n        self,\n        file: Optional[str] = None,\n        level: Optional[str] = None,\n        name: Optional[str] = None\n    ) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Export performance data or return it as data frames.\n\n        Args:\n            file: Optional target file path. If provided, data is\n                written using the monitor's data adapter. If ``None``,\n                data is returned as a mapping of variable name to\n                ``pandas.DataFrame``.\n            level: Optional monitoring level override. If ``None``,\n                the default export level is used.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n            ``None``, a mapping from variable name to data frame. If\n            ``file`` is set, an empty dictionary.\n\n        Examples:\n            Export metrics to a CSV file::\n\n                service.export_perfdata(\n                    file=\"performance.csv\",\n                    level=\"process\",\n                )\n\n            Get a DataFrame in memory::\n\n                frames = service.export_perfdata()\n                df = next(iter(frames.values()))\n        \"\"\"\n        if not self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return {}\n\n        if file:\n            self.monitor.data.export(\n                file, level=level, cell_history=self.cell_history\n            )\n            return {}\n        else:\n            df = self.monitor.data.view(\n                level=level, cell_history=self.cell_history\n            )\n            var_name = name or self.settings.export_vars.perfdata\n            logger.info(\n                EXTENSION_INFO_MESSAGES[\n                    ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n                ].format(var_name=var_name)\n            )\n            return {var_name: df}\n\n    def load_perfdata(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Load performance data from a file.\n\n        Args:\n            file: Path to a CSV or JSON file containing performance\n                data.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n            configured variable name to the loaded data frame.\n\n        Examples:\n            &gt;&gt;&gt; frames = service.load_perfdata(\"performance.csv\")\n            &gt;&gt;&gt; df = next(iter(frames.values()))\n        \"\"\"\n        df = self.monitor.data.load(file)\n        var_name = self.settings.loaded_vars.perfdata\n        if df is not None:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[\n                    ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n                ].format(var_name=var_name)\n            )\n        return {var_name: df}\n\n    def export_cell_history(\n        self,\n        file: Optional[str] = None,\n        name: Optional[str] = None\n    ) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Export cell history or return it as a data frame.\n\n        Args:\n            file: Optional target file path. If provided, the cell\n                history is written to disk. If ``None``, data is\n                returned as a mapping of variable name to\n                ``pandas.DataFrame``.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n            ``None``, a mapping from variable name to data frame. If\n            ``file`` is set, an empty dictionary.\n\n        Examples:\n            Export cell history to CSV::\n\n                service.export_cell_history(file=\"cells.csv\")\n\n            Get the history as a DataFrame::\n\n                frames = service.export_cell_history()\n                df = next(iter(frames.values()))\n        \"\"\"\n        if file:\n            self.cell_history.export(file)\n            return {}\n        else:\n            df = self.cell_history.view()\n            var_name = name or self.settings.export_vars.cell_history\n            logger.info(\n                f\"[JUmPER]: Cell history data available as '{var_name}'\"\n            )\n            return {var_name: df}\n\n    def load_cell_history(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Load cell history from a file.\n\n        Args:\n            file: Path to a CSV or JSON file containing cell history.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n            configured variable name to the loaded data frame.\n\n        Examples:\n            &gt;&gt;&gt; frames = service.load_cell_history(\"cells.csv\")\n            &gt;&gt;&gt; df = next(iter(frames.values()))\n        \"\"\"\n        df = self.cell_history.load(file)\n        var_name = self.settings.loaded_vars.cell_history\n        if df is not None:\n            logger.info(\n                f\"[JUmPER]: Cell history data available as '{var_name}'\"\n            )\n        return {var_name: df}\n\n    def export_session(self, path: Optional[str] = None) -&gt; None:\n        \"\"\"Export the full monitoring session.\n\n        This uses :class:`SessionExporter` to write performance data\n        and cell history to a directory or zip archive.\n\n        Args:\n            path: Optional target directory or ``.zip`` file. If the\n                path ends with ``.zip``, a temporary directory is used\n                and then compressed into that archive. If ``None``, a\n                timestamped directory is created.\n\n        Returns:\n            None\n\n        Examples:\n            Export to a directory::\n\n                service.export_session(\"session-dir\")\n\n            Export to a zip archive::\n\n                service.export_session(\"session.zip\")\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n        exporter = SessionExporter(self.monitor, self.cell_history, self.visualizer, self.reporter, logger)\n        exporter.export(path)\n\n    def import_session(self, path: str) -&gt; None:\n        \"\"\"Import a monitoring session from disk.\n\n        Uses :class:`SessionImporter` to attach performance data and\n        cell history from the given directory or zip archive.\n\n        Args:\n            path: Directory or ``.zip`` archive previously created by\n                :meth:`export_session`.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.import_session(\"session.zip\")\n        \"\"\"\n        importer = SessionImporter(logger)\n        ok = importer.import_(path, self)\n        if ok:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.SESSION_IMPORTED].format(\n                    source=self.monitor.session_source\n                )\n            )\n\n    def fast_setup(self) -&gt; None:\n        \"\"\"Quickly start monitoring with per-cell reports enabled.\n\n        This convenience helper starts monitoring with a one-second\n        interval and enables HTML performance reports at the ``process``\n        level.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.fast_setup()\n        \"\"\"\n        self.start_monitoring(1.0)\n        self.enable_perfreports(level=\"process\", interval=1.0, text=False)\n        logger.info(\"[JUmPER]: Fast setup complete! Ready for interactive analysis.\")\n\n    def start_script_recording(self, output_path: Optional[str] = None) -&gt; None:\n        \"\"\"Start recording code from cells to a Python script.\n\n        Args:\n            output_path: Optional path to the output script file. If\n                ``None``, a filename is generated automatically.\n\n        Returns:\n            None\n\n        Examples:\n            Start recording to an auto-generated file::\n\n                service.start_script_recording()\n\n            Record to a specific script path::\n\n                service.start_script_recording(\"analysis_script.py\")\n        \"\"\"\n        self.script_writer.start_recording(self.settings.snapshot(), output_path)\n\n        if output_path:\n            logger.info(f\"[JUmPER]: Started script recording to '{output_path}'\")\n        else:\n            logger.info(\"[JUmPER]: Started script recording (filename will be auto-generated)\")\n\n    def stop_script_recording(self) -&gt; Optional[str]:\n        \"\"\"Stop recording and save accumulated code to a script file.\n\n        Returns:\n            Optional[str]: Path to the saved script file, or ``None``\n            if recording was not active or no cells were captured.\n\n        Examples:\n            &gt;&gt;&gt; path = service.stop_script_recording()\n            &gt;&gt;&gt; print(path)\n        \"\"\"\n        if not self.script_writer:\n            print(\"No script recording in progress.\")\n            return None\n\n        output_path = self.script_writer.stop_recording()\n        logger.info(f\"Script saved to: {output_path}\")\n        return output_path\n\n    @contextmanager\n    def monitored(self) -&gt; \"Iterator[PerfmonitorService]\":\n        \"\"\"Context manager for monitoring a code block.\n\n        This helper simulates a virtual cell: it registers a synthetic\n        cell before the block and finalizes it afterwards so that the\n        enclosed code is tracked like any other cell.\n\n        Yields:\n            PerfmonitorService: The current service instance, for\n            optional use inside the context.\n\n        Examples:\n            Use the service as a monitoring context::\n\n                with service.monitored():\n                    do_expensive_work()\n        \"\"\"\n        unavailable_message = \"unavailable on monitored context\"\n        self.on_pre_run_cell(\n            raw_cell=f\"# &lt;Code {unavailable_message}&gt;\",\n            cell_magics=[f\"&lt;Magics {unavailable_message}&gt;\"],\n            should_skip_report=False\n        )\n        try:\n            yield self\n        finally:\n            self.on_post_run_cell(None)\n\n    def close(self) -&gt; None:\n        \"\"\"Stop monitoring and release resources held by the service.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.close()\n        \"\"\"\n        if self.monitor:\n            self.monitor.stop()\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.start_monitoring","title":"<code>start_monitoring(interval=None)</code>","text":"<p>Start performance monitoring.</p> <p>This method configures and starts the underlying performance monitor. If an offline (imported) session is currently attached, it is replaced with a new live monitor instance.</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>Optional[float]</code> <p>Sampling interval in seconds. If <code>None</code>, the value from <code>settings.monitoring.default_interval</code> is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[ExtensionErrorCode]</code> <p>Optional[ExtensionErrorCode]: An error code if monitoring</p> <code>Optional[ExtensionErrorCode]</code> <p>was already running, otherwise <code>None</code>.</p> <p>Examples:</p> <p>Start monitoring with the default interval::</p> <pre><code>service.start_monitoring()\n</code></pre> <p>Start monitoring with a custom interval::</p> <pre><code>service.start_monitoring(interval=0.5)\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def start_monitoring(\n    self,\n    interval: Optional[float] = None,\n) -&gt; Optional[ExtensionErrorCode]:\n    \"\"\"Start performance monitoring.\n\n    This method configures and starts the underlying performance\n    monitor. If an offline (imported) session is currently\n    attached, it is replaced with a new live monitor instance.\n\n    Args:\n        interval: Sampling interval in seconds. If ``None``, the\n            value from ``settings.monitoring.default_interval`` is\n            used.\n\n    Returns:\n        Optional[ExtensionErrorCode]: An error code if monitoring\n        was already running, otherwise ``None``.\n\n    Examples:\n        Start monitoring with the default interval::\n\n            service.start_monitoring()\n\n        Start monitoring with a custom interval::\n\n            service.start_monitoring(interval=0.5)\n    \"\"\"\n    # If an imported (offline) session is currently attached, swap to a live monitor\n    if self.monitor.is_imported:\n        self.monitor = PerformanceMonitor()\n\n    if self.monitor.running:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.MONITOR_ALREADY_RUNNING]\n        )\n        return ExtensionErrorCode.MONITOR_ALREADY_RUNNING\n\n    if interval is None:\n        interval = self.settings.monitoring.default_interval\n    else:\n        self.settings.monitoring.user_interval = interval\n\n    self.monitor.start(interval)\n    self.settings.monitoring.running = self.monitor.running\n    self.visualizer.attach(self.monitor)\n    self.reporter.attach(self.monitor)\n    return None\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.stop_monitoring","title":"<code>stop_monitoring()</code>","text":"<p>Stop the active performance monitoring session.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; service.stop_monitoring()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def stop_monitoring(self) -&gt; None:\n    \"\"\"Stop the active performance monitoring session.\n\n    Returns:\n        None\n\n    Examples:\n        &gt;&gt;&gt; service.stop_monitoring()\n    \"\"\"\n    if not self.monitor:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n        )\n        return\n    self.monitor.stop()\n    self.settings.monitoring.running = False\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.enable_perfreports","title":"<code>enable_perfreports(level, interval=None, text=False)</code>","text":"<p>Enable automatic performance reports after each cell.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>str</code> <p>Monitoring level (<code>\"process\"</code>, <code>\"user\"</code>, <code>\"system\"</code>, or <code>\"slurm\"</code>).</p> required <code>interval</code> <code>Optional[float]</code> <p>Sampling interval in seconds. If provided, this value is used when starting monitoring.</p> <code>None</code> <code>text</code> <code>bool</code> <p>If <code>True</code>, use plain-text reports instead of HTML.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <p>Enable HTML reports at process level::</p> <pre><code>service.enable_perfreports(level=\"process\")\n</code></pre> <p>Enable text reports with a custom interval::</p> <pre><code>service.enable_perfreports(\n    level=\"user\",\n    interval=0.5,\n    text=True,\n)\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def enable_perfreports(\n    self,\n    level: str,\n    interval: Optional[float] = None,\n    text: bool = False\n) -&gt; None:\n    \"\"\"Enable automatic performance reports after each cell.\n\n    Args:\n        level: Monitoring level (``\\\"process\\\"``, ``\\\"user\\\"``,\n            ``\\\"system\\\"``, or ``\\\"slurm\\\"``).\n        interval: Sampling interval in seconds. If provided, this\n            value is used when starting monitoring.\n        text: If ``True``, use plain-text reports instead of HTML.\n\n    Returns:\n        None\n\n    Examples:\n        Enable HTML reports at process level::\n\n            service.enable_perfreports(level=\"process\")\n\n        Enable text reports with a custom interval::\n\n            service.enable_perfreports(\n                level=\"user\",\n                interval=0.5,\n                text=True,\n            )\n    \"\"\"\n    self.settings.perfreports.enabled = True\n    self.settings.perfreports.level = level\n    self.settings.perfreports.text = text\n\n    format_message = \"text\" if text else \"html\"\n    options_message = f\"level: {level}, interval: {interval}, format: {format_message}\"\n\n    error_code = self.start_monitoring(interval)\n\n    logger.info(\n        EXTENSION_INFO_MESSAGES[\n            ExtensionInfoCode.PERFORMANCE_REPORTS_ENABLED\n        ].format(\n            options_message=options_message,\n        )\n    )\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.disable_perfreports","title":"<code>disable_perfreports()</code>","text":"<p>Disable automatic performance reports after cell execution.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; service.disable_perfreports()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def disable_perfreports(self) -&gt; None:\n    \"\"\"Disable automatic performance reports after cell execution.\n\n    Returns:\n        None\n\n    Examples:\n        &gt;&gt;&gt; service.disable_perfreports()\n    \"\"\"\n    self.settings.perfreports.enabled = False\n    logger.info(\n        EXTENSION_INFO_MESSAGES[\n            ExtensionInfoCode.PERFORMANCE_REPORTS_DISABLED\n        ]\n    )\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.show_perfreport","title":"<code>show_perfreport(cell_range=None, level=None, text=False)</code>","text":"<p>Show a performance report for the current session.</p> <p>Parameters:</p> Name Type Description Default <code>cell_range</code> <code>Optional[Tuple[int, int]]</code> <p>Optional tuple <code>(start_idx, end_idx)</code> limiting the report to a subset of cells. If <code>None</code>, all cells are included.</p> <code>None</code> <code>level</code> <code>Optional[str]</code> <p>Optional monitoring level override. If <code>None</code>, the default report level is used.</p> <code>None</code> <code>text</code> <code>bool</code> <p>If <code>True</code>, render a text report instead of HTML.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <p>Show a report for all cells::</p> <pre><code>service.show_perfreport()\n</code></pre> <p>Show a report for cells 2 through 5 at system level::</p> <pre><code>service.show_perfreport(\n    cell_range=(2, 5),\n    level=\"system\",\n)\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def show_perfreport(\n    self,\n    cell_range: Optional[Tuple[int, int]] = None,\n    level: Optional[str] = None,\n    text: bool = False\n) -&gt; None:\n    \"\"\"Show a performance report for the current session.\n\n    Args:\n        cell_range: Optional tuple ``(start_idx, end_idx)`` limiting\n            the report to a subset of cells. If ``None``, all cells\n            are included.\n        level: Optional monitoring level override. If ``None``,\n            the default report level is used.\n        text: If ``True``, render a text report instead of HTML.\n\n    Returns:\n        None\n\n    Examples:\n        Show a report for all cells::\n\n            service.show_perfreport()\n\n        Show a report for cells 2 through 5 at system level::\n\n            service.show_perfreport(\n                cell_range=(2, 5),\n                level=\"system\",\n            )\n    \"\"\"\n    if not self.monitor.running:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n        )\n        return\n\n    if text:\n        self.reporter.print(cell_range=cell_range, level=level)\n    else:\n        self.reporter.display(cell_range=cell_range, level=level)\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.plot_performance","title":"<code>plot_performance(metrics=None, cell_range=None, level=None, save_jpeg=None, pickle_file=None)</code>","text":"<p>Open an interactive performance plot.</p> <p>Works for both live and imported sessions. Uses the attached visualizer to display metrics and interactive widgets. When <code>level</code> is provided (or inferred for exports), the plot is rendered directly without ipywidgets, which also enables JPEG and pickle exports.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; service.plot_performance()\n&gt;&gt;&gt; service.plot_performance(\n...     metrics=[\"cpu_summary\", \"memory\"],\n...     level=\"process\",\n...     cell_range=(0, 3),\n... )\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def plot_performance(\n    self,\n    metrics: Optional[List[str]] = None,\n    cell_range: Optional[Tuple[int, int]] = None,\n    level: Optional[str] = None,\n    save_jpeg: Optional[str] = None,\n    pickle_file: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Open an interactive performance plot.\n\n    Works for both live and imported sessions. Uses the attached\n    visualizer to display metrics and interactive widgets. When\n    ``level`` is provided (or inferred for exports), the plot is\n    rendered directly without ipywidgets, which also enables JPEG\n    and pickle exports.\n\n    Returns:\n        None\n\n    Examples:\n        &gt;&gt;&gt; service.plot_performance()\n        &gt;&gt;&gt; service.plot_performance(\n        ...     metrics=[\"cpu_summary\", \"memory\"],\n        ...     level=\"process\",\n        ...     cell_range=(0, 3),\n        ... )\n    \"\"\"\n    if not self.monitor.running and not self.monitor.is_imported:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n        )\n        return\n    if self.monitor.is_imported:\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_PLOT].format(\n                source=self.monitor.session_source\n            )\n        )\n\n    effective_level = level\n\n    if effective_level is None and (\n        metrics or save_jpeg or pickle_file\n    ):\n        # Default to configured level for direct plotting/export paths\n        effective_level = self.settings.perfreports.level\n\n    if effective_level is not None:\n        available_levels = get_available_levels()\n        if effective_level not in available_levels:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.INVALID_LEVEL\n                ].format(level=effective_level, levels=available_levels)\n            )\n            return\n\n    self.visualizer.plot(\n        metric_subsets=metrics,\n        cell_range=cell_range,\n        level=effective_level,\n        save_jpeg=save_jpeg,\n        pickle_file=pickle_file,\n    )\n</code></pre>"},{"location":"api/python/#data-access-and-export","title":"Data access and export","text":"<p>The service exposes helpers for accessing collected data as pandas <code>DataFrame</code> objects and exporting or loading them from disk.</p> <p>High-level performance monitoring service.</p> <p>This service wires together monitoring, visualization, reporting, cell history, and script recording. It is the main entry point for using JUmPER from pure Python code.</p> <p>Examples:</p> <p>Build a default service::</p> <pre><code>from jumper_extension.core.service import (\n    build_perfmonitor_service,\n)\n\nservice = build_perfmonitor_service()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>class PerfmonitorService:\n    \"\"\"High-level performance monitoring service.\n\n    This service wires together monitoring, visualization, reporting,\n    cell history, and script recording. It is the main entry point for\n    using JUmPER from pure Python code.\n\n    Examples:\n        Build a default service::\n\n            from jumper_extension.core.service import (\n                build_perfmonitor_service,\n            )\n\n            service = build_perfmonitor_service()\n    \"\"\"\n    def __init__(\n        self,\n        settings: Settings,\n        monitor: PerformanceMonitorProtocol,\n        visualizer: PerformanceVisualizerProtocol,\n        reporter: PerformanceReporter,\n        cell_history: CellHistory,\n        script_writer: NotebookScriptWriter,\n    ):\n        \"\"\"Initialize a PerfmonitorService instance.\n\n        Args:\n            settings: Extension settings to use for this service.\n            monitor: Performance monitor that will collect metrics.\n            visualizer: Visualizer attached to the monitor.\n            reporter: Reporter responsible for performance reports.\n            cell_history: Cell history tracker for executed cells.\n            script_writer: Script writer used for code recording.\n        \"\"\"\n        self.settings = settings\n        self.monitor = monitor\n        self.visualizer = visualizer\n        self.reporter = reporter\n        self.cell_history = cell_history\n        self.script_writer = script_writer\n        self._skip_report = False\n\n    def on_pre_run_cell(\n        self,\n        raw_cell: str,\n        cell_magics: List[str],\n        should_skip_report: bool,\n    ):\n        \"\"\"Prepare internal state before executing a cell.\n\n        Args:\n            raw_cell: Source code of the cell being executed.\n            cell_magics: List of magic commands detected in the cell.\n            should_skip_report: Whether automatic reporting should be\n                skipped for this cell.\n        \"\"\"\n        self.cell_history.start_cell(raw_cell, cell_magics)\n        self._skip_report = should_skip_report\n\n    def on_post_run_cell(self, result):\n        \"\"\"Handle post-cell execution, including automatic reports.\n\n        If automatic reports are enabled and monitoring is running,\n        this will emit either a text or HTML report for the last cell.\n\n        Args:\n            result: Execution result object returned by IPython.\n        \"\"\"\n        self.cell_history.end_cell(result)\n        if (\n                not self._skip_report\n                and self.monitor.running\n                and self.settings.perfreports.enabled\n        ):\n            if self.settings.perfreports.text:\n                self.reporter.print(\n                    cell_range=None, level=self.settings.perfreports.level\n                )\n            else:\n                self.reporter.display(\n                    cell_range=None, level=self.settings.perfreports.level\n                )\n\n    def show_resources(self) -&gt; None:\n        \"\"\"Display available hardware resources.\n\n        Prints information about CPUs, memory, and GPUs available to the\n        current or imported session.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.show_resources()\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        if self.monitor.is_imported:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_RESOURCES].format(\n                    source=self.monitor.session_source\n                )\n            )\n        print(\"[JUmPER]:\")\n        cpu_info = (\n            f\"  CPUs: {self.monitor.num_cpus}\\n    \"\n            f\"CPU affinity: {self.monitor.cpu_handles}\"\n        )\n        print(cpu_info)\n        mem_gpu_info = (\n            f\"  Memory: {self.monitor.memory_limits['system']} GB\\n  \"\n            f\"GPUs: {self.monitor.num_gpus}\"\n        )\n        print(mem_gpu_info)\n        if self.monitor.num_gpus:\n            print(f\"    {self.monitor.gpu_name}, {self.monitor.gpu_memory} GB\")\n\n    def show_cell_history(self) -&gt; None:\n        \"\"\"Show an interactive table of executed cells.\n\n        Displays the tracked cell history using an interactive table\n        widget, if available.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.show_cell_history()\n        \"\"\"\n        self.cell_history.show_itable()\n\n    def start_monitoring(\n        self,\n        interval: Optional[float] = None,\n    ) -&gt; Optional[ExtensionErrorCode]:\n        \"\"\"Start performance monitoring.\n\n        This method configures and starts the underlying performance\n        monitor. If an offline (imported) session is currently\n        attached, it is replaced with a new live monitor instance.\n\n        Args:\n            interval: Sampling interval in seconds. If ``None``, the\n                value from ``settings.monitoring.default_interval`` is\n                used.\n\n        Returns:\n            Optional[ExtensionErrorCode]: An error code if monitoring\n            was already running, otherwise ``None``.\n\n        Examples:\n            Start monitoring with the default interval::\n\n                service.start_monitoring()\n\n            Start monitoring with a custom interval::\n\n                service.start_monitoring(interval=0.5)\n        \"\"\"\n        # If an imported (offline) session is currently attached, swap to a live monitor\n        if self.monitor.is_imported:\n            self.monitor = PerformanceMonitor()\n\n        if self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.MONITOR_ALREADY_RUNNING]\n            )\n            return ExtensionErrorCode.MONITOR_ALREADY_RUNNING\n\n        if interval is None:\n            interval = self.settings.monitoring.default_interval\n        else:\n            self.settings.monitoring.user_interval = interval\n\n        self.monitor.start(interval)\n        self.settings.monitoring.running = self.monitor.running\n        self.visualizer.attach(self.monitor)\n        self.reporter.attach(self.monitor)\n        return None\n\n    def stop_monitoring(self) -&gt; None:\n        \"\"\"Stop the active performance monitoring session.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.stop_monitoring()\n        \"\"\"\n        if not self.monitor:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        self.monitor.stop()\n        self.settings.monitoring.running = False\n\n    def plot_performance(\n        self,\n        metrics: Optional[List[str]] = None,\n        cell_range: Optional[Tuple[int, int]] = None,\n        level: Optional[str] = None,\n        save_jpeg: Optional[str] = None,\n        pickle_file: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Open an interactive performance plot.\n\n        Works for both live and imported sessions. Uses the attached\n        visualizer to display metrics and interactive widgets. When\n        ``level`` is provided (or inferred for exports), the plot is\n        rendered directly without ipywidgets, which also enables JPEG\n        and pickle exports.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.plot_performance()\n            &gt;&gt;&gt; service.plot_performance(\n            ...     metrics=[\"cpu_summary\", \"memory\"],\n            ...     level=\"process\",\n            ...     cell_range=(0, 3),\n            ... )\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        if self.monitor.is_imported:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_PLOT].format(\n                    source=self.monitor.session_source\n                )\n            )\n\n        effective_level = level\n\n        if effective_level is None and (\n            metrics or save_jpeg or pickle_file\n        ):\n            # Default to configured level for direct plotting/export paths\n            effective_level = self.settings.perfreports.level\n\n        if effective_level is not None:\n            available_levels = get_available_levels()\n            if effective_level not in available_levels:\n                logger.warning(\n                    EXTENSION_ERROR_MESSAGES[\n                        ExtensionErrorCode.INVALID_LEVEL\n                    ].format(level=effective_level, levels=available_levels)\n                )\n                return\n\n        self.visualizer.plot(\n            metric_subsets=metrics,\n            cell_range=cell_range,\n            level=effective_level,\n            save_jpeg=save_jpeg,\n            pickle_file=pickle_file,\n        )\n\n    def enable_perfreports(\n        self,\n        level: str,\n        interval: Optional[float] = None,\n        text: bool = False\n    ) -&gt; None:\n        \"\"\"Enable automatic performance reports after each cell.\n\n        Args:\n            level: Monitoring level (``\\\"process\\\"``, ``\\\"user\\\"``,\n                ``\\\"system\\\"``, or ``\\\"slurm\\\"``).\n            interval: Sampling interval in seconds. If provided, this\n                value is used when starting monitoring.\n            text: If ``True``, use plain-text reports instead of HTML.\n\n        Returns:\n            None\n\n        Examples:\n            Enable HTML reports at process level::\n\n                service.enable_perfreports(level=\"process\")\n\n            Enable text reports with a custom interval::\n\n                service.enable_perfreports(\n                    level=\"user\",\n                    interval=0.5,\n                    text=True,\n                )\n        \"\"\"\n        self.settings.perfreports.enabled = True\n        self.settings.perfreports.level = level\n        self.settings.perfreports.text = text\n\n        format_message = \"text\" if text else \"html\"\n        options_message = f\"level: {level}, interval: {interval}, format: {format_message}\"\n\n        error_code = self.start_monitoring(interval)\n\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_REPORTS_ENABLED\n            ].format(\n                options_message=options_message,\n            )\n        )\n\n    def disable_perfreports(self) -&gt; None:\n        \"\"\"Disable automatic performance reports after cell execution.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.disable_perfreports()\n        \"\"\"\n        self.settings.perfreports.enabled = False\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_REPORTS_DISABLED\n            ]\n        )\n\n    def show_perfreport(\n        self,\n        cell_range: Optional[Tuple[int, int]] = None,\n        level: Optional[str] = None,\n        text: bool = False\n    ) -&gt; None:\n        \"\"\"Show a performance report for the current session.\n\n        Args:\n            cell_range: Optional tuple ``(start_idx, end_idx)`` limiting\n                the report to a subset of cells. If ``None``, all cells\n                are included.\n            level: Optional monitoring level override. If ``None``,\n                the default report level is used.\n            text: If ``True``, render a text report instead of HTML.\n\n        Returns:\n            None\n\n        Examples:\n            Show a report for all cells::\n\n                service.show_perfreport()\n\n            Show a report for cells 2 through 5 at system level::\n\n                service.show_perfreport(\n                    cell_range=(2, 5),\n                    level=\"system\",\n                )\n        \"\"\"\n        if not self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n\n        if text:\n            self.reporter.print(cell_range=cell_range, level=level)\n        else:\n            self.reporter.display(cell_range=cell_range, level=level)\n\n    def export_perfdata(\n        self,\n        file: Optional[str] = None,\n        level: Optional[str] = None,\n        name: Optional[str] = None\n    ) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Export performance data or return it as data frames.\n\n        Args:\n            file: Optional target file path. If provided, data is\n                written using the monitor's data adapter. If ``None``,\n                data is returned as a mapping of variable name to\n                ``pandas.DataFrame``.\n            level: Optional monitoring level override. If ``None``,\n                the default export level is used.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n            ``None``, a mapping from variable name to data frame. If\n            ``file`` is set, an empty dictionary.\n\n        Examples:\n            Export metrics to a CSV file::\n\n                service.export_perfdata(\n                    file=\"performance.csv\",\n                    level=\"process\",\n                )\n\n            Get a DataFrame in memory::\n\n                frames = service.export_perfdata()\n                df = next(iter(frames.values()))\n        \"\"\"\n        if not self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return {}\n\n        if file:\n            self.monitor.data.export(\n                file, level=level, cell_history=self.cell_history\n            )\n            return {}\n        else:\n            df = self.monitor.data.view(\n                level=level, cell_history=self.cell_history\n            )\n            var_name = name or self.settings.export_vars.perfdata\n            logger.info(\n                EXTENSION_INFO_MESSAGES[\n                    ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n                ].format(var_name=var_name)\n            )\n            return {var_name: df}\n\n    def load_perfdata(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Load performance data from a file.\n\n        Args:\n            file: Path to a CSV or JSON file containing performance\n                data.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n            configured variable name to the loaded data frame.\n\n        Examples:\n            &gt;&gt;&gt; frames = service.load_perfdata(\"performance.csv\")\n            &gt;&gt;&gt; df = next(iter(frames.values()))\n        \"\"\"\n        df = self.monitor.data.load(file)\n        var_name = self.settings.loaded_vars.perfdata\n        if df is not None:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[\n                    ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n                ].format(var_name=var_name)\n            )\n        return {var_name: df}\n\n    def export_cell_history(\n        self,\n        file: Optional[str] = None,\n        name: Optional[str] = None\n    ) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Export cell history or return it as a data frame.\n\n        Args:\n            file: Optional target file path. If provided, the cell\n                history is written to disk. If ``None``, data is\n                returned as a mapping of variable name to\n                ``pandas.DataFrame``.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n            ``None``, a mapping from variable name to data frame. If\n            ``file`` is set, an empty dictionary.\n\n        Examples:\n            Export cell history to CSV::\n\n                service.export_cell_history(file=\"cells.csv\")\n\n            Get the history as a DataFrame::\n\n                frames = service.export_cell_history()\n                df = next(iter(frames.values()))\n        \"\"\"\n        if file:\n            self.cell_history.export(file)\n            return {}\n        else:\n            df = self.cell_history.view()\n            var_name = name or self.settings.export_vars.cell_history\n            logger.info(\n                f\"[JUmPER]: Cell history data available as '{var_name}'\"\n            )\n            return {var_name: df}\n\n    def load_cell_history(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Load cell history from a file.\n\n        Args:\n            file: Path to a CSV or JSON file containing cell history.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n            configured variable name to the loaded data frame.\n\n        Examples:\n            &gt;&gt;&gt; frames = service.load_cell_history(\"cells.csv\")\n            &gt;&gt;&gt; df = next(iter(frames.values()))\n        \"\"\"\n        df = self.cell_history.load(file)\n        var_name = self.settings.loaded_vars.cell_history\n        if df is not None:\n            logger.info(\n                f\"[JUmPER]: Cell history data available as '{var_name}'\"\n            )\n        return {var_name: df}\n\n    def export_session(self, path: Optional[str] = None) -&gt; None:\n        \"\"\"Export the full monitoring session.\n\n        This uses :class:`SessionExporter` to write performance data\n        and cell history to a directory or zip archive.\n\n        Args:\n            path: Optional target directory or ``.zip`` file. If the\n                path ends with ``.zip``, a temporary directory is used\n                and then compressed into that archive. If ``None``, a\n                timestamped directory is created.\n\n        Returns:\n            None\n\n        Examples:\n            Export to a directory::\n\n                service.export_session(\"session-dir\")\n\n            Export to a zip archive::\n\n                service.export_session(\"session.zip\")\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n        exporter = SessionExporter(self.monitor, self.cell_history, self.visualizer, self.reporter, logger)\n        exporter.export(path)\n\n    def import_session(self, path: str) -&gt; None:\n        \"\"\"Import a monitoring session from disk.\n\n        Uses :class:`SessionImporter` to attach performance data and\n        cell history from the given directory or zip archive.\n\n        Args:\n            path: Directory or ``.zip`` archive previously created by\n                :meth:`export_session`.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.import_session(\"session.zip\")\n        \"\"\"\n        importer = SessionImporter(logger)\n        ok = importer.import_(path, self)\n        if ok:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.SESSION_IMPORTED].format(\n                    source=self.monitor.session_source\n                )\n            )\n\n    def fast_setup(self) -&gt; None:\n        \"\"\"Quickly start monitoring with per-cell reports enabled.\n\n        This convenience helper starts monitoring with a one-second\n        interval and enables HTML performance reports at the ``process``\n        level.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.fast_setup()\n        \"\"\"\n        self.start_monitoring(1.0)\n        self.enable_perfreports(level=\"process\", interval=1.0, text=False)\n        logger.info(\"[JUmPER]: Fast setup complete! Ready for interactive analysis.\")\n\n    def start_script_recording(self, output_path: Optional[str] = None) -&gt; None:\n        \"\"\"Start recording code from cells to a Python script.\n\n        Args:\n            output_path: Optional path to the output script file. If\n                ``None``, a filename is generated automatically.\n\n        Returns:\n            None\n\n        Examples:\n            Start recording to an auto-generated file::\n\n                service.start_script_recording()\n\n            Record to a specific script path::\n\n                service.start_script_recording(\"analysis_script.py\")\n        \"\"\"\n        self.script_writer.start_recording(self.settings.snapshot(), output_path)\n\n        if output_path:\n            logger.info(f\"[JUmPER]: Started script recording to '{output_path}'\")\n        else:\n            logger.info(\"[JUmPER]: Started script recording (filename will be auto-generated)\")\n\n    def stop_script_recording(self) -&gt; Optional[str]:\n        \"\"\"Stop recording and save accumulated code to a script file.\n\n        Returns:\n            Optional[str]: Path to the saved script file, or ``None``\n            if recording was not active or no cells were captured.\n\n        Examples:\n            &gt;&gt;&gt; path = service.stop_script_recording()\n            &gt;&gt;&gt; print(path)\n        \"\"\"\n        if not self.script_writer:\n            print(\"No script recording in progress.\")\n            return None\n\n        output_path = self.script_writer.stop_recording()\n        logger.info(f\"Script saved to: {output_path}\")\n        return output_path\n\n    @contextmanager\n    def monitored(self) -&gt; \"Iterator[PerfmonitorService]\":\n        \"\"\"Context manager for monitoring a code block.\n\n        This helper simulates a virtual cell: it registers a synthetic\n        cell before the block and finalizes it afterwards so that the\n        enclosed code is tracked like any other cell.\n\n        Yields:\n            PerfmonitorService: The current service instance, for\n            optional use inside the context.\n\n        Examples:\n            Use the service as a monitoring context::\n\n                with service.monitored():\n                    do_expensive_work()\n        \"\"\"\n        unavailable_message = \"unavailable on monitored context\"\n        self.on_pre_run_cell(\n            raw_cell=f\"# &lt;Code {unavailable_message}&gt;\",\n            cell_magics=[f\"&lt;Magics {unavailable_message}&gt;\"],\n            should_skip_report=False\n        )\n        try:\n            yield self\n        finally:\n            self.on_post_run_cell(None)\n\n    def close(self) -&gt; None:\n        \"\"\"Stop monitoring and release resources held by the service.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.close()\n        \"\"\"\n        if self.monitor:\n            self.monitor.stop()\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.export_perfdata","title":"<code>export_perfdata(file=None, level=None, name=None)</code>","text":"<p>Export performance data or return it as data frames.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>Optional[str]</code> <p>Optional target file path. If provided, data is written using the monitor's data adapter. If <code>None</code>, data is returned as a mapping of variable name to <code>pandas.DataFrame</code>.</p> <code>None</code> <code>level</code> <code>Optional[str]</code> <p>Optional monitoring level override. If <code>None</code>, the default export level is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, DataFrame]]</code> <p>Optional[Dict[str, pandas.DataFrame]]: If <code>file</code> is</p> <code>Optional[Dict[str, DataFrame]]</code> <p><code>None</code>, a mapping from variable name to data frame. If</p> <code>Optional[Dict[str, DataFrame]]</code> <p><code>file</code> is set, an empty dictionary.</p> <p>Examples:</p> <p>Export metrics to a CSV file::</p> <pre><code>service.export_perfdata(\n    file=\"performance.csv\",\n    level=\"process\",\n)\n</code></pre> <p>Get a DataFrame in memory::</p> <pre><code>frames = service.export_perfdata()\ndf = next(iter(frames.values()))\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def export_perfdata(\n    self,\n    file: Optional[str] = None,\n    level: Optional[str] = None,\n    name: Optional[str] = None\n) -&gt; Optional[Dict[str, pd.DataFrame]]:\n    \"\"\"Export performance data or return it as data frames.\n\n    Args:\n        file: Optional target file path. If provided, data is\n            written using the monitor's data adapter. If ``None``,\n            data is returned as a mapping of variable name to\n            ``pandas.DataFrame``.\n        level: Optional monitoring level override. If ``None``,\n            the default export level is used.\n\n    Returns:\n        Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n        ``None``, a mapping from variable name to data frame. If\n        ``file`` is set, an empty dictionary.\n\n    Examples:\n        Export metrics to a CSV file::\n\n            service.export_perfdata(\n                file=\"performance.csv\",\n                level=\"process\",\n            )\n\n        Get a DataFrame in memory::\n\n            frames = service.export_perfdata()\n            df = next(iter(frames.values()))\n    \"\"\"\n    if not self.monitor.running:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n        )\n        return {}\n\n    if file:\n        self.monitor.data.export(\n            file, level=level, cell_history=self.cell_history\n        )\n        return {}\n    else:\n        df = self.monitor.data.view(\n            level=level, cell_history=self.cell_history\n        )\n        var_name = name or self.settings.export_vars.perfdata\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n            ].format(var_name=var_name)\n        )\n        return {var_name: df}\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.load_perfdata","title":"<code>load_perfdata(file)</code>","text":"<p>Load performance data from a file.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>Path to a CSV or JSON file containing performance data.</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, DataFrame]]</code> <p>Optional[Dict[str, pandas.DataFrame]]: Mapping from the</p> <code>Optional[Dict[str, DataFrame]]</code> <p>configured variable name to the loaded data frame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; frames = service.load_perfdata(\"performance.csv\")\n&gt;&gt;&gt; df = next(iter(frames.values()))\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def load_perfdata(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n    \"\"\"Load performance data from a file.\n\n    Args:\n        file: Path to a CSV or JSON file containing performance\n            data.\n\n    Returns:\n        Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n        configured variable name to the loaded data frame.\n\n    Examples:\n        &gt;&gt;&gt; frames = service.load_perfdata(\"performance.csv\")\n        &gt;&gt;&gt; df = next(iter(frames.values()))\n    \"\"\"\n    df = self.monitor.data.load(file)\n    var_name = self.settings.loaded_vars.perfdata\n    if df is not None:\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n            ].format(var_name=var_name)\n        )\n    return {var_name: df}\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.export_cell_history","title":"<code>export_cell_history(file=None, name=None)</code>","text":"<p>Export cell history or return it as a data frame.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>Optional[str]</code> <p>Optional target file path. If provided, the cell history is written to disk. If <code>None</code>, data is returned as a mapping of variable name to <code>pandas.DataFrame</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, DataFrame]]</code> <p>Optional[Dict[str, pandas.DataFrame]]: If <code>file</code> is</p> <code>Optional[Dict[str, DataFrame]]</code> <p><code>None</code>, a mapping from variable name to data frame. If</p> <code>Optional[Dict[str, DataFrame]]</code> <p><code>file</code> is set, an empty dictionary.</p> <p>Examples:</p> <p>Export cell history to CSV::</p> <pre><code>service.export_cell_history(file=\"cells.csv\")\n</code></pre> <p>Get the history as a DataFrame::</p> <pre><code>frames = service.export_cell_history()\ndf = next(iter(frames.values()))\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def export_cell_history(\n    self,\n    file: Optional[str] = None,\n    name: Optional[str] = None\n) -&gt; Optional[Dict[str, pd.DataFrame]]:\n    \"\"\"Export cell history or return it as a data frame.\n\n    Args:\n        file: Optional target file path. If provided, the cell\n            history is written to disk. If ``None``, data is\n            returned as a mapping of variable name to\n            ``pandas.DataFrame``.\n\n    Returns:\n        Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n        ``None``, a mapping from variable name to data frame. If\n        ``file`` is set, an empty dictionary.\n\n    Examples:\n        Export cell history to CSV::\n\n            service.export_cell_history(file=\"cells.csv\")\n\n        Get the history as a DataFrame::\n\n            frames = service.export_cell_history()\n            df = next(iter(frames.values()))\n    \"\"\"\n    if file:\n        self.cell_history.export(file)\n        return {}\n    else:\n        df = self.cell_history.view()\n        var_name = name or self.settings.export_vars.cell_history\n        logger.info(\n            f\"[JUmPER]: Cell history data available as '{var_name}'\"\n        )\n        return {var_name: df}\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.load_cell_history","title":"<code>load_cell_history(file)</code>","text":"<p>Load cell history from a file.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>Path to a CSV or JSON file containing cell history.</p> required <p>Returns:</p> Type Description <code>Optional[Dict[str, DataFrame]]</code> <p>Optional[Dict[str, pandas.DataFrame]]: Mapping from the</p> <code>Optional[Dict[str, DataFrame]]</code> <p>configured variable name to the loaded data frame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; frames = service.load_cell_history(\"cells.csv\")\n&gt;&gt;&gt; df = next(iter(frames.values()))\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def load_cell_history(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n    \"\"\"Load cell history from a file.\n\n    Args:\n        file: Path to a CSV or JSON file containing cell history.\n\n    Returns:\n        Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n        configured variable name to the loaded data frame.\n\n    Examples:\n        &gt;&gt;&gt; frames = service.load_cell_history(\"cells.csv\")\n        &gt;&gt;&gt; df = next(iter(frames.values()))\n    \"\"\"\n    df = self.cell_history.load(file)\n    var_name = self.settings.loaded_vars.cell_history\n    if df is not None:\n        logger.info(\n            f\"[JUmPER]: Cell history data available as '{var_name}'\"\n        )\n    return {var_name: df}\n</code></pre>"},{"location":"api/python/#sessions-scripts-and-utilities","title":"Sessions, scripts, and utilities","text":"<p>For higher\u2011level workflows, the service also exposes helpers for resources, sessions, and script recording.</p> <p>For direct interaction with string\u2011based commands or IPython magics, see the String Based API and Jupyter API sections.</p> <p>High-level performance monitoring service.</p> <p>This service wires together monitoring, visualization, reporting, cell history, and script recording. It is the main entry point for using JUmPER from pure Python code.</p> <p>Examples:</p> <p>Build a default service::</p> <pre><code>from jumper_extension.core.service import (\n    build_perfmonitor_service,\n)\n\nservice = build_perfmonitor_service()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>class PerfmonitorService:\n    \"\"\"High-level performance monitoring service.\n\n    This service wires together monitoring, visualization, reporting,\n    cell history, and script recording. It is the main entry point for\n    using JUmPER from pure Python code.\n\n    Examples:\n        Build a default service::\n\n            from jumper_extension.core.service import (\n                build_perfmonitor_service,\n            )\n\n            service = build_perfmonitor_service()\n    \"\"\"\n    def __init__(\n        self,\n        settings: Settings,\n        monitor: PerformanceMonitorProtocol,\n        visualizer: PerformanceVisualizerProtocol,\n        reporter: PerformanceReporter,\n        cell_history: CellHistory,\n        script_writer: NotebookScriptWriter,\n    ):\n        \"\"\"Initialize a PerfmonitorService instance.\n\n        Args:\n            settings: Extension settings to use for this service.\n            monitor: Performance monitor that will collect metrics.\n            visualizer: Visualizer attached to the monitor.\n            reporter: Reporter responsible for performance reports.\n            cell_history: Cell history tracker for executed cells.\n            script_writer: Script writer used for code recording.\n        \"\"\"\n        self.settings = settings\n        self.monitor = monitor\n        self.visualizer = visualizer\n        self.reporter = reporter\n        self.cell_history = cell_history\n        self.script_writer = script_writer\n        self._skip_report = False\n\n    def on_pre_run_cell(\n        self,\n        raw_cell: str,\n        cell_magics: List[str],\n        should_skip_report: bool,\n    ):\n        \"\"\"Prepare internal state before executing a cell.\n\n        Args:\n            raw_cell: Source code of the cell being executed.\n            cell_magics: List of magic commands detected in the cell.\n            should_skip_report: Whether automatic reporting should be\n                skipped for this cell.\n        \"\"\"\n        self.cell_history.start_cell(raw_cell, cell_magics)\n        self._skip_report = should_skip_report\n\n    def on_post_run_cell(self, result):\n        \"\"\"Handle post-cell execution, including automatic reports.\n\n        If automatic reports are enabled and monitoring is running,\n        this will emit either a text or HTML report for the last cell.\n\n        Args:\n            result: Execution result object returned by IPython.\n        \"\"\"\n        self.cell_history.end_cell(result)\n        if (\n                not self._skip_report\n                and self.monitor.running\n                and self.settings.perfreports.enabled\n        ):\n            if self.settings.perfreports.text:\n                self.reporter.print(\n                    cell_range=None, level=self.settings.perfreports.level\n                )\n            else:\n                self.reporter.display(\n                    cell_range=None, level=self.settings.perfreports.level\n                )\n\n    def show_resources(self) -&gt; None:\n        \"\"\"Display available hardware resources.\n\n        Prints information about CPUs, memory, and GPUs available to the\n        current or imported session.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.show_resources()\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        if self.monitor.is_imported:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_RESOURCES].format(\n                    source=self.monitor.session_source\n                )\n            )\n        print(\"[JUmPER]:\")\n        cpu_info = (\n            f\"  CPUs: {self.monitor.num_cpus}\\n    \"\n            f\"CPU affinity: {self.monitor.cpu_handles}\"\n        )\n        print(cpu_info)\n        mem_gpu_info = (\n            f\"  Memory: {self.monitor.memory_limits['system']} GB\\n  \"\n            f\"GPUs: {self.monitor.num_gpus}\"\n        )\n        print(mem_gpu_info)\n        if self.monitor.num_gpus:\n            print(f\"    {self.monitor.gpu_name}, {self.monitor.gpu_memory} GB\")\n\n    def show_cell_history(self) -&gt; None:\n        \"\"\"Show an interactive table of executed cells.\n\n        Displays the tracked cell history using an interactive table\n        widget, if available.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.show_cell_history()\n        \"\"\"\n        self.cell_history.show_itable()\n\n    def start_monitoring(\n        self,\n        interval: Optional[float] = None,\n    ) -&gt; Optional[ExtensionErrorCode]:\n        \"\"\"Start performance monitoring.\n\n        This method configures and starts the underlying performance\n        monitor. If an offline (imported) session is currently\n        attached, it is replaced with a new live monitor instance.\n\n        Args:\n            interval: Sampling interval in seconds. If ``None``, the\n                value from ``settings.monitoring.default_interval`` is\n                used.\n\n        Returns:\n            Optional[ExtensionErrorCode]: An error code if monitoring\n            was already running, otherwise ``None``.\n\n        Examples:\n            Start monitoring with the default interval::\n\n                service.start_monitoring()\n\n            Start monitoring with a custom interval::\n\n                service.start_monitoring(interval=0.5)\n        \"\"\"\n        # If an imported (offline) session is currently attached, swap to a live monitor\n        if self.monitor.is_imported:\n            self.monitor = PerformanceMonitor()\n\n        if self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.MONITOR_ALREADY_RUNNING]\n            )\n            return ExtensionErrorCode.MONITOR_ALREADY_RUNNING\n\n        if interval is None:\n            interval = self.settings.monitoring.default_interval\n        else:\n            self.settings.monitoring.user_interval = interval\n\n        self.monitor.start(interval)\n        self.settings.monitoring.running = self.monitor.running\n        self.visualizer.attach(self.monitor)\n        self.reporter.attach(self.monitor)\n        return None\n\n    def stop_monitoring(self) -&gt; None:\n        \"\"\"Stop the active performance monitoring session.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.stop_monitoring()\n        \"\"\"\n        if not self.monitor:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        self.monitor.stop()\n        self.settings.monitoring.running = False\n\n    def plot_performance(\n        self,\n        metrics: Optional[List[str]] = None,\n        cell_range: Optional[Tuple[int, int]] = None,\n        level: Optional[str] = None,\n        save_jpeg: Optional[str] = None,\n        pickle_file: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Open an interactive performance plot.\n\n        Works for both live and imported sessions. Uses the attached\n        visualizer to display metrics and interactive widgets. When\n        ``level`` is provided (or inferred for exports), the plot is\n        rendered directly without ipywidgets, which also enables JPEG\n        and pickle exports.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.plot_performance()\n            &gt;&gt;&gt; service.plot_performance(\n            ...     metrics=[\"cpu_summary\", \"memory\"],\n            ...     level=\"process\",\n            ...     cell_range=(0, 3),\n            ... )\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n        if self.monitor.is_imported:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_PLOT].format(\n                    source=self.monitor.session_source\n                )\n            )\n\n        effective_level = level\n\n        if effective_level is None and (\n            metrics or save_jpeg or pickle_file\n        ):\n            # Default to configured level for direct plotting/export paths\n            effective_level = self.settings.perfreports.level\n\n        if effective_level is not None:\n            available_levels = get_available_levels()\n            if effective_level not in available_levels:\n                logger.warning(\n                    EXTENSION_ERROR_MESSAGES[\n                        ExtensionErrorCode.INVALID_LEVEL\n                    ].format(level=effective_level, levels=available_levels)\n                )\n                return\n\n        self.visualizer.plot(\n            metric_subsets=metrics,\n            cell_range=cell_range,\n            level=effective_level,\n            save_jpeg=save_jpeg,\n            pickle_file=pickle_file,\n        )\n\n    def enable_perfreports(\n        self,\n        level: str,\n        interval: Optional[float] = None,\n        text: bool = False\n    ) -&gt; None:\n        \"\"\"Enable automatic performance reports after each cell.\n\n        Args:\n            level: Monitoring level (``\\\"process\\\"``, ``\\\"user\\\"``,\n                ``\\\"system\\\"``, or ``\\\"slurm\\\"``).\n            interval: Sampling interval in seconds. If provided, this\n                value is used when starting monitoring.\n            text: If ``True``, use plain-text reports instead of HTML.\n\n        Returns:\n            None\n\n        Examples:\n            Enable HTML reports at process level::\n\n                service.enable_perfreports(level=\"process\")\n\n            Enable text reports with a custom interval::\n\n                service.enable_perfreports(\n                    level=\"user\",\n                    interval=0.5,\n                    text=True,\n                )\n        \"\"\"\n        self.settings.perfreports.enabled = True\n        self.settings.perfreports.level = level\n        self.settings.perfreports.text = text\n\n        format_message = \"text\" if text else \"html\"\n        options_message = f\"level: {level}, interval: {interval}, format: {format_message}\"\n\n        error_code = self.start_monitoring(interval)\n\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_REPORTS_ENABLED\n            ].format(\n                options_message=options_message,\n            )\n        )\n\n    def disable_perfreports(self) -&gt; None:\n        \"\"\"Disable automatic performance reports after cell execution.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.disable_perfreports()\n        \"\"\"\n        self.settings.perfreports.enabled = False\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.PERFORMANCE_REPORTS_DISABLED\n            ]\n        )\n\n    def show_perfreport(\n        self,\n        cell_range: Optional[Tuple[int, int]] = None,\n        level: Optional[str] = None,\n        text: bool = False\n    ) -&gt; None:\n        \"\"\"Show a performance report for the current session.\n\n        Args:\n            cell_range: Optional tuple ``(start_idx, end_idx)`` limiting\n                the report to a subset of cells. If ``None``, all cells\n                are included.\n            level: Optional monitoring level override. If ``None``,\n                the default report level is used.\n            text: If ``True``, render a text report instead of HTML.\n\n        Returns:\n            None\n\n        Examples:\n            Show a report for all cells::\n\n                service.show_perfreport()\n\n            Show a report for cells 2 through 5 at system level::\n\n                service.show_perfreport(\n                    cell_range=(2, 5),\n                    level=\"system\",\n                )\n        \"\"\"\n        if not self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return\n\n        if text:\n            self.reporter.print(cell_range=cell_range, level=level)\n        else:\n            self.reporter.display(cell_range=cell_range, level=level)\n\n    def export_perfdata(\n        self,\n        file: Optional[str] = None,\n        level: Optional[str] = None,\n        name: Optional[str] = None\n    ) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Export performance data or return it as data frames.\n\n        Args:\n            file: Optional target file path. If provided, data is\n                written using the monitor's data adapter. If ``None``,\n                data is returned as a mapping of variable name to\n                ``pandas.DataFrame``.\n            level: Optional monitoring level override. If ``None``,\n                the default export level is used.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n            ``None``, a mapping from variable name to data frame. If\n            ``file`` is set, an empty dictionary.\n\n        Examples:\n            Export metrics to a CSV file::\n\n                service.export_perfdata(\n                    file=\"performance.csv\",\n                    level=\"process\",\n                )\n\n            Get a DataFrame in memory::\n\n                frames = service.export_perfdata()\n                df = next(iter(frames.values()))\n        \"\"\"\n        if not self.monitor.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return {}\n\n        if file:\n            self.monitor.data.export(\n                file, level=level, cell_history=self.cell_history\n            )\n            return {}\n        else:\n            df = self.monitor.data.view(\n                level=level, cell_history=self.cell_history\n            )\n            var_name = name or self.settings.export_vars.perfdata\n            logger.info(\n                EXTENSION_INFO_MESSAGES[\n                    ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n                ].format(var_name=var_name)\n            )\n            return {var_name: df}\n\n    def load_perfdata(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Load performance data from a file.\n\n        Args:\n            file: Path to a CSV or JSON file containing performance\n                data.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n            configured variable name to the loaded data frame.\n\n        Examples:\n            &gt;&gt;&gt; frames = service.load_perfdata(\"performance.csv\")\n            &gt;&gt;&gt; df = next(iter(frames.values()))\n        \"\"\"\n        df = self.monitor.data.load(file)\n        var_name = self.settings.loaded_vars.perfdata\n        if df is not None:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[\n                    ExtensionInfoCode.PERFORMANCE_DATA_AVAILABLE\n                ].format(var_name=var_name)\n            )\n        return {var_name: df}\n\n    def export_cell_history(\n        self,\n        file: Optional[str] = None,\n        name: Optional[str] = None\n    ) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Export cell history or return it as a data frame.\n\n        Args:\n            file: Optional target file path. If provided, the cell\n                history is written to disk. If ``None``, data is\n                returned as a mapping of variable name to\n                ``pandas.DataFrame``.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: If ``file`` is\n            ``None``, a mapping from variable name to data frame. If\n            ``file`` is set, an empty dictionary.\n\n        Examples:\n            Export cell history to CSV::\n\n                service.export_cell_history(file=\"cells.csv\")\n\n            Get the history as a DataFrame::\n\n                frames = service.export_cell_history()\n                df = next(iter(frames.values()))\n        \"\"\"\n        if file:\n            self.cell_history.export(file)\n            return {}\n        else:\n            df = self.cell_history.view()\n            var_name = name or self.settings.export_vars.cell_history\n            logger.info(\n                f\"[JUmPER]: Cell history data available as '{var_name}'\"\n            )\n            return {var_name: df}\n\n    def load_cell_history(self, file: str) -&gt; Optional[Dict[str, pd.DataFrame]]:\n        \"\"\"Load cell history from a file.\n\n        Args:\n            file: Path to a CSV or JSON file containing cell history.\n\n        Returns:\n            Optional[Dict[str, pandas.DataFrame]]: Mapping from the\n            configured variable name to the loaded data frame.\n\n        Examples:\n            &gt;&gt;&gt; frames = service.load_cell_history(\"cells.csv\")\n            &gt;&gt;&gt; df = next(iter(frames.values()))\n        \"\"\"\n        df = self.cell_history.load(file)\n        var_name = self.settings.loaded_vars.cell_history\n        if df is not None:\n            logger.info(\n                f\"[JUmPER]: Cell history data available as '{var_name}'\"\n            )\n        return {var_name: df}\n\n    def export_session(self, path: Optional[str] = None) -&gt; None:\n        \"\"\"Export the full monitoring session.\n\n        This uses :class:`SessionExporter` to write performance data\n        and cell history to a directory or zip archive.\n\n        Args:\n            path: Optional target directory or ``.zip`` file. If the\n                path ends with ``.zip``, a temporary directory is used\n                and then compressed into that archive. If ``None``, a\n                timestamped directory is created.\n\n        Returns:\n            None\n\n        Examples:\n            Export to a directory::\n\n                service.export_session(\"session-dir\")\n\n            Export to a zip archive::\n\n                service.export_session(\"session.zip\")\n        \"\"\"\n        if not self.monitor.running and not self.monitor.is_imported:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n        exporter = SessionExporter(self.monitor, self.cell_history, self.visualizer, self.reporter, logger)\n        exporter.export(path)\n\n    def import_session(self, path: str) -&gt; None:\n        \"\"\"Import a monitoring session from disk.\n\n        Uses :class:`SessionImporter` to attach performance data and\n        cell history from the given directory or zip archive.\n\n        Args:\n            path: Directory or ``.zip`` archive previously created by\n                :meth:`export_session`.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.import_session(\"session.zip\")\n        \"\"\"\n        importer = SessionImporter(logger)\n        ok = importer.import_(path, self)\n        if ok:\n            logger.info(\n                EXTENSION_INFO_MESSAGES[ExtensionInfoCode.SESSION_IMPORTED].format(\n                    source=self.monitor.session_source\n                )\n            )\n\n    def fast_setup(self) -&gt; None:\n        \"\"\"Quickly start monitoring with per-cell reports enabled.\n\n        This convenience helper starts monitoring with a one-second\n        interval and enables HTML performance reports at the ``process``\n        level.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.fast_setup()\n        \"\"\"\n        self.start_monitoring(1.0)\n        self.enable_perfreports(level=\"process\", interval=1.0, text=False)\n        logger.info(\"[JUmPER]: Fast setup complete! Ready for interactive analysis.\")\n\n    def start_script_recording(self, output_path: Optional[str] = None) -&gt; None:\n        \"\"\"Start recording code from cells to a Python script.\n\n        Args:\n            output_path: Optional path to the output script file. If\n                ``None``, a filename is generated automatically.\n\n        Returns:\n            None\n\n        Examples:\n            Start recording to an auto-generated file::\n\n                service.start_script_recording()\n\n            Record to a specific script path::\n\n                service.start_script_recording(\"analysis_script.py\")\n        \"\"\"\n        self.script_writer.start_recording(self.settings.snapshot(), output_path)\n\n        if output_path:\n            logger.info(f\"[JUmPER]: Started script recording to '{output_path}'\")\n        else:\n            logger.info(\"[JUmPER]: Started script recording (filename will be auto-generated)\")\n\n    def stop_script_recording(self) -&gt; Optional[str]:\n        \"\"\"Stop recording and save accumulated code to a script file.\n\n        Returns:\n            Optional[str]: Path to the saved script file, or ``None``\n            if recording was not active or no cells were captured.\n\n        Examples:\n            &gt;&gt;&gt; path = service.stop_script_recording()\n            &gt;&gt;&gt; print(path)\n        \"\"\"\n        if not self.script_writer:\n            print(\"No script recording in progress.\")\n            return None\n\n        output_path = self.script_writer.stop_recording()\n        logger.info(f\"Script saved to: {output_path}\")\n        return output_path\n\n    @contextmanager\n    def monitored(self) -&gt; \"Iterator[PerfmonitorService]\":\n        \"\"\"Context manager for monitoring a code block.\n\n        This helper simulates a virtual cell: it registers a synthetic\n        cell before the block and finalizes it afterwards so that the\n        enclosed code is tracked like any other cell.\n\n        Yields:\n            PerfmonitorService: The current service instance, for\n            optional use inside the context.\n\n        Examples:\n            Use the service as a monitoring context::\n\n                with service.monitored():\n                    do_expensive_work()\n        \"\"\"\n        unavailable_message = \"unavailable on monitored context\"\n        self.on_pre_run_cell(\n            raw_cell=f\"# &lt;Code {unavailable_message}&gt;\",\n            cell_magics=[f\"&lt;Magics {unavailable_message}&gt;\"],\n            should_skip_report=False\n        )\n        try:\n            yield self\n        finally:\n            self.on_post_run_cell(None)\n\n    def close(self) -&gt; None:\n        \"\"\"Stop monitoring and release resources held by the service.\n\n        Returns:\n            None\n\n        Examples:\n            &gt;&gt;&gt; service.close()\n        \"\"\"\n        if self.monitor:\n            self.monitor.stop()\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.show_resources","title":"<code>show_resources()</code>","text":"<p>Display available hardware resources.</p> <p>Prints information about CPUs, memory, and GPUs available to the current or imported session.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; service.show_resources()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def show_resources(self) -&gt; None:\n    \"\"\"Display available hardware resources.\n\n    Prints information about CPUs, memory, and GPUs available to the\n    current or imported session.\n\n    Returns:\n        None\n\n    Examples:\n        &gt;&gt;&gt; service.show_resources()\n    \"\"\"\n    if not self.monitor.running and not self.monitor.is_imported:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n        )\n        return\n    if self.monitor.is_imported:\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.IMPORTED_SESSION_RESOURCES].format(\n                source=self.monitor.session_source\n            )\n        )\n    print(\"[JUmPER]:\")\n    cpu_info = (\n        f\"  CPUs: {self.monitor.num_cpus}\\n    \"\n        f\"CPU affinity: {self.monitor.cpu_handles}\"\n    )\n    print(cpu_info)\n    mem_gpu_info = (\n        f\"  Memory: {self.monitor.memory_limits['system']} GB\\n  \"\n        f\"GPUs: {self.monitor.num_gpus}\"\n    )\n    print(mem_gpu_info)\n    if self.monitor.num_gpus:\n        print(f\"    {self.monitor.gpu_name}, {self.monitor.gpu_memory} GB\")\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.show_cell_history","title":"<code>show_cell_history()</code>","text":"<p>Show an interactive table of executed cells.</p> <p>Displays the tracked cell history using an interactive table widget, if available.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; service.show_cell_history()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def show_cell_history(self) -&gt; None:\n    \"\"\"Show an interactive table of executed cells.\n\n    Displays the tracked cell history using an interactive table\n    widget, if available.\n\n    Returns:\n        None\n\n    Examples:\n        &gt;&gt;&gt; service.show_cell_history()\n    \"\"\"\n    self.cell_history.show_itable()\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.export_session","title":"<code>export_session(path=None)</code>","text":"<p>Export the full monitoring session.</p> <p>This uses :class:<code>SessionExporter</code> to write performance data and cell history to a directory or zip archive.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[str]</code> <p>Optional target directory or <code>.zip</code> file. If the path ends with <code>.zip</code>, a temporary directory is used and then compressed into that archive. If <code>None</code>, a timestamped directory is created.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <p>Export to a directory::</p> <pre><code>service.export_session(\"session-dir\")\n</code></pre> <p>Export to a zip archive::</p> <pre><code>service.export_session(\"session.zip\")\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def export_session(self, path: Optional[str] = None) -&gt; None:\n    \"\"\"Export the full monitoring session.\n\n    This uses :class:`SessionExporter` to write performance data\n    and cell history to a directory or zip archive.\n\n    Args:\n        path: Optional target directory or ``.zip`` file. If the\n            path ends with ``.zip``, a temporary directory is used\n            and then compressed into that archive. If ``None``, a\n            timestamped directory is created.\n\n    Returns:\n        None\n\n    Examples:\n        Export to a directory::\n\n            service.export_session(\"session-dir\")\n\n        Export to a zip archive::\n\n            service.export_session(\"session.zip\")\n    \"\"\"\n    if not self.monitor.running and not self.monitor.is_imported:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n        )\n    exporter = SessionExporter(self.monitor, self.cell_history, self.visualizer, self.reporter, logger)\n    exporter.export(path)\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.import_session","title":"<code>import_session(path)</code>","text":"<p>Import a monitoring session from disk.</p> <p>Uses :class:<code>SessionImporter</code> to attach performance data and cell history from the given directory or zip archive.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Directory or <code>.zip</code> archive previously created by :meth:<code>export_session</code>.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; service.import_session(\"session.zip\")\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def import_session(self, path: str) -&gt; None:\n    \"\"\"Import a monitoring session from disk.\n\n    Uses :class:`SessionImporter` to attach performance data and\n    cell history from the given directory or zip archive.\n\n    Args:\n        path: Directory or ``.zip`` archive previously created by\n            :meth:`export_session`.\n\n    Returns:\n        None\n\n    Examples:\n        &gt;&gt;&gt; service.import_session(\"session.zip\")\n    \"\"\"\n    importer = SessionImporter(logger)\n    ok = importer.import_(path, self)\n    if ok:\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.SESSION_IMPORTED].format(\n                source=self.monitor.session_source\n            )\n        )\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.fast_setup","title":"<code>fast_setup()</code>","text":"<p>Quickly start monitoring with per-cell reports enabled.</p> <p>This convenience helper starts monitoring with a one-second interval and enables HTML performance reports at the <code>process</code> level.</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; service.fast_setup()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def fast_setup(self) -&gt; None:\n    \"\"\"Quickly start monitoring with per-cell reports enabled.\n\n    This convenience helper starts monitoring with a one-second\n    interval and enables HTML performance reports at the ``process``\n    level.\n\n    Returns:\n        None\n\n    Examples:\n        &gt;&gt;&gt; service.fast_setup()\n    \"\"\"\n    self.start_monitoring(1.0)\n    self.enable_perfreports(level=\"process\", interval=1.0, text=False)\n    logger.info(\"[JUmPER]: Fast setup complete! Ready for interactive analysis.\")\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.start_script_recording","title":"<code>start_script_recording(output_path=None)</code>","text":"<p>Start recording code from cells to a Python script.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>Optional[str]</code> <p>Optional path to the output script file. If <code>None</code>, a filename is generated automatically.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Examples:</p> <p>Start recording to an auto-generated file::</p> <pre><code>service.start_script_recording()\n</code></pre> <p>Record to a specific script path::</p> <pre><code>service.start_script_recording(\"analysis_script.py\")\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def start_script_recording(self, output_path: Optional[str] = None) -&gt; None:\n    \"\"\"Start recording code from cells to a Python script.\n\n    Args:\n        output_path: Optional path to the output script file. If\n            ``None``, a filename is generated automatically.\n\n    Returns:\n        None\n\n    Examples:\n        Start recording to an auto-generated file::\n\n            service.start_script_recording()\n\n        Record to a specific script path::\n\n            service.start_script_recording(\"analysis_script.py\")\n    \"\"\"\n    self.script_writer.start_recording(self.settings.snapshot(), output_path)\n\n    if output_path:\n        logger.info(f\"[JUmPER]: Started script recording to '{output_path}'\")\n    else:\n        logger.info(\"[JUmPER]: Started script recording (filename will be auto-generated)\")\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.stop_script_recording","title":"<code>stop_script_recording()</code>","text":"<p>Stop recording and save accumulated code to a script file.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Optional[str]: Path to the saved script file, or <code>None</code></p> <code>Optional[str]</code> <p>if recording was not active or no cells were captured.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; path = service.stop_script_recording()\n&gt;&gt;&gt; print(path)\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def stop_script_recording(self) -&gt; Optional[str]:\n    \"\"\"Stop recording and save accumulated code to a script file.\n\n    Returns:\n        Optional[str]: Path to the saved script file, or ``None``\n        if recording was not active or no cells were captured.\n\n    Examples:\n        &gt;&gt;&gt; path = service.stop_script_recording()\n        &gt;&gt;&gt; print(path)\n    \"\"\"\n    if not self.script_writer:\n        print(\"No script recording in progress.\")\n        return None\n\n    output_path = self.script_writer.stop_recording()\n    logger.info(f\"Script saved to: {output_path}\")\n    return output_path\n</code></pre>"},{"location":"api/python/#jumper_extension.core.service.PerfmonitorService.monitored","title":"<code>monitored()</code>","text":"<p>Context manager for monitoring a code block.</p> <p>This helper simulates a virtual cell: it registers a synthetic cell before the block and finalizes it afterwards so that the enclosed code is tracked like any other cell.</p> <p>Yields:</p> Name Type Description <code>PerfmonitorService</code> <code>PerfmonitorService</code> <p>The current service instance, for</p> <code>PerfmonitorService</code> <p>optional use inside the context.</p> <p>Examples:</p> <p>Use the service as a monitoring context::</p> <pre><code>with service.monitored():\n    do_expensive_work()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>@contextmanager\ndef monitored(self) -&gt; \"Iterator[PerfmonitorService]\":\n    \"\"\"Context manager for monitoring a code block.\n\n    This helper simulates a virtual cell: it registers a synthetic\n    cell before the block and finalizes it afterwards so that the\n    enclosed code is tracked like any other cell.\n\n    Yields:\n        PerfmonitorService: The current service instance, for\n        optional use inside the context.\n\n    Examples:\n        Use the service as a monitoring context::\n\n            with service.monitored():\n                do_expensive_work()\n    \"\"\"\n    unavailable_message = \"unavailable on monitored context\"\n    self.on_pre_run_cell(\n        raw_cell=f\"# &lt;Code {unavailable_message}&gt;\",\n        cell_magics=[f\"&lt;Magics {unavailable_message}&gt;\"],\n        should_skip_report=False\n    )\n    try:\n        yield self\n    finally:\n        self.on_post_run_cell(None)\n</code></pre>"},{"location":"api/string/","title":"String Based API","text":"<p>The string\u2011based API is implemented by <code>PerfmonitorMagicAdapter</code> in <code>jumper_extension.core.service</code>. It provides a thin layer that:</p> <ul> <li>Accepts command\u2011line style strings (as used by IPython magics).</li> <li>Parses arguments using <code>ArgParsers</code> built from the core parser utilities.</li> <li>Delegates the resulting structured options to methods on <code>PerfmonitorService</code>.</li> </ul> <p>This layer is also used by the notebook script writer when generating reproducible monitoring scripts.</p>"},{"location":"api/string/#role-in-the-public-api","title":"Role in the public API","text":"<p>At runtime, the flow of a typical command is:</p> <ol> <li>IPython calls the appropriate method on <code>PerfmonitorMagics</code> (for example <code>perfmonitor_perfreport</code>).</li> <li><code>PerfmonitorMagics</code> forwards the raw <code>line</code> string to the corresponding method on <code>PerfmonitorMagicAdapter</code>.</li> <li><code>PerfmonitorMagicAdapter</code> parses the string with the relevant parser (for example <code>parsers.perfreport</code>) and calls the corresponding method on <code>PerfmonitorService</code>.</li> </ol> <p>This design keeps the parsing and text handling logic separate from the core monitoring and analysis code.</p>"},{"location":"api/string/#example-usage","title":"Example usage","text":"<p>While you typically interact with the string\u2011based API indirectly through magics, you can also construct it directly:</p> <pre><code>from jumper_extension.core.service import build_perfmonitor_magic_adapter\n\nadapter = build_perfmonitor_magic_adapter()\nadapter.perfmonitor_start(\"1.0\")\nadapter.perfmonitor_perfreport(\"--cell 2:5 --level user\")\nadapter.perfmonitor_export_perfdata(\"--file perf.csv --level system\")\n</code></pre> <p>The commands are identical to the magic syntax but passed as plain strings. This is the same interface that <code>NotebookScriptWriter</code> relies on when emitting code for <code>monitored_script.py</code>.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This extension is distributed as a standard Python package and can be installed from PyPI or from source.</p>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<p>Install the latest released version into your current environment:</p> <pre><code>pip install jumper_extension\n</code></pre> <p>This installs the IPython extension, its monitoring dependencies, and the entry point that allows <code>%load_ext jumper_extension</code> to work inside IPython and Jupyter.</p>"},{"location":"getting-started/installation/#install-from-source","title":"Install from source","text":"<p>If you are working from a clone of the repository or want the very latest changes, install the package from the project root:</p> <pre><code>pip install .\n</code></pre> <p>This builds and installs the local copy of <code>jumper_extension</code> into your active environment.</p>"},{"location":"getting-started/installation/#optional-gpu-support","title":"Optional GPU support","text":"<p>JUmPER can collect GPU metrics for both NVIDIA and AMD GPUs. GPU support is optional; CPU and memory monitoring work without it.</p> <p>For NVIDIA GPUs, install:</p> <pre><code>pip install pynvml\n</code></pre> <p>For AMD GPUs, install:</p> <pre><code>pip install ADLXPybind\n</code></pre> <p>Both GPU libraries can be installed at the same time to monitor mixed GPU systems. JUmPER will automatically detect which backends are available.</p>"},{"location":"getting-started/installation/#environment-configuration","title":"Environment configuration","text":"<p>JUmPER writes logs to a configurable directory. To change the default location, set the <code>JUMPER_LOG_DIR</code> environment variable before starting your notebook or IPython session:</p> <pre><code>export JUMPER_LOG_DIR=/path/to/logs\n</code></pre> <p>If this variable is not set, logs are stored in a directory under the user\u2019s home folder.</p>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>This quickstart shows how to enable the JUmPER IPython extension in a notebook, start monitoring, and inspect basic performance data for a few cells.</p> <p>All examples below assume that <code>jumper_extension</code> has been installed as described in the Installation section.</p>"},{"location":"getting-started/quickstart/#enable-the-extension","title":"Enable the extension","text":"<p>In a Jupyter notebook or IPython shell, load the extension once per session:</p> <pre><code>%load_ext jumper_extension\n</code></pre> <p>This registers the <code>%perfmonitor_*</code> magic commands and wires them into the underlying monitoring service.</p>"},{"location":"getting-started/quickstart/#minimal-monitoring-workflow","title":"Minimal monitoring workflow","text":""},{"location":"getting-started/quickstart/#1-start-monitoring","title":"1. Start monitoring","text":"<p>Begin collecting performance data for subsequent cells:</p> <pre><code>%perfmonitor_start [interval]\n</code></pre> <ul> <li><code>interval</code> is optional and specifies how often metrics are sampled in seconds.</li> <li>If omitted, the default interval of <code>1</code> second is used.</li> </ul>"},{"location":"getting-started/quickstart/#2-run-your-code","title":"2. Run your code","text":"<p>Execute the cells you want to profile as usual. While monitoring is active, JUmPER records CPU, memory, GPU, and I/O metrics over time.</p>"},{"location":"getting-started/quickstart/#3-view-a-performance-report","title":"3. View a performance report","text":"<p>Show an aggregate report for the current session:</p> <pre><code>%perfmonitor_perfreport\n%perfmonitor_perfreport --cell 2:5 --level user\n</code></pre> <ul> <li>Without arguments, the report covers all cells executed so far.</li> <li><code>--cell RANGE</code> restricts the analysis to specific cells (for example <code>5</code>, <code>2:8</code>, <code>:5</code>, or <code>3:</code>).</li> <li><code>--level LEVEL</code> selects the monitoring scope: <code>process</code>, <code>user</code>, <code>system</code>, or <code>slurm</code> (if available).</li> </ul> <p>The report prints aggregated metrics such as CPU utilization, memory usage, GPU utilization, and GPU memory across the selected range.</p>"},{"location":"getting-started/quickstart/#4-plot-performance-data","title":"4. Plot performance data","text":"<p>Open an interactive plot with widgets for exploring metrics over time:</p> <pre><code>%perfmonitor_plot\n</code></pre> <p>The plot lets you:</p> <ul> <li>Zoom into interesting regions of the timeline.</li> <li>Filter by cell ranges.</li> <li>Switch between monitoring levels.</li> </ul> <p>You can also use a direct, non-widget mode and export results:</p> <pre><code>%perfmonitor_plot --metrics cpu_summary,memory\n%perfmonitor_plot --metrics cpu_summary --level user --cell 2:5\n%perfmonitor_plot --metrics cpu_summary,memory --save-jpeg performance_analysis.jpg\n%perfmonitor_plot --metrics cpu_summary --level user --pickle analysis_data.pkl\n</code></pre> <ul> <li><code>--metrics</code> accepts a comma\u2011separated list of metric keys such as <code>cpu_summary</code>, <code>memory</code>, <code>io_read</code>, <code>io_write</code>, <code>gpu_util_summary</code>, <code>gpu_band_summary</code>, and <code>gpu_mem_summary</code>.</li> <li><code>--save-jpeg</code> writes the current view to an image file.</li> <li><code>--pickle</code> exports the plot data for later interactive analysis.</li> </ul>"},{"location":"getting-started/quickstart/#5-inspect-cell-execution-history","title":"5. Inspect cell execution history","text":"<p>Review all executed cells with their timestamps and durations:</p> <pre><code>%cell_history\n</code></pre> <p>This opens an interactive table that lets you correlate individual cells with collected performance metrics.</p>"},{"location":"getting-started/quickstart/#6-stop-monitoring","title":"6. Stop monitoring","text":"<p>When you are done collecting data, stop the monitor:</p> <pre><code>%perfmonitor_stop\n</code></pre>"},{"location":"getting-started/quickstart/#onecommand-fast-setup","title":"One\u2011command fast setup","text":"<p>For a fully configured environment with interactive plotting and automatic reports, use the fast setup command:</p> <pre><code>%perfmonitor_fast_setup\n</code></pre> <p>This command:</p> <ul> <li>Enables <code>ipympl</code>\u2011based interactive plots in the current notebook.</li> <li>Starts the performance monitor with a <code>1.0</code> second interval.</li> <li>Enables automatic performance reports after each cell at the <code>process</code> level.</li> </ul> <p>For detailed options and additional commands, see the Public API section.</p>"},{"location":"guides/plot-export/","title":"Pickle and Restore Plots","text":"<p>This guide will cover saving plots or visualizer state and restoring it later for review.</p> PresentationVideo <p> </p> <p> </p>"},{"location":"guides/script-export/","title":"Record a Notebook to a Script","text":"<p>This guide will walk through recording cells to a Python script and running that script on another machine.</p> PresentationVideo <p> </p> <p> </p>"},{"location":"guides/session-transfer/","title":"Transfer Sessions Between Machines","text":"<p>This guide will show how to export a monitoring session and import it on another system for offline analysis.</p> PresentationVideo <p> </p> <p> </p>"},{"location":"internals/adapters/","title":"Adapters","text":"<p>This page documents the adapter modules under <code>jumper_extension.adapters</code> that implement monitoring, reporting, visualization, session management, and script writing. High\u2011level usage is described in the Public API and Jupyter API sections; the content below is generated directly from the Python code.</p>"},{"location":"internals/adapters/#monitor-and-data","title":"Monitor and data","text":""},{"location":"internals/adapters/#jumper_extension.adapters.monitor.MonitorUnavailableError","title":"<code>MonitorUnavailableError</code>","text":"<p>               Bases: <code>RuntimeError</code></p> <p>This monitor is a stub and cannot be used.</p> Source code in <code>jumper_extension/adapters/monitor.py</code> <pre><code>class MonitorUnavailableError(RuntimeError):\n    \"\"\"This monitor is a stub and cannot be used.\"\"\"\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.monitor.OfflinePerformanceMonitor","title":"<code>OfflinePerformanceMonitor</code>","text":"<p>Offline monitor that satisfies PerformanceMonitorProtocol.</p> <p>It holds static data frames plus metadata from a manifest; does not collect live data.</p> Source code in <code>jumper_extension/adapters/monitor.py</code> <pre><code>class OfflinePerformanceMonitor:\n    \"\"\"Offline monitor that satisfies PerformanceMonitorProtocol.\n\n    It holds static data frames plus metadata from a manifest; does not collect live data.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        manifest: Dict,\n        perf_dfs: Dict[str, pd.DataFrame],\n        source: Optional[str] = None,\n    ):\n        monitor_info = manifest.get(\"monitor\", {})\n\n        # Protocol surface\n        self.interval = float(monitor_info.get(\"interval\", 1.0) or 1.0)\n        self.running = False\n        self.start_time = monitor_info.get(\"start_time\")\n        self.stop_time = monitor_info.get(\"stop_time\")\n\n        # Hardware/context\n        self.num_cpus = int(monitor_info.get(\"num_cpus\", 0) or 0)\n        self.num_system_cpus = int(monitor_info.get(\"num_system_cpus\", self.num_cpus) or self.num_cpus)\n        self.num_gpus = int(monitor_info.get(\"num_gpus\", 0) or 0)\n        self.gpu_memory = float(monitor_info.get(\"gpu_memory\", 0.0) or 0.0)\n        self.gpu_name = monitor_info.get(\"gpu_name\", \"\") or \"\"\n        self.cpu_handles = monitor_info.get(\"cpu_handles\", []) or []\n        self.memory_limits = monitor_info.get(\"memory_limits\", {}) or {}\n\n        # Performance data container\n        self.data = PerformanceData(\n            self.num_cpus,\n            self.num_system_cpus,\n            self.num_gpus,\n        )\n        for level, df in (perf_dfs or {}).items():\n            try:\n                self.data._validate_level(level)\n            except Exception:\n                pass\n            self.data.data[level] = df\n\n        # Imported session state\n        self.is_imported = True\n        self.session_source = source\n\n    # No-op lifecycle\n    def start(self, interval: float = 1.0) -&gt; None:\n        self.interval = interval\n        self.running = False\n\n    def stop(self) -&gt; None:\n        self.running = False\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.monitor.PerformanceMonitor","title":"<code>PerformanceMonitor</code>","text":"Source code in <code>jumper_extension/adapters/monitor.py</code> <pre><code>class PerformanceMonitor:\n    def __init__(self):\n        self.interval = 1.0\n        self.running = False\n        self.start_time = None\n        self.stop_time = None\n        self.monitor_thread = None\n        self.process = psutil.Process()\n        self.n_measurements = 0\n        self.n_missed_measurements = 0\n        \"\"\"\n        on MacOS cpu_affinity is not implemented in psutil \n        (raises AttributeError)\n        set the num_cpus to the number of cpus in the system\n        same for cpu_affinity\n        \"\"\"\n        try:\n            self.cpu_handles = self.process.cpu_affinity()\n            self.num_cpus = len(self.cpu_handles)\n        except AttributeError:\n            self.cpu_handles = []\n            self.num_cpus = len(psutil.cpu_percent(percpu=True))\n        self.num_system_cpus = len(psutil.cpu_percent(percpu=True))\n        self.pid = os.getpid()\n        self.uid = os.getuid()\n        self.slurm_job = os.environ.get(\"SLURM_JOB_ID\", 0)\n        self.levels = get_available_levels()\n        self.process_pids = []\n\n        self.memory_limits = {\n            level: detect_memory_limit(level, self.uid, self.slurm_job)\n            for level in self.levels\n        }\n\n        self.nvidia_gpu_handles = []\n        self.amd_gpu_handles = []\n        self.gpu_memory = 0\n        self.gpu_name = \"\"\n        if PYNVML_AVAILABLE:\n            self._setup_nvidia_gpu()\n        if ADLX_AVAILABLE:\n            self._setup_amd_gpu()\n        self.num_gpus = len(self.nvidia_gpu_handles) + len(\n            self.amd_gpu_handles\n        )\n\n        self.metrics = [\n            \"cpu\",\n            \"memory\",\n            \"io_read\",\n            \"io_write\",\n            \"io_read_count\",\n            \"io_write_count\",\n        ]\n\n        if self.num_gpus:\n            self.metrics.extend([\"gpu_util\", \"gpu_band\", \"gpu_mem\"])\n\n        self.data = PerformanceData(\n            self.num_cpus, self.num_system_cpus, self.num_gpus\n        )\n        # session state\n        self.is_imported = False\n        self.session_source = None\n\n    def _setup_nvidia_gpu(self):\n        try:\n            ngpus = pynvml.nvmlDeviceGetCount()\n            self.nvidia_gpu_handles = [\n                pynvml.nvmlDeviceGetHandleByIndex(i) for i in range(ngpus)\n            ]\n            if self.nvidia_gpu_handles:\n                handle = self.nvidia_gpu_handles[0]\n                gpu_mem = round(\n                    pynvml.nvmlDeviceGetMemoryInfo(handle).total / (1024**3), 2\n                )\n                if self.gpu_memory == 0:\n                    self.gpu_memory = gpu_mem\n                name = pynvml.nvmlDeviceGetName(handle)\n                gpu_name = name.decode() if isinstance(name, bytes) else name\n                if not self.gpu_name:\n                    self.gpu_name = gpu_name\n                else:\n                    self.gpu_name += f\", {gpu_name}\"\n        except Exception:\n            self.nvidia_gpu_handles = []\n\n    def _setup_amd_gpu(self):\n        try:\n            gpus_list = adlx_system.GetGPUs()\n            num_amd_gpus = gpus_list.Size()\n            self.amd_gpu_handles = [\n                gpus_list.At(i) for i in range(num_amd_gpus)\n            ]\n            if self.amd_gpu_handles:\n                gpu = self.amd_gpu_handles[0]\n                # Get memory info\n                gpu_mem_info = gpu.TotalVRAM()\n                gpu_mem = round(gpu_mem_info / (1024**3), 2)\n                if self.gpu_memory == 0:\n                    self.gpu_memory = gpu_mem\n                # Get GPU name\n                gpu_name = gpu.Name()\n                if not self.gpu_name:\n                    self.gpu_name = gpu_name\n                else:\n                    self.gpu_name += f\", {gpu_name}\"\n        except Exception:\n            self.amd_gpu_handles = []\n\n    def _get_process_pids(self):\n        \"\"\"Get current process PID and all its children PIDs\"\"\"\n        pids = {self.pid}\n        try:\n            pids.update(\n                child.pid for child in self.process.children(recursive=True)\n            )\n        except (psutil.NoSuchProcess, psutil.AccessDenied):\n            pass\n        return pids\n\n    def _validate_level(self, level):\n        if level not in self.levels:\n            raise ValueError(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.INVALID_LEVEL\n                ].format(level=level, levels=self.levels)\n            )\n\n    def _filter_process(self, proc, mode):\n        \"\"\"Check if process matches the filtering mode\"\"\"\n        try:\n            if mode == \"user\":\n                return proc.uids().real == self.uid\n            elif mode == \"slurm\":\n                if not is_slurm_available():\n                    return False\n                return proc.environ().get(\"SLURM_JOB_ID\") == str(\n                    self.slurm_job\n                )\n        except (psutil.AccessDenied, psutil.NoSuchProcess):\n            pass\n        return False\n\n    def _get_filtered_processes(self, level=\"user\", mode=\"cpu\", handle=None):\n        \"\"\"Get filtered processes for CPU or GPU monitoring\"\"\"\n        if mode == \"cpu\":\n            return [\n                proc\n                for proc in psutil.process_iter([\"pid\", \"uids\"])\n                if self._safe_proc_call(\n                    proc, lambda p: self._filter_process(p, level), False\n                )\n            ]\n        elif mode == \"nvidia_gpu\":\n            all_procs = pynvml.nvmlDeviceGetComputeRunningProcesses(handle)\n            filtered = [\n                p\n                for p in all_procs\n                if self._safe_proc_call(\n                    p.pid,\n                    lambda proc: self._filter_process(proc, level),\n                    False,\n                )\n            ]\n            return filtered, all_procs\n        else:\n            raise ValueError(f\"Unknown mode: {mode}\")\n\n    def _safe_proc_call(self, proc, proc_func, default=0):\n        \"\"\"Safely call a process method and return default on error\"\"\"\n        try:\n            if not isinstance(proc, psutil.Process):\n                # proc might be a pid. Moved Process creation here to catch\n                # exceptions at the same place\n                proc = psutil.Process(proc)\n            result = proc_func(proc)\n            return result if result is not None else default\n        except (psutil.NoSuchProcess, psutil.AccessDenied, AttributeError):\n            return default\n        except TypeError:\n            # in test case, where psutil is a mock\n            if isinstance(psutil.Process, unittest.mock.MagicMock):\n                return default\n\n    def _collect_cpu(self, level=\"process\"):\n        self._validate_level(level)\n        if level == \"system\":\n            # just return the whole system here\n            cpu_util_per_core = psutil.cpu_percent(percpu=True)\n            return cpu_util_per_core\n            # return [cpu_util_per_core[i] for i in self.cpu_handles]\n        elif level == \"process\":\n            # get process pids\n            pids = self.process_pids\n            cpu_total = sum(\n                self._safe_proc_call(\n                    pid, lambda p: p.cpu_percent(interval=0.1)\n                )\n                for pid in pids\n            )\n            return [cpu_total / self.num_cpus] * self.num_cpus\n        else:  # user or slurm\n            cpu_total = sum(\n                self._safe_proc_call(proc, lambda p: p.cpu_percent())\n                for proc in self._get_filtered_processes(level, \"cpu\")\n            )\n            return [cpu_total / self.num_cpus] * self.num_cpus\n\n    def _collect_memory(self, level=\"process\"):\n        self._validate_level(level)\n        if level == \"system\":\n            return (\n                psutil.virtual_memory().total\n                - psutil.virtual_memory().available\n            ) / (1024**3)\n        elif level == \"process\":\n            pids = self.process_pids\n            memory_total = sum(\n                self._safe_proc_call(pid, lambda p: p.memory_full_info().uss)\n                for pid in pids\n            )\n            return memory_total / (1024**3)\n        else:  # user or slurm\n            memory_total = sum(\n                self._safe_proc_call(\n                    proc, lambda p: p.memory_full_info().uss, 0\n                )\n                for proc in self._get_filtered_processes(level, \"cpu\")\n            )\n            return memory_total / (1024**3)\n\n    def _collect_io(self, level=\"process\"):\n        self._validate_level(level)\n        if level == \"process\":\n            pids = self.process_pids\n            totals = [0, 0, 0, 0]\n            for pid in pids:\n                io_data = self._safe_proc_call(pid, lambda p: p.io_counters())\n                if io_data:\n                    totals[0] += io_data.read_count\n                    totals[1] += io_data.write_count\n                    totals[2] += io_data.read_bytes\n                    totals[3] += io_data.write_bytes\n        elif level == \"system\":\n            totals = [0, 0, 0, 0]\n            for proc in psutil.process_iter([\"pid\"]):\n                io_data = self._safe_proc_call(proc, lambda p: p.io_counters())\n                if io_data:\n                    totals[0] += io_data.read_count\n                    totals[1] += io_data.write_count\n                    totals[2] += io_data.read_bytes\n                    totals[3] += io_data.write_bytes\n        else:  # user or slurm\n            totals = [0, 0, 0, 0]\n            for proc in self._get_filtered_processes(level, \"cpu\"):\n                io_data = self._safe_proc_call(proc, lambda p: p.io_counters())\n                if io_data:\n                    totals[0] += io_data.read_count\n                    totals[1] += io_data.write_count\n                    totals[2] += io_data.read_bytes\n                    totals[3] += io_data.write_bytes\n        return totals\n\n    def _collect_gpu(self, level=\"process\"):\n        if not (PYNVML_AVAILABLE or ADLX_AVAILABLE) or self.num_gpus == 0:\n            return [], [], []\n\n        self._validate_level(level)\n        gpu_util, gpu_band, gpu_mem = [], [], []\n\n        # Collect NVIDIA GPU metrics\n        if PYNVML_AVAILABLE and self.nvidia_gpu_handles:\n            nvidia_util, nvidia_band, nvidia_mem = self._collect_nvidia_gpu(\n                level\n            )\n            gpu_util.extend(nvidia_util)\n            gpu_band.extend(nvidia_band)\n            gpu_mem.extend(nvidia_mem)\n\n        # Collect AMD GPU metrics\n        if ADLX_AVAILABLE and self.amd_gpu_handles:\n            amd_util, amd_band, amd_mem = self._collect_amd_gpu(level)\n            gpu_util.extend(amd_util)\n            gpu_band.extend(amd_band)\n            gpu_mem.extend(amd_mem)\n\n        return gpu_util, gpu_band, gpu_mem\n\n    def _collect_nvidia_gpu(self, level=\"process\"):\n        \"\"\"Collect NVIDIA GPU metrics\"\"\"\n        gpu_util, gpu_band, gpu_mem = [], [], []\n\n        for handle in self.nvidia_gpu_handles:\n            try:\n                util_rates = pynvml.nvmlDeviceGetUtilizationRates(handle)\n            except pynvml.NVMLError:\n                # If permission denied or other error, use default values\n                class DefaultUtilRates:\n                    gpu = 0.0\n                    memory = 0.0\n                util_rates = DefaultUtilRates()\n\n            if level == \"system\":\n                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n                gpu_util.append(util_rates.gpu)\n                gpu_band.append(util_rates.memory)\n                gpu_mem.append(memory_info.used / (1024**3))\n            elif level == \"process\":\n                pids = self.process_pids\n                process_mem = sum(\n                    p.usedGpuMemory\n                    for p in pynvml.nvmlDeviceGetComputeRunningProcesses(\n                        handle\n                    )\n                    if p.pid in pids and p.usedGpuMemory\n                ) / (1024**3)\n                gpu_util.append(util_rates.gpu if process_mem &gt; 0 else 0.0)\n                gpu_band.append(0.0)\n                gpu_mem.append(process_mem)\n            else:  # user or slurm\n                filtered_gpu_processes, all_processes = (\n                    self._get_filtered_processes(level, \"nvidia_gpu\", handle)\n                )\n                filtered_mem = sum(\n                    p.usedGpuMemory\n                    for p in filtered_gpu_processes\n                    if p.usedGpuMemory\n                ) / (1024**3)\n                filtered_util = (\n                    (\n                        util_rates.gpu\n                        * len(filtered_gpu_processes)\n                        / max(len(all_processes), 1)\n                    )\n                    if filtered_gpu_processes\n                    else 0.0\n                )\n                gpu_util.append(filtered_util)\n                gpu_band.append(0.0)\n                gpu_mem.append(filtered_mem)\n\n        return gpu_util, gpu_band, gpu_mem\n\n    def _collect_amd_gpu(self, level=\"process\"):\n        \"\"\"Collect AMD GPU metrics\"\"\"\n        gpu_util, gpu_band, gpu_mem = [], [], []\n\n        for gpu_handle in self.amd_gpu_handles:\n            try:\n                # Get performance metrics interface\n                perf_monitoring = (\n                    adlx_system.GetPerformanceMonitoringServices()\n                )\n\n                # Get current metrics\n                current_metrics = perf_monitoring.GetCurrentPerformanceMetrics(\n                    gpu_handle\n                )\n\n                # Get GPU utilization\n                util = current_metrics.GPUUsage()\n\n                # Get memory info\n                mem_info = current_metrics.GPUVRAMUsage()\n\n                if level == \"system\":\n                    gpu_util.append(util)\n                    gpu_band.append(\n                        0.0\n                    )  # AMD ADLX doesn't provide memory bandwidth easily\n                    # Convert VRAM usage from MB to GB\n                    gpu_mem.append(mem_info / 1024.0)\n                elif level == \"process\":\n                    # AMD ADLX doesn't provide per-process metrics easily\n                    # For now, we'll report 0 for process-level\n                    gpu_util.append(0.0)\n                    gpu_band.append(0.0)\n                    gpu_mem.append(0.0)\n                else:  # user or slurm\n                    # AMD ADLX doesn't provide per-user metrics easily\n                    # For now, we'll report 0 for user/slurm level\n                    gpu_util.append(0.0)\n                    gpu_band.append(0.0)\n                    gpu_mem.append(0.0)\n            except Exception:\n                # If we can't get metrics, append zeros\n                gpu_util.append(0.0)\n                gpu_band.append(0.0)\n                gpu_mem.append(0.0)\n\n        return gpu_util, gpu_band, gpu_mem\n\n    def _collect_metrics(self):\n        time_mark = time.perf_counter()\n        return tuple(\n            (\n                time_mark,\n                self._collect_cpu(level),\n                self._collect_memory(level),\n                *self._collect_gpu(level),\n                self._collect_io(level),\n            )\n            for level in self.levels\n        )\n\n    def _collect_data(self):\n        while self.running:\n            time_start_measurement = time.perf_counter()\n            self.process_pids = self._get_process_pids()\n            metrics = self._collect_metrics()\n            for level, data_tuple in zip(self.levels, metrics):\n                self.data.add_sample(level, *data_tuple)\n            time_measurement = time.perf_counter() - time_start_measurement\n            self.n_measurements += 1\n            if time_measurement &gt; self.interval:\n                \"\"\"\n                logger.warning(\n                    EXTENSION_INFO_MESSAGES[\n                        ExtensionInfoCode.IMPRECISE_INTERVAL\n                    ].format(interval=self.interval),\n                    end=\"\\r\",\n                )\n                \"\"\"\n                self.n_missed_measurements += 1\n            else:\n                time.sleep(self.interval - time_measurement)\n\n    def start(self, interval: float = 1.0):\n        if self.running:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.MONITOR_ALREADY_RUNNING\n                ]\n            )\n            return\n        self.interval = interval\n        self.start_time = time.perf_counter()\n        self.running = True\n        self.monitor_thread = threading.Thread(\n            target=self._collect_data, daemon=True\n        )\n        self.monitor_thread.start()\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.MONITOR_STARTED].format(\n                pid=self.pid,\n                interval=self.interval,\n            )\n        )\n\n    def stop(self):\n        self.running = False\n        if self.monitor_thread:\n            self.monitor_thread.join(timeout=2.0)\n        self.stop_time = time.perf_counter()\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.MONITOR_STOPPED].format(\n                seconds=self.stop_time - self.start_time\n            )\n        )\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.MISSED_MEASUREMENTS].format(\n                perc_missed_measurements=self.n_missed_measurements / self.n_measurements\n            )\n        )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.monitor.PerformanceMonitor.n_missed_measurements","title":"<code>n_missed_measurements = 0</code>  <code>instance-attribute</code>","text":"<p>on MacOS cpu_affinity is not implemented in psutil  (raises AttributeError) set the num_cpus to the number of cpus in the system same for cpu_affinity</p>"},{"location":"internals/adapters/#jumper_extension.adapters.monitor.UnavailablePerformanceMonitor","title":"<code>UnavailablePerformanceMonitor</code>","text":"<p>A stub that type-checks against PerformanceMonitor Protocol but fails at runtime.</p> <ul> <li>Declares all required attributes for structural typing.</li> <li>Any attribute access or method call raises MonitorUnavailableError,   except 'running', which is always readable and returns False.</li> </ul> Source code in <code>jumper_extension/adapters/monitor.py</code> <pre><code>class UnavailablePerformanceMonitor:\n    \"\"\"\n    A stub that type-checks against PerformanceMonitor Protocol but fails at runtime.\n\n    - Declares all required attributes for structural typing.\n    - Any attribute access or method call raises MonitorUnavailableError,\n      except 'running', which is always readable and returns False.\n    \"\"\"\n\n    # --- Protocol surface ---\n    interval: float\n    data: \"PerformanceData\"\n    start_time: Optional[float]\n    num_cpus: int\n    num_system_cpus: int\n    num_gpus: int\n    gpu_memory: float\n    memory_limits: dict\n    cpu_handles: list[int]\n    gpu_name: str\n    running: bool\n\n    def start(self, interval: float = 1.0) -&gt; None: ...\n    def stop(self) -&gt; None: ...\n\n    # --- Runtime behavior ---\n    def __init__(self, reason: str = \"Performance monitor is not available\"):\n        object.__setattr__(self, \"_reason\", reason)\n\n    def __getattribute__(self, name: str):\n        # allow a few safe attributes + running\n        if name in {\n            \"_reason\", \"__class__\", \"__repr__\", \"__str__\",\n            \"__init__\", \"__getattribute__\", \"__setattr__\",\n            \"__dict__\", \"__annotations__\"\n        }:\n            return object.__getattribute__(self, name)\n\n        if name == \"running\":\n            return False\n\n        reason = object.__getattribute__(self, \"_reason\")\n        raise MonitorUnavailableError(f\"Access to '{name}' is not allowed: {reason}\")\n\n    def __setattr__(self, name: str, value):\n        if name in {\"_reason\", \"__dict__\", \"__annotations__\"}:\n            return object.__setattr__(self, name, value)\n        reason = object.__getattribute__(self, \"_reason\")\n        raise MonitorUnavailableError(f\"Setting '{name}' is not allowed: {reason}\")\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;UnavailablePerformanceMonitor: {self._reason}&gt;\"\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.data.PerformanceData","title":"<code>PerformanceData</code>","text":"Source code in <code>jumper_extension/adapters/data.py</code> <pre><code>class PerformanceData:\n    def __init__(self, num_cpus, num_system_cpus, num_gpus):\n        self.num_cpus = num_cpus\n        self.num_system_cpus = num_system_cpus\n        self.num_gpus = num_gpus\n        self.levels = get_available_levels()\n        # Minimal required base columns for loaded performance data\n        self._base_columns = [\n            \"time\",\n            \"memory\",\n            \"io_read_count\",\n            \"io_write_count\",\n            \"io_read\",\n            \"io_write\",\n            \"cpu_util_avg\",\n            \"cpu_util_min\",\n            \"cpu_util_max\",\n        ]\n        self.data = {\n            level: self._initialize_dataframe(level) for level in self.levels\n        }\n        # File writers/readers mappings\n        self._file_writers = {\n            \"json\": self._write_json,\n            \"csv\": self._write_csv,\n        }\n        self._file_readers = {\n            \"json\": pd.read_json,\n            \"csv\": pd.read_csv,\n        }\n\n    def _validate_level(self, level):\n        if level not in self.levels:\n            raise ValueError(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.INVALID_LEVEL\n                ].format(level=level, levels=self.levels)\n            )\n\n    def _initialize_dataframe(self, level):\n\n        effective_num_cpus = (\n            self.num_system_cpus if level == \"system\" else self.num_cpus\n        )\n\n        columns = self._base_columns + [f\"cpu_util_{i}\" for i in range(effective_num_cpus)]\n\n        if self.num_gpus &gt; 0:\n            gpu_metrics = [\"util\", \"band\", \"mem\"]\n            columns.extend(\n                [\n                    f\"gpu_{metric}_{stat}\"\n                    for metric in gpu_metrics\n                    for stat in [\"avg\", \"min\", \"max\"]\n                ]\n            )\n            columns.extend(\n                [\n                    f\"gpu_{metric}_{i}\"\n                    for i in range(self.num_gpus)\n                    for metric in gpu_metrics\n                ]\n            )\n\n        return pd.DataFrame(columns=columns)\n\n    def _attach_cell_index(self, df, cell_history) -&gt; pd.DataFrame:\n        result = df.copy()\n        result[\"cell_index\"] = pd.NA\n        times = result[\"time\"].to_numpy()\n        for row in cell_history.data.itertuples(index=False):\n            mask = (times &gt;= row.start_time) &amp; (times &lt;= row.end_time)\n            result.loc[mask, \"cell_index\"] = row.cell_index\n        return result\n\n    def _write_json(self, filename: str, df: pd.DataFrame) -&gt; None:\n        with open(filename, \"w\") as f:\n            json.dump(df.to_dict(\"records\"), f, indent=2)\n\n    def _write_csv(self, filename: str, df: pd.DataFrame) -&gt; None:\n        df.to_csv(filename, index=False)\n\n    def view(self, level=\"process\", slice_=None, cell_history=None):\n        \"\"\"View data for a specific level with optional slicing.\"\"\"\n        self._validate_level(level)\n        base = (\n            self.data[level]\n            if slice_ is None\n            else self.data[level].iloc[slice_[0] : slice_[1] + 1]\n        )\n        return (\n            self._attach_cell_index(base, cell_history)\n            if cell_history is not None\n            else base\n        )\n\n    def add_sample(\n        self,\n        level,\n        time_mark,\n        cpu_util_per_core,\n        memory,\n        gpu_util,\n        gpu_band,\n        gpu_mem,\n        io_counters,\n    ):\n        self._validate_level(level)\n        effective_num_cpus = (\n            self.num_system_cpus if level == \"system\" else self.num_cpus\n        )\n\n        last_timestamp = 0\n        if len(self.data[level]):\n            last_timestamp = self.data[level].loc[len(self.data[level]) - 1][\n                \"time\"\n            ]\n\n        cumulative_metrics_ratio = time_mark - last_timestamp\n        row_data = {\n            \"time\": time_mark,\n            \"memory\": memory,\n            \"io_read_count\": io_counters[0] / cumulative_metrics_ratio,\n            \"io_write_count\": io_counters[1] / cumulative_metrics_ratio,\n            \"io_read\": io_counters[2] / cumulative_metrics_ratio,\n            \"io_write\": io_counters[3] / cumulative_metrics_ratio,\n            \"cpu_util_avg\": sum(cpu_util_per_core) / effective_num_cpus,\n            \"cpu_util_min\": min(cpu_util_per_core),\n            \"cpu_util_max\": max(cpu_util_per_core),\n            **{\n                f\"cpu_util_{i}\": cpu_util_per_core[i]\n                for i in range(effective_num_cpus)\n            },\n        }\n\n        if self.num_gpus &gt; 0:\n            gpu_data = {\"util\": gpu_util, \"band\": gpu_band, \"mem\": gpu_mem}\n            for metric, values in gpu_data.items():\n                row_data.update(\n                    {\n                        f\"gpu_{metric}_avg\": sum(values) / self.num_gpus,\n                        f\"gpu_{metric}_min\": min(values),\n                        f\"gpu_{metric}_max\": max(values),\n                        **{\n                            f\"gpu_{metric}_{i}\": values[i]\n                            for i in range(self.num_gpus)\n                        },\n                    }\n                )\n\n        self.data[level].loc[len(self.data[level])] = row_data\n\n    def export(\n        self,\n        filename=\"performance_data.csv\",\n        level=\"process\",\n        cell_history=None,\n    ):\n        \"\"\"Export performance data to JSON or CSV.\"\"\"\n        self._validate_level(level)\n        if len(self.data[level]) == 0:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.NO_PERFORMANCE_DATA\n                ]\n            )\n            return\n\n        # Determine format from filename extension\n        _, ext = os.path.splitext(filename)\n        format = ext.lower().lstrip(\".\")\n\n        # Default to csv if no extension provided\n        if not format:\n            format = \"csv\"\n            filename += \".csv\"\n\n        df_to_write = (\n            self._attach_cell_index(self.data[level], cell_history)\n            if cell_history is not None\n            else self.data[level]\n        )\n\n        writer = self._file_writers.get(format)\n        if writer is None:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.UNSUPPORTED_FORMAT\n                ].format(\n                    format=format,\n                    supported_formats=\", \".join([\"json\", \"csv\"]),\n                )\n            )\n            return\n        writer(filename, df_to_write)\n\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.EXPORT_SUCCESS].format(\n                filename=filename\n            )\n        )\n\n    def load(self, filename: str) -&gt; Optional[pd.DataFrame]:\n        \"\"\"Load performance data from CSV or JSON file.\n\n        Returns:\n            DataFrame if successful, None otherwise\n        \"\"\"\n        return load_dataframe_from_file(\n            filename,\n            self._file_readers,\n            self._base_columns,\n            entity_name=\"performance data\",\n        )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.data.PerformanceData.export","title":"<code>export(filename='performance_data.csv', level='process', cell_history=None)</code>","text":"<p>Export performance data to JSON or CSV.</p> Source code in <code>jumper_extension/adapters/data.py</code> <pre><code>def export(\n    self,\n    filename=\"performance_data.csv\",\n    level=\"process\",\n    cell_history=None,\n):\n    \"\"\"Export performance data to JSON or CSV.\"\"\"\n    self._validate_level(level)\n    if len(self.data[level]) == 0:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[\n                ExtensionErrorCode.NO_PERFORMANCE_DATA\n            ]\n        )\n        return\n\n    # Determine format from filename extension\n    _, ext = os.path.splitext(filename)\n    format = ext.lower().lstrip(\".\")\n\n    # Default to csv if no extension provided\n    if not format:\n        format = \"csv\"\n        filename += \".csv\"\n\n    df_to_write = (\n        self._attach_cell_index(self.data[level], cell_history)\n        if cell_history is not None\n        else self.data[level]\n    )\n\n    writer = self._file_writers.get(format)\n    if writer is None:\n        logger.warning(\n            EXTENSION_ERROR_MESSAGES[\n                ExtensionErrorCode.UNSUPPORTED_FORMAT\n            ].format(\n                format=format,\n                supported_formats=\", \".join([\"json\", \"csv\"]),\n            )\n        )\n        return\n    writer(filename, df_to_write)\n\n    logger.info(\n        EXTENSION_INFO_MESSAGES[ExtensionInfoCode.EXPORT_SUCCESS].format(\n            filename=filename\n        )\n    )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.data.PerformanceData.load","title":"<code>load(filename)</code>","text":"<p>Load performance data from CSV or JSON file.</p> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame if successful, None otherwise</p> Source code in <code>jumper_extension/adapters/data.py</code> <pre><code>def load(self, filename: str) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Load performance data from CSV or JSON file.\n\n    Returns:\n        DataFrame if successful, None otherwise\n    \"\"\"\n    return load_dataframe_from_file(\n        filename,\n        self._file_readers,\n        self._base_columns,\n        entity_name=\"performance data\",\n    )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.data.PerformanceData.view","title":"<code>view(level='process', slice_=None, cell_history=None)</code>","text":"<p>View data for a specific level with optional slicing.</p> Source code in <code>jumper_extension/adapters/data.py</code> <pre><code>def view(self, level=\"process\", slice_=None, cell_history=None):\n    \"\"\"View data for a specific level with optional slicing.\"\"\"\n    self._validate_level(level)\n    base = (\n        self.data[level]\n        if slice_ is None\n        else self.data[level].iloc[slice_[0] : slice_[1] + 1]\n    )\n    return (\n        self._attach_cell_index(base, cell_history)\n        if cell_history is not None\n        else base\n    )\n</code></pre>"},{"location":"internals/adapters/#cell-history-and-analysis","title":"Cell history and analysis","text":""},{"location":"internals/adapters/#jumper_extension.adapters.cell_history.CellHistory","title":"<code>CellHistory</code>","text":"Source code in <code>jumper_extension/adapters/cell_history.py</code> <pre><code>class CellHistory:\n    def __init__(self):\n        self._columns = [\n            \"cell_index\",\n            \"raw_cell\",\n            \"start_time\",\n            \"end_time\",\n            \"duration\",\n        ]\n        self.data = pd.DataFrame(columns=self._columns)\n        self.file_readers = {\n            \"json\": pd.read_json,\n            \"csv\": pd.read_csv,\n        }\n        self.current_cell = None\n\n    def start_cell(self, raw_cell: str, cell_magics: List[str]):\n        self.current_cell = {\n            \"cell_index\": len(self.data),\n            \"cell_magics\": cell_magics,\n            \"raw_cell\": raw_cell,\n            \"start_time\": time.perf_counter(),\n            \"end_time\": None,\n            \"duration\": None,\n        }\n\n    def end_cell(self, result):\n        if self.current_cell:\n            self.current_cell[\"end_time\"] = time.perf_counter()\n            self.current_cell[\"duration\"] = (\n                self.current_cell[\"end_time\"] - self.current_cell[\"start_time\"]\n            )\n\n            new_row = pd.DataFrame([self.current_cell])\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\", FutureWarning)\n                warnings.simplefilter(\"ignore\", pd.errors.PerformanceWarning)\n                self.data = pd.concat([self.data, new_row], ignore_index=True)\n            self.current_cell = None\n\n    def view(self, start=None, end=None):\n        if start is None and end is None:\n            return self.data\n        return self.data.iloc[start:end]\n\n    def print(self):\n        for _, cell in self.data.iterrows():\n            print(\n                f\"Cell #{int(cell['cell_index'])} - Duration: \"\n                f\"{cell['duration']:.2f}s\"\n            )\n            print(\"-\" * 40)\n            print(cell[\"raw_cell\"])\n            print(\"=\" * 40)\n\n    def show_itable(self):\n        if self.data.empty:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_CELL_HISTORY]\n            )\n            return\n\n        data = []\n        for _, row in self.data.iterrows():\n            duration = row[\"end_time\"] - row[\"start_time\"]\n            data.append(\n                {\n                    \"Cell index\": row[\"cell_index\"],\n                    \"Duration (s)\": f\"{duration:.2f}\",\n                    \"Start Time\": time.strftime(\n                        \"%H:%M:%S\", time.localtime(row[\"start_time\"])\n                    ),\n                    \"End Time\": time.strftime(\n                        \"%H:%M:%S\", time.localtime(row[\"end_time\"])\n                    ),\n                    \"Code\": row[\"raw_cell\"].replace(\"\\n\", \"&lt;br&gt;\"),\n                }\n            )\n\n        df = pd.DataFrame(data)\n\n        # To avoid warnings about a non-documented 'escape' option in a notebook\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"ignore\", category=SyntaxWarning, module=\"itables\\\\.typing\")\n            show(\n                df,\n                layout={\"topStart\": \"search\", \"topEnd\": None},\n                columnDefs=[\n                    {\"targets\": [4], \"className\": \"dt-left\"}\n                ],  # 4 - \"Code\" index\n                escape=False,\n            )\n\n    def export(self, filename=\"cell_history.json\"):\n        if self.data.empty:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_CELL_HISTORY]\n            )\n            return\n\n        # Determine format from filename extension\n        _, ext = os.path.splitext(filename)\n        format = ext.lower().lstrip(\".\")\n\n        # Default to csv if no extension provided\n        if not format:\n            format = \"csv\"\n            filename += \".csv\"\n\n        if format == \"json\":\n            with open(filename, \"w\") as f:\n                json.dump(self.data.to_dict(\"records\"), f, indent=2)\n        elif format == \"csv\":\n            self.data.to_csv(filename, index=False)\n        else:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.UNSUPPORTED_FORMAT\n                ].format(\n                    format=format,\n                    supported_formats=\", \".join([\"json\", \"csv\"]),\n                )\n            )\n            return\n\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.EXPORT_SUCCESS].format(\n                filename=filename\n            )\n        )\n\n    def load(self, filename: str) -&gt; Optional[pd.DataFrame]:\n        \"\"\"Load cell history from CSV or JSON file.\n\n        Returns:\n            DataFrame if successful, None otherwise\n        \"\"\"\n        return load_dataframe_from_file(\n            filename,\n            self.file_readers,\n            self._columns,\n            entity_name=\"cell history\",\n        )\n\n    def __len__(self):\n        return len(self.data)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.cell_history.CellHistory.load","title":"<code>load(filename)</code>","text":"<p>Load cell history from CSV or JSON file.</p> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame if successful, None otherwise</p> Source code in <code>jumper_extension/adapters/cell_history.py</code> <pre><code>def load(self, filename: str) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Load cell history from CSV or JSON file.\n\n    Returns:\n        DataFrame if successful, None otherwise\n    \"\"\"\n    return load_dataframe_from_file(\n        filename,\n        self.file_readers,\n        self._columns,\n        entity_name=\"cell history\",\n    )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.analyzer.PerformanceAnalyzer","title":"<code>PerformanceAnalyzer</code>","text":"<p>Performance analyzer to determine workload type using relative thresholds.</p> <p>Inspired by <code>JobLabeller</code> from: https://gitlab.hrz.tu-chemnitz.de/pika/pika-server/-/blob/ 619d62926cd85f8c20589c75aba0c6e2c51087e1/ src/post_processing/post_processing.py#L711</p> Source code in <code>jumper_extension/adapters/analyzer.py</code> <pre><code>class PerformanceAnalyzer:\n    \"\"\"\n    Performance analyzer to determine workload type using relative thresholds.\n\n    Inspired by `JobLabeller` from:\n    https://gitlab.hrz.tu-chemnitz.de/pika/pika-server/-/blob/\n    619d62926cd85f8c20589c75aba0c6e2c51087e1/\n    src/post_processing/post_processing.py#L711\n    \"\"\"\n    # Default thresholds\n    DEFAULT_THRESHOLDS = {\n        'memory_ratio': 0.8,  # memory limit 0.80\n        'cpu_ratio': 0.7,  # CPU capacity 0.70\n        'gpu_util_ratio': 0.8,  # GPU utilization\n        'gpu_memory_ratio': 0.8,  # GPU memory\n\n        # --- thresholds for \"GPU idle\" detection\n        # minimum memory usage required to treat GPU as allocated\n        'gpu_alloc_min_mem_gb': 0.1,\n        # minimum GPU utilization to treat GPU in idle state\n        'gpu_util_idle_threshold': 0.05,\n        # minimum overall usage fraction required to trigger the tag\n        'gpu_alloc_min_fraction': 0.5,\n\n    }\n\n    def __init__(\n        self,\n        thresholds: Optional[Dict[str, float]] = None,\n    ):\n        \"\"\"\n        Initialize analyzer with relative thresholds\n\n        Args:\n            thresholds: Custom threshold values (uses defaults if None)\n        \"\"\"\n        self.thresholds = {**self.DEFAULT_THRESHOLDS, **(thresholds or {})}\n\n    def analyze_cell_performance(\n        self,\n        perfdata: \"pd.DataFrame\",\n        memory_limit: float,\n        gpu_memory_limit: Optional[float] = None,\n    ) -&gt; List[TagScore]:\n        \"\"\"\n        Analyze cell performance and determine tags\n\n        Args:\n            perfdata: DataFrame with performance data\n            memory_limit: System memory limit in GB\n            gpu_memory_limit: GPU memory limit in GB (if available)\n\n        Returns:\n            List[TagScore]: Ranked performance tags for the cell\n        \"\"\"\n\n        logger.debug(f\"{memory_limit = }\")\n        logger.debug(f\"{gpu_memory_limit = }\")\n\n        # Compute normalized metrics\n        metrics = self._compute_metrics(perfdata, gpu_memory_limit)\n\n        # Calculate resource utilization ratios\n        ratios = self._calculate_utilization_ratios(metrics, memory_limit, gpu_memory_limit)\n\n        # Create the ranked tags list\n        ranked_tags = self._create_ranked_tags(ratios)\n\n        # Detect \"GPU allocated but not used\" and prepend if applicable\n        gpu_unused_tag = self._detect_gpu_allocated_but_not_used(perfdata, gpu_memory_limit)\n        if gpu_unused_tag is not None:\n            # Prepend the GPU allocated but not used as this is the most important tag\n            ranked_tags = [gpu_unused_tag] +  ranked_tags\n\n        logger.debug(f\"{ranked_tags = }\")\n\n        return ranked_tags if ranked_tags else [TagScore(PerformanceTag.NORMAL, 0.0)]\n\n    @staticmethod\n    def _compute_metrics(\n            perfdata: \"pd.DataFrame\",\n            gpu_memory_limit: Optional[float],\n    ) -&gt; Dict[str, float]:\n        \"\"\"Compute raw performance metrics\"\"\"\n        metrics = {}\n\n        # CPU metrics\n        if 'cpu_util_avg' in perfdata.columns:\n            metrics['cpu_avg'] = perfdata['cpu_util_avg'].mean()\n\n        # Memory metrics\n        if 'memory' in perfdata.columns:\n            metrics['memory_avg_gb'] = perfdata['memory'].mean()\n\n        # GPU metrics\n        if 'gpu_util_avg' in perfdata.columns:\n            metrics['gpu_util_avg'] = perfdata['gpu_util_avg'].mean()\n\n        if 'gpu_mem_avg' in perfdata.columns and gpu_memory_limit:\n            metrics['gpu_memory_avg_gb'] = perfdata['gpu_mem_avg'].mean()\n\n        return metrics\n\n    def _calculate_utilization_ratios(self, metrics: Dict[str, float],\n                                      memory_limit: float,\n                                      gpu_memory_limit: Optional[float]) -&gt; Dict[str, float]:\n        \"\"\"Calculate utilization ratios relative to system limits\"\"\"\n        ratios = {}\n\n        # Memory ratio (current usage / limit)\n        memory_avg = metrics.get('memory_avg_gb', 0)\n        ratios['memory'] = self._safe_ratio(memory_avg, memory_limit)\n\n        # CPU ratio (utilization / 100%)\n        cpu_avg = metrics.get('cpu_avg', 0)\n        ratios['cpu'] = self._safe_ratio(cpu_avg, 100.0)\n\n        # GPU utilization ratio\n        gpu_util = metrics.get('gpu_util_avg', 0)\n        ratios['gpu_util'] = self._safe_ratio(gpu_util, 100.0)\n\n        # GPU memory ratio\n        if gpu_memory_limit and gpu_memory_limit &gt; 0:\n            gpu_memory = metrics.get('gpu_memory_avg_gb', 0)\n            ratios['gpu_memory'] = self._safe_ratio(gpu_memory, gpu_memory_limit)\n        else:\n            ratios['gpu_memory'] = 0.0\n\n        logger.debug(f\"ratios: {ratios}\")\n\n        return ratios\n\n    @staticmethod\n    def _safe_ratio(measured: float, maximum: float) -&gt; float:\n        \"\"\"Safely calculate ratio with error handling\"\"\"\n        try:\n            if maximum is None or maximum &lt;= 0 or measured is None:\n                return 0.0\n            return min(1.0, max(0.0, measured / maximum))\n        except (TypeError, ZeroDivisionError):\n            return 0.0\n\n    def _create_ranked_tags(self, ratios: Dict[str, float]) -&gt; List[TagScore]:\n        \"\"\"Create the ranked list of tags based on ratios (0.0-1.0 scale)\"\"\"\n\n        # Sort by descending ratios\n        sorted_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True)\n\n        # Create ranked tags for resources that exceed the minimum threshold\n        tag_mapping = {\n            'cpu': PerformanceTag.CPU_BOUND,\n            'memory': PerformanceTag.MEMORY_BOUND,\n            'gpu_util': PerformanceTag.GPU_UTIL_BOUND,\n            'gpu_memory': PerformanceTag.GPU_MEMORY_BOUND,\n        }\n\n        ranked_tags = []\n\n        for resource, ratio in sorted_ratios:\n            threshold_key = f'{resource}_ratio'\n            threshold = self.thresholds.get(threshold_key, 0.0)\n            if ratio &gt;= threshold:\n                tag = tag_mapping.get(resource)\n                if tag:\n                    ranked_tags.append(TagScore(tag, ratio))\n\n        return ranked_tags\n\n    def _detect_gpu_allocated_but_not_used(\n        self,\n        perfdata: \"pd.DataFrame\",\n        gpu_memory_limit: Optional[float],\n    ) -&gt; Optional[TagScore]:\n        \"\"\"\n        Detect case when GPU memory is allocated but GPU compute utilization stays idle\n        for a significant fraction of measurement time.\n        \"\"\"\n        # must have GPU columns and a GPU present\n        if gpu_memory_limit is None:\n            return None\n        if 'gpu_mem_avg' not in perfdata.columns or 'gpu_util_avg' not in perfdata.columns:\n            return None\n        if perfdata.empty:\n            return None\n\n        memory_threshold_gb = max(float(self.thresholds.get('gpu_alloc_min_mem_gb', 0.1)), 0.0)\n        utilization_idle_threshold = float(self.thresholds.get('gpu_util_idle_threshold', 0.05))  # 0..1\n        min_fraction = float(self.thresholds.get('gpu_alloc_min_fraction', 0.5))        # 0..1\n\n        # allocation considered if memory usage exceeds memory_threshold_gb\n        mask_allocated = perfdata['gpu_mem_avg'] &gt; memory_threshold_gb\n        if mask_allocated.sum() == 0:\n            return None\n\n        # idle if util \u2264 util_idle_thr * 100 (%)\n        mask_idle = perfdata['gpu_util_avg'] &lt;= (utilization_idle_threshold * 100.0)\n\n        mask_allocated_and_idle = mask_allocated &amp; mask_idle\n        frac = float(mask_allocated_and_idle.mean())\n\n        logger.debug(f\"GPU idle check:\")\n        logger.debug(f\"gpu_mem_avg:\\n{perfdata['gpu_mem_avg']}\")\n        logger.debug(f\"mask_allocated:\\n{mask_allocated}\\n\")\n        logger.debug(f\"gpu_util_avg:\\n{perfdata['gpu_util_avg']}\")\n        logger.debug(f\"mask_idle:\\n{mask_idle}\\n\")\n        logger.debug(f\"GPU not used {min_fraction = }\")\n        logger.debug(f\"GPU not used {frac = }\")\n\n        if frac &gt;= min_fraction:\n            return TagScore(PerformanceTag.GPU_ALLOCATED_BUT_NOT_USED, frac)\n        return None\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.analyzer.PerformanceAnalyzer.__init__","title":"<code>__init__(thresholds=None)</code>","text":"<p>Initialize analyzer with relative thresholds</p> <p>Parameters:</p> Name Type Description Default <code>thresholds</code> <code>Optional[Dict[str, float]]</code> <p>Custom threshold values (uses defaults if None)</p> <code>None</code> Source code in <code>jumper_extension/adapters/analyzer.py</code> <pre><code>def __init__(\n    self,\n    thresholds: Optional[Dict[str, float]] = None,\n):\n    \"\"\"\n    Initialize analyzer with relative thresholds\n\n    Args:\n        thresholds: Custom threshold values (uses defaults if None)\n    \"\"\"\n    self.thresholds = {**self.DEFAULT_THRESHOLDS, **(thresholds or {})}\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.analyzer.PerformanceAnalyzer.analyze_cell_performance","title":"<code>analyze_cell_performance(perfdata, memory_limit, gpu_memory_limit=None)</code>","text":"<p>Analyze cell performance and determine tags</p> <p>Parameters:</p> Name Type Description Default <code>perfdata</code> <code>DataFrame</code> <p>DataFrame with performance data</p> required <code>memory_limit</code> <code>float</code> <p>System memory limit in GB</p> required <code>gpu_memory_limit</code> <code>Optional[float]</code> <p>GPU memory limit in GB (if available)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[TagScore]</code> <p>List[TagScore]: Ranked performance tags for the cell</p> Source code in <code>jumper_extension/adapters/analyzer.py</code> <pre><code>def analyze_cell_performance(\n    self,\n    perfdata: \"pd.DataFrame\",\n    memory_limit: float,\n    gpu_memory_limit: Optional[float] = None,\n) -&gt; List[TagScore]:\n    \"\"\"\n    Analyze cell performance and determine tags\n\n    Args:\n        perfdata: DataFrame with performance data\n        memory_limit: System memory limit in GB\n        gpu_memory_limit: GPU memory limit in GB (if available)\n\n    Returns:\n        List[TagScore]: Ranked performance tags for the cell\n    \"\"\"\n\n    logger.debug(f\"{memory_limit = }\")\n    logger.debug(f\"{gpu_memory_limit = }\")\n\n    # Compute normalized metrics\n    metrics = self._compute_metrics(perfdata, gpu_memory_limit)\n\n    # Calculate resource utilization ratios\n    ratios = self._calculate_utilization_ratios(metrics, memory_limit, gpu_memory_limit)\n\n    # Create the ranked tags list\n    ranked_tags = self._create_ranked_tags(ratios)\n\n    # Detect \"GPU allocated but not used\" and prepend if applicable\n    gpu_unused_tag = self._detect_gpu_allocated_but_not_used(perfdata, gpu_memory_limit)\n    if gpu_unused_tag is not None:\n        # Prepend the GPU allocated but not used as this is the most important tag\n        ranked_tags = [gpu_unused_tag] +  ranked_tags\n\n    logger.debug(f\"{ranked_tags = }\")\n\n    return ranked_tags if ranked_tags else [TagScore(PerformanceTag.NORMAL, 0.0)]\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.analyzer.PerformanceTag","title":"<code>PerformanceTag</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Performance tags for classifying cells</p> Source code in <code>jumper_extension/adapters/analyzer.py</code> <pre><code>class PerformanceTag(Enum):\n    \"\"\"Performance tags for classifying cells\"\"\"\n    NORMAL = \"normal\"\n    CPU_BOUND = \"cpu-bound\"\n    MEMORY_BOUND = \"memory-bound\"\n    GPU_UTIL_BOUND = \"gpu-util-bound\"\n    GPU_MEMORY_BOUND = \"gpu-memory-bound\"\n    GPU_ALLOCATED_BUT_NOT_USED = \"gpu-allocated-but-not-used\"\n\n    def __str__(self):\n        return self.value\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.analyzer.TagScore","title":"<code>TagScore</code>  <code>dataclass</code>","text":"<p>Tag with its score for ranking</p> Source code in <code>jumper_extension/adapters/analyzer.py</code> <pre><code>@dataclass\nclass TagScore:\n    \"\"\"Tag with its score for ranking\"\"\"\n    tag: PerformanceTag\n    score: float\n</code></pre>"},{"location":"internals/adapters/#reporting-and-visualization","title":"Reporting and visualization","text":""},{"location":"internals/adapters/#jumper_extension.adapters.reporter.PerformanceReporter","title":"<code>PerformanceReporter</code>","text":"<p>Adapter class for performance reporting</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>class PerformanceReporter:\n    \"\"\"Adapter class for performance reporting\"\"\"\n    def __init__(\n        self,\n        printer: ReportPrinter,\n        displayer: ReportDisplayerProtocol\n    ):\n        self.printer = printer\n        self.displayer = displayer\n\n    def attach(\n        self,\n        monitor: PerformanceMonitorProtocol,\n    ):\n        \"\"\"Attach started PerformanceMonitor\"\"\"\n        # Attach to printer\n        self.printer.monitor = monitor\n        self.printer.min_duration = monitor.interval\n        # Attach to displayer\n        self.displayer.monitor = monitor\n        self.displayer.min_duration = monitor.interval\n\n    def print(self, cell_range=None, level=\"process\"):\n        \"\"\"Print performance report\"\"\"\n        self.printer.print(cell_range, level)\n\n    def display(self, cell_range=None, level=\"process\"):\n        \"\"\"Display performance report\"\"\"\n        self.displayer.display(cell_range, level)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.PerformanceReporter.attach","title":"<code>attach(monitor)</code>","text":"<p>Attach started PerformanceMonitor</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>def attach(\n    self,\n    monitor: PerformanceMonitorProtocol,\n):\n    \"\"\"Attach started PerformanceMonitor\"\"\"\n    # Attach to printer\n    self.printer.monitor = monitor\n    self.printer.min_duration = monitor.interval\n    # Attach to displayer\n    self.displayer.monitor = monitor\n    self.displayer.min_duration = monitor.interval\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.PerformanceReporter.display","title":"<code>display(cell_range=None, level='process')</code>","text":"<p>Display performance report</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>def display(self, cell_range=None, level=\"process\"):\n    \"\"\"Display performance report\"\"\"\n    self.displayer.display(cell_range, level)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.PerformanceReporter.print","title":"<code>print(cell_range=None, level='process')</code>","text":"<p>Print performance report</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>def print(self, cell_range=None, level=\"process\"):\n    \"\"\"Print performance report\"\"\"\n    self.printer.print(cell_range, level)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.ReportBuilder","title":"<code>ReportBuilder</code>","text":"<p>Base class for report builders</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>class ReportBuilder:\n    \"\"\"Base class for report builders\"\"\"\n    def __init__(\n        self,\n        monitor: PerformanceMonitorProtocol,\n        cell_history: CellHistory,\n        analyzer: PerformanceAnalyzer,\n    ):\n        self.monitor = monitor\n        self.cell_history = cell_history\n        self.min_duration = None\n        self.analyzer = analyzer\n\n    def _prepare_report_data(self, cell_range, level):\n        \"\"\"Prepare all necessary data for performance reporting.\n\n        Returns:\n            dict: Dictionary containing filtered_cells, perfdata, ranked_tags,\n                  total_duration, and other data needed for display methods.\n                  Returns None if data preparation fails.\n        \"\"\"\n\n        cell_range = self._resolve_cell_range(cell_range)\n\n        if cell_range is None:\n            return\n\n        # Filter cell history data first using cell_range\n        start_idx, end_idx = cell_range\n        filtered_cells = self.cell_history.view(start_idx, end_idx + 1)\n\n        perfdata = self.monitor.data.view(level=level)\n        perfdata = filter_perfdata(\n            filtered_cells, perfdata, compress_idle=False\n        )\n\n        # Check if non-empty, otherwise print results\n        if perfdata.empty:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.NO_PERFORMANCE_DATA\n                ]\n            )\n            return\n\n        # Analyze cell performance\n        memory_limit = self.monitor.memory_limits[level]\n        gpu_memory_limit = self.monitor.gpu_memory if self.monitor.num_gpus &gt; 0 else None\n\n        tags_model = self.analyzer.analyze_cell_performance(\n            perfdata,\n            memory_limit,\n            gpu_memory_limit\n        )\n\n        # Calculate the total duration of selected cells\n        total_duration = filtered_cells[\"duration\"].sum()\n\n        return {\n            'cell_range': cell_range,\n            'filtered_cells': filtered_cells,\n            'perfdata': perfdata,\n            'tags_model': tags_model,\n            'total_duration': total_duration,\n        }\n\n    def _resolve_cell_range(self, cell_range) -&gt; Union[Tuple[int, int], None]:\n        \"\"\"\n        Resolve cell range for performance reporting.\n\n        Behavior:\n        - If cell_range is None, selects the last cell whose duration is not \"short\"\n         and returns it as a singleton range (idx, idx).\n        - Returns None if:\n          - no active monitor is attached,\n          - the history has no cells,\n          - there is no cell with a non-short duration.\n        \"\"\"\n\n        if not self.monitor:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_ACTIVE_MONITOR]\n            )\n            return None\n\n        if cell_range is None:\n            valid_cells = self.cell_history.view()\n\n            if len(valid_cells) &gt; 0:\n                # Filter for non-short cells\n                min_duration = (\n                    self.min_duration if self.min_duration is not None else 0\n                )\n                non_short_cells = valid_cells[\n                    valid_cells[\"duration\"] &gt;= min_duration\n                    ]\n\n                if len(non_short_cells) &gt; 0:\n                    # Get the last non-short cell index\n                    last_valid_cell_idx = int(\n                        non_short_cells.iloc[-1][\"cell_index\"]\n                    )\n                    cell_range = (last_valid_cell_idx, last_valid_cell_idx)\n                    return cell_range\n                else:\n                    logger.warning(\n                        EXTENSION_ERROR_MESSAGES[\n                            ExtensionErrorCode.NO_PERFORMANCE_DATA\n                        ]\n                    )\n                    return None\n            else:\n                return None\n\n        return cell_range\n\n    @staticmethod\n    def _format_performance_tags(ranked_tags: List[TagScore]):\n        \"\"\"Format ranked performance tags for display\"\"\"\n        if not ranked_tags:\n            return [{\"name\": \"UNKNOWN\", \"slug\": \"unknown\"}]\n\n        # If the only classification is NORMAL, do not display any tag\n        if len(ranked_tags) == 1 and ranked_tags[0].tag == PerformanceTag.NORMAL:\n            return []\n\n        # Format all tags with their scores/ratios\n        tag_displays = []\n        for tag_score in ranked_tags:\n            # Create slug for CSS hooks and uppercase name for display\n            tag_slug = str(tag_score.tag)\n            tag_name = tag_slug.upper()\n            tag_displays.append({\n                \"name\": tag_name,\n                \"slug\": tag_slug,\n            })\n        return tag_displays\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.ReportDisplayer","title":"<code>ReportDisplayer</code>","text":"<p>               Bases: <code>ReportBuilder</code></p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>class ReportDisplayer(ReportBuilder):\n    def __init__(\n        self,\n        monitor: PerformanceMonitorProtocol,\n        cell_history: CellHistory,\n        analyzer: PerformanceAnalyzer,\n        templates_dir=None\n    ):\n        super().__init__(monitor, cell_history, analyzer)\n        self.templates_dir = Path(templates_dir) if templates_dir else Path(__file__).parent.parent / \"templates\"\n\n    def display(self, cell_range=None, level=\"process\"):\n        \"\"\"Print performance report\"\"\"\n\n        data = self._prepare_report_data(cell_range, level)\n        if data is None:\n            return\n\n        filtered_cells = data['filtered_cells']\n        perfdata = data['perfdata']\n        tags_model = data['tags_model']\n        total_duration = data['total_duration']\n\n        tags_display = self._format_performance_tags(tags_model)\n\n        # Build report\n        metrics_spec = [\n            (f\"CPU Util (Across {self.monitor.num_cpus} CPUs)\", \"cpu_util_avg\", \"-\"),\n            (\"Memory (GB)\", \"memory\", f\"{self.monitor.memory_limits[level]:.2f}\" if hasattr(self.monitor, \"memory_limits\") else \"-\"),\n            (f\"GPU Util (Across {getattr(self.monitor, 'num_gpus', 0)} GPUs)\", \"gpu_util_avg\", \"-\"),\n            (\"GPU Memory (GB)\", \"gpu_mem_avg\", f\"{getattr(self.monitor, 'gpu_memory', 0.0):.2f}\"),\n        ]\n        metrics_rows = []\n        for name, col, total in metrics_spec:\n            if col in perfdata.columns:\n                metrics_rows.append({\n                    \"name\": name,\n                    \"avg\": float(perfdata[col].mean()),\n                    \"min\": float(perfdata[col].min()),\n                    \"max\": float(perfdata[col].max()),\n                    \"total\": total,\n                })\n\n        # Render Jinja2 HTML from external files\n        env = Environment(\n            loader=FileSystemLoader(str(self.templates_dir)),\n            autoescape=select_autoescape([\"html\", \"xml\"])\n        )\n        report_html_path = Path(\"report\") / \"report.html\"\n        template = env.get_template(report_html_path.as_posix())\n        # Read external stylesheet and inline it for notebook rendering\n        try:\n            styles_path = self.templates_dir / \"report\" / \"styles.css\"\n            inline_styles = styles_path.read_text(encoding=\"utf-8\") if styles_path.exists() else \"\"\n        except Exception:\n            inline_styles = \"\"\n\n        html = template.render(\n            duration=total_duration,\n            n_cells=len(filtered_cells) if filtered_cells is not None else 1,\n            metrics=metrics_rows,\n            tags=tags_display,\n            inline_styles=inline_styles,\n        )\n        display(HTML(html))\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.ReportDisplayer.display","title":"<code>display(cell_range=None, level='process')</code>","text":"<p>Print performance report</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>def display(self, cell_range=None, level=\"process\"):\n    \"\"\"Print performance report\"\"\"\n\n    data = self._prepare_report_data(cell_range, level)\n    if data is None:\n        return\n\n    filtered_cells = data['filtered_cells']\n    perfdata = data['perfdata']\n    tags_model = data['tags_model']\n    total_duration = data['total_duration']\n\n    tags_display = self._format_performance_tags(tags_model)\n\n    # Build report\n    metrics_spec = [\n        (f\"CPU Util (Across {self.monitor.num_cpus} CPUs)\", \"cpu_util_avg\", \"-\"),\n        (\"Memory (GB)\", \"memory\", f\"{self.monitor.memory_limits[level]:.2f}\" if hasattr(self.monitor, \"memory_limits\") else \"-\"),\n        (f\"GPU Util (Across {getattr(self.monitor, 'num_gpus', 0)} GPUs)\", \"gpu_util_avg\", \"-\"),\n        (\"GPU Memory (GB)\", \"gpu_mem_avg\", f\"{getattr(self.monitor, 'gpu_memory', 0.0):.2f}\"),\n    ]\n    metrics_rows = []\n    for name, col, total in metrics_spec:\n        if col in perfdata.columns:\n            metrics_rows.append({\n                \"name\": name,\n                \"avg\": float(perfdata[col].mean()),\n                \"min\": float(perfdata[col].min()),\n                \"max\": float(perfdata[col].max()),\n                \"total\": total,\n            })\n\n    # Render Jinja2 HTML from external files\n    env = Environment(\n        loader=FileSystemLoader(str(self.templates_dir)),\n        autoescape=select_autoescape([\"html\", \"xml\"])\n    )\n    report_html_path = Path(\"report\") / \"report.html\"\n    template = env.get_template(report_html_path.as_posix())\n    # Read external stylesheet and inline it for notebook rendering\n    try:\n        styles_path = self.templates_dir / \"report\" / \"styles.css\"\n        inline_styles = styles_path.read_text(encoding=\"utf-8\") if styles_path.exists() else \"\"\n    except Exception:\n        inline_styles = \"\"\n\n    html = template.render(\n        duration=total_duration,\n        n_cells=len(filtered_cells) if filtered_cells is not None else 1,\n        metrics=metrics_rows,\n        tags=tags_display,\n        inline_styles=inline_styles,\n    )\n    display(HTML(html))\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.ReportDisplayerProtocol","title":"<code>ReportDisplayerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Structural protocol for HTML/text report displayers.</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>@runtime_checkable\nclass ReportDisplayerProtocol(Protocol):\n    \"\"\"Structural protocol for HTML/text report displayers.\"\"\"\n    def display(self, cell_range=None, level: str = \"process\") -&gt; None: ...\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.ReportPrinter","title":"<code>ReportPrinter</code>","text":"<p>               Bases: <code>ReportBuilder</code></p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>class ReportPrinter(ReportBuilder):\n    def __init__(\n        self,\n        monitor: PerformanceMonitorProtocol,\n        cell_history: CellHistory,\n        analyzer: PerformanceAnalyzer,\n    ):\n        super().__init__(monitor, cell_history, analyzer)\n\n    def print(self, cell_range=None, level=\"process\"):\n        \"\"\"Print performance report\"\"\"\n        data = self._prepare_report_data(cell_range, level)\n        if data is None:\n            return\n\n        filtered_cells = data['filtered_cells']\n        perfdata = data['perfdata']\n        tags_model = data['tags_model']\n        total_duration = data['total_duration']\n\n        print(\"-\" * 40)\n        print(\"JUmPER Performance Report\")\n        print(\"-\" * 40)\n        n_cells = len(filtered_cells)\n        print(\n            f\"Duration: {total_duration:.2f}s \"\n            f\"({n_cells} cell{'s' if n_cells != 1 else ''})\"\n        )\n        print(\"-\" * 40)\n\n        # Output performance tags\n        tags_display = self._format_performance_tags(tags_model)\n        if tags_display:\n            print(\"Signature(s):\")\n            tags_line = \" | \".join(tag[\"name\"] for tag in tags_display)\n            print(tags_line)\n\n            print(\"-\" * 40)\n\n        # Report table\n        metrics = [\n            (\n                f\"CPU Util (Across {self.monitor.num_cpus} CPUs)\",\n                \"cpu_util_avg\",\n                \"-\",\n            ),\n            (\n                \"Memory (GB)\",\n                \"memory\",\n                f\"{self.monitor.memory_limits[level]:.2f}\",\n            ),\n            (\n                f\"GPU Util (Across {self.monitor.num_gpus} GPUs)\",\n                \"gpu_util_avg\",\n                \"-\",\n            ),\n            (\n                \"GPU Memory (GB)\",\n                \"gpu_mem_avg\",\n                f\"{self.monitor.gpu_memory:.2f}\",\n            ),\n        ]\n\n        print(f\"{'Metric':&lt;25} {'AVG':&lt;8} {'MIN':&lt;8} {'MAX':&lt;8} {'TOTAL':&lt;8}\")\n        print(\"-\" * 65)\n        for name, col, total in metrics:\n            if col in perfdata.columns:\n                print(\n                    f\"{name:&lt;25} {perfdata[col].mean():&lt;8.2f} \"\n                    f\"{perfdata[col].min():&lt;8.2f} {perfdata[col].max():&lt;8.2f} \"\n                    f\"{total:&lt;8}\"\n                )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.ReportPrinter.print","title":"<code>print(cell_range=None, level='process')</code>","text":"<p>Print performance report</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>def print(self, cell_range=None, level=\"process\"):\n    \"\"\"Print performance report\"\"\"\n    data = self._prepare_report_data(cell_range, level)\n    if data is None:\n        return\n\n    filtered_cells = data['filtered_cells']\n    perfdata = data['perfdata']\n    tags_model = data['tags_model']\n    total_duration = data['total_duration']\n\n    print(\"-\" * 40)\n    print(\"JUmPER Performance Report\")\n    print(\"-\" * 40)\n    n_cells = len(filtered_cells)\n    print(\n        f\"Duration: {total_duration:.2f}s \"\n        f\"({n_cells} cell{'s' if n_cells != 1 else ''})\"\n    )\n    print(\"-\" * 40)\n\n    # Output performance tags\n    tags_display = self._format_performance_tags(tags_model)\n    if tags_display:\n        print(\"Signature(s):\")\n        tags_line = \" | \".join(tag[\"name\"] for tag in tags_display)\n        print(tags_line)\n\n        print(\"-\" * 40)\n\n    # Report table\n    metrics = [\n        (\n            f\"CPU Util (Across {self.monitor.num_cpus} CPUs)\",\n            \"cpu_util_avg\",\n            \"-\",\n        ),\n        (\n            \"Memory (GB)\",\n            \"memory\",\n            f\"{self.monitor.memory_limits[level]:.2f}\",\n        ),\n        (\n            f\"GPU Util (Across {self.monitor.num_gpus} GPUs)\",\n            \"gpu_util_avg\",\n            \"-\",\n        ),\n        (\n            \"GPU Memory (GB)\",\n            \"gpu_mem_avg\",\n            f\"{self.monitor.gpu_memory:.2f}\",\n        ),\n    ]\n\n    print(f\"{'Metric':&lt;25} {'AVG':&lt;8} {'MIN':&lt;8} {'MAX':&lt;8} {'TOTAL':&lt;8}\")\n    print(\"-\" * 65)\n    for name, col, total in metrics:\n        if col in perfdata.columns:\n            print(\n                f\"{name:&lt;25} {perfdata[col].mean():&lt;8.2f} \"\n                f\"{perfdata[col].min():&lt;8.2f} {perfdata[col].max():&lt;8.2f} \"\n                f\"{total:&lt;8}\"\n            )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.UnavailableReportDisplayer","title":"<code>UnavailableReportDisplayer</code>","text":"Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>class UnavailableReportDisplayer:\n    def __init__(self, reason=\"Display not available.\"):\n        self._reason = reason\n\n    def display(self, cell_range=None, level=\"process\"):\n        \"\"\"non-opt display\"\"\"\n        logger.info(\n            EXTENSION_INFO_MESSAGES[\n                ExtensionInfoCode.HTML_REPORTS_NOT_AVAILABLE\n            ].format(reason=self._reason))\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.UnavailableReportDisplayer.display","title":"<code>display(cell_range=None, level='process')</code>","text":"<p>non-opt display</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>def display(self, cell_range=None, level=\"process\"):\n    \"\"\"non-opt display\"\"\"\n    logger.info(\n        EXTENSION_INFO_MESSAGES[\n            ExtensionInfoCode.HTML_REPORTS_NOT_AVAILABLE\n        ].format(reason=self._reason))\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.reporter.build_performance_reporter","title":"<code>build_performance_reporter(cell_history, templates_dir=None, display_disabled=False, display_disabled_reason='Display not available.', thresholds=None)</code>","text":"<p>Build PerformanceReporter object. Allows building a reporter without displaying.</p> Source code in <code>jumper_extension/adapters/reporter.py</code> <pre><code>def build_performance_reporter(\n    cell_history: CellHistory,\n    templates_dir=None,\n    display_disabled: bool = False,\n    display_disabled_reason=\"Display not available.\",\n    thresholds=None,\n):\n    \"\"\"\n    Build PerformanceReporter object.\n    Allows building a reporter without displaying.\n    \"\"\"\n    monitor = UnavailablePerformanceMonitor(\n        reason=\"Monitor has not been started yet.\"\n    )\n    analyzer = PerformanceAnalyzer(thresholds=thresholds)\n    printer = ReportPrinter(monitor, cell_history, analyzer)\n    if display_disabled:\n        displayer = UnavailableReportDisplayer(\n            reason=display_disabled_reason\n        )\n    else:\n        displayer = ReportDisplayer(\n            monitor,\n            cell_history,\n            analyzer,\n            templates_dir\n        )\n    return PerformanceReporter(printer, displayer)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.visualizer.InteractivePlotWrapper","title":"<code>InteractivePlotWrapper</code>","text":"<p>Interactive plotter with dropdown selection and reusable matplotlib axes.</p> Source code in <code>jumper_extension/adapters/visualizer.py</code> <pre><code>class InteractivePlotWrapper:\n    \"\"\"Interactive plotter with dropdown selection and reusable matplotlib\n    axes.\"\"\"\n\n    def __init__(\n        self,\n        plot_callback,\n        metrics: List[str],\n        labeled_options,\n        perfdata_by_level,\n        cell_range=None,\n        show_idle=False,\n        figsize=None,\n    ):\n        self.plot_callback, self.perfdata_by_level, self.metrics = (\n            plot_callback,\n            perfdata_by_level,\n            metrics,\n        )\n        self.labeled_options = labeled_options\n        self.cell_range, self.show_idle, self.figsize = (\n            cell_range,\n            show_idle,\n            figsize,\n        )\n        self.shown_metrics, self.panel_count, self.max_panels = (\n            set(),\n            0,\n            len(metrics) * 4,\n        )\n        # Store plot panels for updates\n        self.plot_panels = []\n\n        self.output_container = widgets.HBox(\n            layout=Layout(\n                display=\"flex\",\n                flex_flow=\"row wrap\",\n                align_items=\"center\",\n                justify_content=\"space-between\",\n                width=\"100%\",\n            )\n        )\n        self.add_panel_button = widgets.Button(\n            description=\"Add Plot Panel\",\n            layout=Layout(margin=\"0 auto 20px auto\"),\n        )\n        self.add_panel_button.on_click(self._on_add_panel_clicked)\n\n    def display_ui(self):\n        \"\"\"Display the Add button and all interactive panels.\"\"\"\n        display(widgets.VBox([self.add_panel_button, self.output_container]))\n        self._on_add_panel_clicked(None)\n\n    def _on_add_panel_clicked(self, _):\n        \"\"\"Add a new plot panel with dropdown and persistent matplotlib\n        axis.\"\"\"\n        if self.panel_count &gt;= self.max_panels:\n            self.add_panel_button.disabled = True\n            self.output_container.children += (\n                widgets.HTML(\"&lt;b&gt;All panels have been added.&lt;/b&gt;\"),\n            )\n            return\n\n        self.output_container.children += (\n            widgets.HBox(\n                [\n                    self._create_dropdown_plot_panel(),\n                    self._create_dropdown_plot_panel(),\n                ],\n            ),\n        )\n        self.panel_count += 2\n\n        if self.panel_count &gt;= self.max_panels:\n            self.add_panel_button.disabled = True\n\n    def _create_dropdown_plot_panel(self):\n        \"\"\"Create metric and level dropdown + matplotlib figure panel with\n        persistent Axes.\"\"\"\n        metric_dropdown = widgets.Dropdown(\n            options=self.labeled_options,\n            value=self._get_next_metric(),\n            description=\"Metric:\",\n        )\n        level_dropdown = widgets.Dropdown(\n            options=get_available_levels(),\n            value=\"process\",\n            description=\"Level:\",\n        )\n        fig, ax = plt.subplots(figsize=self.figsize, constrained_layout=True)\n        if not is_ipympl_backend():\n            plt.close(fig)\n        output = widgets.Output()\n\n        def update_plot():\n            metric = metric_dropdown.value\n            level = level_dropdown.value\n            df = self.perfdata_by_level.get(level)\n            if not is_ipympl_backend():\n                output.clear_output(wait=True)\n            with output:\n                ax.clear()\n                if df is not None and not df.empty:\n                    self.plot_callback(\n                        df, metric, self.cell_range, self.show_idle, ax, level\n                    )\n                fig.canvas.draw_idle()\n                if not is_ipympl_backend():\n                    display(fig)\n\n        def on_dropdown_change(change):\n            if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n                update_plot()\n\n        metric_dropdown.observe(on_dropdown_change)\n        level_dropdown.observe(on_dropdown_change)\n\n        # Store panel data for updates\n        panel_data = {\n            \"metric_dropdown\": metric_dropdown,\n            \"level_dropdown\": level_dropdown,\n            \"figure\": fig,\n            \"axes\": ax,\n            \"output\": output,\n            \"update_plot\": update_plot,\n        }\n        self.plot_panels.append(panel_data)\n\n        # Initial plot\n        update_plot()\n        if is_ipympl_backend():\n            with output:\n                plt.show()\n\n        return widgets.VBox(\n            [widgets.HBox([metric_dropdown, level_dropdown]), output]\n        )\n\n    def _get_next_metric(self):\n        for metric in self.metrics:\n            if metric not in self.shown_metrics:\n                self.shown_metrics.add(metric)\n                return metric\n        return None\n\n    def update_data(self, perfdata_by_level, cell_range, show_idle):\n        self.perfdata_by_level = perfdata_by_level\n        self.cell_range = cell_range\n        self.show_idle = show_idle\n        for panel in self.plot_panels:\n            panel[\"output\"].clear_output(wait=True)\n            panel[\"update_plot\"]()\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.visualizer.InteractivePlotWrapper.display_ui","title":"<code>display_ui()</code>","text":"<p>Display the Add button and all interactive panels.</p> Source code in <code>jumper_extension/adapters/visualizer.py</code> <pre><code>def display_ui(self):\n    \"\"\"Display the Add button and all interactive panels.\"\"\"\n    display(widgets.VBox([self.add_panel_button, self.output_container]))\n    self._on_add_panel_clicked(None)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.visualizer.PerformanceVisualizer","title":"<code>PerformanceVisualizer</code>","text":"<p>Visualizes performance metrics collected by PerformanceMonitor.</p> <p>Supports multiple levels: 'user', 'process' (default), 'system', and 'slurm' (if available)</p> Source code in <code>jumper_extension/adapters/visualizer.py</code> <pre><code>class PerformanceVisualizer:\n    \"\"\"Visualizes performance metrics collected by PerformanceMonitor.\n\n    Supports multiple levels: 'user', 'process' (default), 'system', and\n    'slurm' (if available)\n    \"\"\"\n\n    def __init__(self, cell_history: CellHistory):\n        self.monitor = UnavailablePerformanceMonitor(\n            reason=\"Monitor has not been started yet.\"\n        )\n        self.cell_history = cell_history\n        self.figsize = (5, 3)\n        self.min_duration = None\n        self._io_window = None\n        self.subsets = {}\n\n    def attach(\n        self,\n        monitor: PerformanceMonitorProtocol,\n    ):\n        \"\"\"Attach started PerformanceMonitor.\"\"\"\n        self.monitor = monitor\n        self.min_duration = self.monitor.interval\n        # Smooth IO with ~1s rolling window based on sampling interval\n        try:\n            self._io_window = max(\n                1, int(round(1.0 / (self.monitor.interval or 1.0)))\n            )\n        except Exception:\n            self._io_window = 1\n        self._build_subsets()\n\n    def _build_subsets(self):\n        \"\"\"Build a dictionary of metric subsets based on the provided\n        configuration\"\"\"\n        # Compressed metrics configuration (dict-based entries for clarity)\n        self.subsets = {\n            \"cpu_all\": {\n                \"cpu\": {\n                    \"type\": \"multi_series\",\n                    \"prefix\": \"cpu_util_\",\n                    \"title\": \"CPU Utilization (%) - Across Cores\",\n                    \"ylim\": (0, 100),\n                    \"label\": \"CPU Utilization (All Cores)\",\n                }\n            },\n            \"gpu_all\": {\n                \"gpu_util\": {\n                    \"type\": \"multi_series\",\n                    \"prefix\": \"gpu_util_\",\n                    \"title\": \"GPU Utilization (%) - Across GPUs\",\n                    \"ylim\": (0, 100),\n                    \"label\": \"GPU Utilization (All GPUs)\",\n                },\n                \"gpu_band\": {\n                    \"type\": \"multi_series\",\n                    \"prefix\": \"gpu_band_\",\n                    \"title\": \"GPU Bandwidth Usage (%) - Across GPUs\",\n                    \"ylim\": (0, 100),\n                    \"label\": \"GPU Bandwidth (All GPUs)\",\n                },\n                \"gpu_mem\": {\n                    \"type\": \"multi_series\",\n                    \"prefix\": \"gpu_mem_\",\n                    \"title\": \"GPU Memory Usage (GB) - Across GPUs\",\n                    \"ylim\": (0, self.monitor.gpu_memory),\n                    \"label\": \"GPU Memory (All GPUs)\",\n                },\n            },\n            \"cpu\": {\n                \"cpu_summary\": {\n                    \"type\": \"summary_series\",\n                    \"columns\": [\n                        \"cpu_util_min\",\n                        \"cpu_util_avg\",\n                        \"cpu_util_max\",\n                    ],\n                    \"title\": (\n                        \"CPU Utilization (%) - \"\n                        f\"{self.monitor.num_cpus} CPUs\"\n                    ),\n                    \"ylim\": (0, 100),\n                    \"label\": \"CPU Utilization Summary\",\n                }\n            },\n            \"gpu\": {\n                \"gpu_util_summary\": {\n                    \"type\": \"summary_series\",\n                    \"columns\": [\n                        \"gpu_util_min\",\n                        \"gpu_util_avg\",\n                        \"gpu_util_max\",\n                    ],\n                    \"title\": (\n                        \"GPU Utilization (%) - \"\n                        f\"{self.monitor.num_gpus} GPUs\"\n                    ),\n                    \"ylim\": (0, 100),\n                    \"label\": \"GPU Utilization Summary\",\n                },\n                \"gpu_band_summary\": {\n                    \"type\": \"summary_series\",\n                    \"columns\": [\n                        \"gpu_band_min\",\n                        \"gpu_band_avg\",\n                        \"gpu_band_max\",\n                    ],\n                    \"title\": (\n                        \"GPU Bandwidth Usage (%) - \"\n                        f\"{self.monitor.num_gpus} GPUs\"\n                    ),\n                    \"ylim\": (0, 100),\n                    \"label\": \"GPU Bandwidth Summary\",\n                },\n                \"gpu_mem_summary\": {\n                    \"type\": \"summary_series\",\n                    \"columns\": [\"gpu_mem_min\", \"gpu_mem_avg\", \"gpu_mem_max\"],\n                    \"title\": (\n                        \"GPU Memory Usage (GB) - \"\n                        f\"{self.monitor.num_gpus} GPUs\"\n                    ),\n                    \"ylim\": (0, self.monitor.gpu_memory),\n                    \"label\": \"GPU Memory Summary\",\n                },\n            },\n            \"mem\": {\n                \"memory\": {\n                    \"type\": \"single_series\",\n                    \"column\": \"memory\",\n                    \"title\": \"Memory Usage (GB)\",\n                    \"ylim\": None,  # Will be set dynamically based on level\n                    \"label\": \"Memory Usage\",\n                }\n            },\n            \"io\": {\n                \"io_read\": {\n                    \"type\": \"single_series\",\n                    \"column\": \"io_read\",\n                    \"title\": \"I/O Read (MB/s)\",\n                    \"ylim\": None,\n                    \"label\": \"IO Read MB/s\",\n                },\n                \"io_write\": {\n                    \"type\": \"single_series\",\n                    \"column\": \"io_write\",\n                    \"title\": \"I/O Write (MB/s)\",\n                    \"ylim\": None,\n                    \"label\": \"IO Write MB/s\",\n                },\n                \"io_read_count\": {\n                    \"type\": \"single_series\",\n                    \"column\": \"io_read_count\",\n                    \"title\": \"I/O Read Operations (ops/s)\",\n                    \"ylim\": None,\n                    \"label\": \"IO Read Ops\",\n                },\n                \"io_write_count\": {\n                    \"type\": \"single_series\",\n                    \"column\": \"io_write_count\",\n                    \"title\": \"I/O Write Operations (ops/s)\",\n                    \"ylim\": None,\n                    \"label\": \"IO Write Ops\",\n                },\n            },\n        }\n\n    def _resolve_metric_subsets(\n        self,\n        metrics: Optional[List[str]]\n    ) -&gt; Tuple[str, ...]:\n        \"\"\"Map user-specified metrics or subsets to visualizer subset keys.\"\"\"\n        if not metrics:\n            return (\"cpu\", \"mem\", \"io\")\n\n        resolved: List[str] = []\n        metric_list = (\n            [metrics]\n            if isinstance(metrics, str)\n            else list(metrics)\n        )\n        for metric in metric_list:\n            if not metric:\n                continue\n            metric_key = str(metric).strip()\n            if metric_key in self.subsets:\n                resolved.append(metric_key)\n                continue\n            found_subset = next(\n                (\n                    subset\n                    for subset, cfg in self.subsets.items()\n                    if metric_key in cfg\n                ),\n                None,\n            )\n            if found_subset:\n                resolved.append(found_subset)\n            else:\n                logger.warning(\n                    EXTENSION_ERROR_MESSAGES[\n                        ExtensionErrorCode.INVALID_METRIC_SUBSET\n                    ].format(\n                        subset=metric_key,\n                        supported_subsets=\", \".join(self.subsets.keys()),\n                    )\n                )\n\n        # Remove duplicates while preserving order; fall back to defaults\n        deduped = tuple(dict.fromkeys(resolved))\n        return deduped or (\"cpu\", \"mem\", \"io\")\n\n    def _compress_time_axis(self, perfdata, cell_range):\n        \"\"\"Compress time axis by removing idle periods between cells\"\"\"\n        if perfdata.empty:\n            return perfdata, []\n\n        start_idx, end_idx = cell_range\n        cell_data = self.cell_history.view(start_idx, end_idx + 1)\n        compressed_perfdata, cell_boundaries, current_time = (\n            perfdata.copy(),\n            [],\n            0,\n        )\n\n        for idx, cell in cell_data.iterrows():\n            cell_mask = (perfdata[\"time\"] &gt;= cell[\"start_time\"]) &amp; (\n                perfdata[\"time\"] &lt;= cell[\"end_time\"]\n            )\n            cell_perfdata = perfdata[cell_mask]\n\n            if not cell_perfdata.empty:\n                original_start, cell_duration = (\n                    cell[\"start_time\"],\n                    cell[\"end_time\"] - cell[\"start_time\"],\n                )\n                compressed_perfdata.loc[cell_mask, \"time\"] = current_time + (\n                    cell_perfdata[\"time\"].values - original_start\n                )\n                cell_boundaries.append(\n                    {\n                        \"cell_index\": cell[\"cell_index\"],\n                        \"start_time\": current_time,\n                        \"end_time\": current_time + cell_duration,\n                        \"duration\": cell_duration,\n                    }\n                )\n                current_time += cell_duration\n\n        return compressed_perfdata, cell_boundaries\n\n    def _plot_direct(self, metric_subsets, cell_range, show_idle, level, save_jpeg=None, pickle_file=None):\n        \"\"\"Plot metrics directly with matplotlib without widgets\"\"\"\n        start_idx, end_idx = cell_range\n        filtered_cells = self.cell_history.view(start_idx, end_idx + 1)\n\n        # Get performance data for the specified level\n        perfdata = filter_perfdata(\n            filtered_cells,\n            self.monitor.data.view(level=level),\n            not show_idle,\n        )\n\n        if perfdata.empty:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[\n                    ExtensionErrorCode.NO_PERFORMANCE_DATA\n                ]\n            )\n            return\n\n        # Process time data\n        if not show_idle:\n            processed_data, self._compressed_cell_boundaries = (\n                self._compress_time_axis(perfdata, cell_range)\n            )\n        else:\n            processed_data = perfdata.copy()\n            processed_data[\"time\"] -= self.monitor.start_time\n\n        # Get metrics for subsets\n        metrics = []\n        for subset in metric_subsets:\n            if subset in self.subsets:\n                for metric_key in self.subsets[subset].keys():\n                    metrics.append(metric_key)\n            else:\n                logger.warning(\n                    EXTENSION_ERROR_MESSAGES[\n                        ExtensionErrorCode.INVALID_METRIC_SUBSET\n                    ].format(\n                        subset=subset,\n                        supported_subsets=\", \".join(self.subsets.keys()),\n                    )\n                )\n\n        if not metrics:\n            logger.warning(\"No valid metrics found to plot\")\n            return\n\n        # Create subplots\n        n_metrics = len(metrics)\n        fig, axes = plt.subplots(n_metrics, 1, figsize=(10, 3 * n_metrics), \n                                constrained_layout=True)\n        if n_metrics == 1:\n            axes = [axes]\n\n        # Plot each metric\n        for i, metric in enumerate(metrics):\n            self._plot_metric(\n                processed_data, metric, cell_range, show_idle, axes[i], level\n            )\n\n        # Handle JPEG saving\n        if save_jpeg:\n            if not save_jpeg.endswith('.jpg') and not save_jpeg.endswith('.jpeg'):\n                save_jpeg += '.jpg'\n            fig.savefig(save_jpeg, format='jpeg', dpi=300, bbox_inches='tight')\n            print(f\"Plot saved as JPEG: {save_jpeg}\")\n\n        # Handle pickle serialization\n        if pickle_file:\n            if not pickle_file.endswith('.pkl'):\n                pickle_file += '.pkl'\n\n            # Create plot data dictionary\n            plot_data = {\n                'figure': fig,\n                'axes': axes,\n                'metrics': metrics,\n                'processed_data': processed_data,\n                'cell_range': cell_range,\n                'level': level,\n                'show_idle': show_idle,\n                'metric_subsets': metric_subsets\n            }\n\n            # Save to pickle file\n            with open(pickle_file, 'wb') as f:\n                pickle.dump(plot_data, f)\n\n            # Print reload code\n            print(f\"Plot objects serialized to: {pickle_file}\")\n            print(\"\\n# Python code to reload and display the plot:\")\n            print(f\"import pickle\")\n            print(f\"import matplotlib.pyplot as plt\")\n            print(f\"\")\n            print(f\"# Load the pickled plot data\")\n            print(f\"with open('{pickle_file}', 'rb') as f:\")\n            print(f\"    plot_data = pickle.load(f)\")\n            print(f\"\")\n            print(f\"# Extract the figure and display\")\n            print(f\"fig = plot_data['figure']\")\n            print(f\"plt.show()\")\n            print(f\"\")\n            print(f\"# Access other data:\")\n            print(f\"# axes = plot_data['axes']\")\n            print(f\"# metrics = plot_data['metrics']\")\n            print(f\"# processed_data = plot_data['processed_data']\")\n            print(f\"# cell_range = plot_data['cell_range']\")\n            print(f\"# level = plot_data['level']\")\n\n        plt.show()\n\n    def _plot_metric(\n        self,\n        df,\n        metric,\n        cell_range=None,\n        show_idle=False,\n        ax: plt.Axes = None,\n        level=\"process\",\n    ):\n        \"\"\"Plot a single metric using its configuration\"\"\"\n        config = next(\n            (\n                subset[metric]\n                for subset in self.subsets.values()\n                if metric in subset\n            ),\n            None,\n        )\n        if not config:\n            return\n\n        # Parse dict-based config format\n        if not isinstance(config, dict):\n            return\n\n        plot_type = config.get(\"type\")\n        if plot_type == \"single_series\":\n            column = config.get(\"column\")\n            title = config.get(\"title\", \"\")\n            ylim = config.get(\"ylim\")\n            # Set dynamic memory limit for memory metric\n            if metric == \"memory\" and ylim is None:\n                ylim = (0, self.monitor.memory_limits[level])\n            if not column or column not in df.columns:\n                return\n        elif plot_type == \"multi_series\":\n            prefix = config.get(\"prefix\", \"\")\n            title = config.get(\"title\", \"\")\n            ylim = config.get(\"ylim\")\n            series_cols = [\n                col\n                for col in df.columns\n                if prefix\n                and col.startswith(prefix)\n                and not col.endswith(\"avg\")\n            ]\n            # Derive average column name from prefix\n            avg_column = f\"{prefix}avg\" if prefix else None\n            if (\n                avg_column is None or avg_column not in df.columns\n            ) and not series_cols:\n                return\n        elif plot_type == \"summary_series\":\n            columns = config.get(\"columns\", [])\n            title = config.get(\"title\", \"\")\n            ylim = config.get(\"ylim\")\n            if level == \"system\":\n                title = re.sub(\n                    r\"\\d+\", str(self.monitor.num_system_cpus), title\n                )\n            available_cols = [col for col in columns if col in df.columns]\n            if not available_cols:\n                return\n        else:\n            return\n\n        if ax is None:\n            fig, ax = plt.subplots(figsize=self.figsize)\n\n        # Plot based on type\n        if plot_type == \"single_series\":\n            series = df[column]\n            # For IO metrics, compute simple diffs from cumulative counters\n            if metric in (\n                \"io_read\",\n                \"io_write\",\n                \"io_read_count\",\n                \"io_write_count\",\n            ):\n                diffs = df[column].astype(float).diff().clip(lower=0)\n                if metric in (\"io_read\", \"io_write\"):\n                    diffs = diffs / (1024**2)  # bytes -&gt; MB\n                series = diffs.fillna(0.0)\n                if self._io_window &gt; 1:\n                    series = series.rolling(\n                        window=self._io_window, min_periods=1\n                    ).mean()\n\n            ax.plot(df[\"time\"], series, color=\"blue\", linewidth=2)\n        elif plot_type == \"summary_series\":\n            line_styles, alpha_vals = [\"dotted\", \"-\", \"--\"], [0.35, 1.0, 0.35]\n            for i, (col, label) in enumerate(\n                zip(columns, [\"Min\", \"Average\", \"Max\"])\n            ):\n                if col in df.columns:\n                    ax.plot(\n                        df[\"time\"],\n                        df[col],\n                        color=\"blue\",\n                        linestyle=line_styles[i % len(line_styles)],\n                        linewidth=2,\n                        alpha=alpha_vals[i % len(alpha_vals)],\n                        label=label,\n                    )\n            ax.legend()\n        elif plot_type == \"multi_series\":\n            for col in series_cols:\n                ax.plot(df[\"time\"], df[col], \"-\", alpha=0.5, label=col)\n            if avg_column in df.columns:\n                ax.plot(\n                    df[\"time\"], df[avg_column], \"b-\", linewidth=2, label=\"Mean\"\n                )\n            ax.legend()\n\n        # Apply settings\n        ax.set_title(title + (\" (No Idle)\" if not show_idle else \"\"))\n        ax.set_xlabel(\"Time (seconds)\")\n        ax.grid(True)\n        if ylim:\n            ax.set_ylim(ylim)\n        self._draw_cell_boundaries(ax, cell_range, show_idle)\n\n    def _draw_cell_boundaries(self, ax, cell_range=None, show_idle=False):\n        \"\"\"Draw cell boundaries as colored rectangles with cell indices\"\"\"\n        colors = jumper_colors\n        y_min, y_max = ax.get_ylim()\n        x_max, height = ax.get_xlim()[1], y_max - y_min\n        min_duration = self.min_duration or 0\n\n        def draw_cell_rect(start_time, duration, cell_num, alpha):\n            if (\n                duration &lt; min_duration\n                or start_time &gt; x_max\n                or start_time + duration &lt; 0\n            ):\n                return\n            color = colors[cell_num % len(colors)]\n            ax.add_patch(\n                plt.Rectangle(\n                    (start_time, y_min),\n                    duration,\n                    height,\n                    facecolor=color,\n                    alpha=alpha,\n                    edgecolor=\"black\",\n                    linestyle=\"--\",\n                    linewidth=1,\n                    zorder=0,\n                )\n            )\n            ax.text(\n                start_time + duration / 2,\n                y_max - height * 0.1,\n                f\"#{cell_num}\",\n                ha=\"center\",\n                va=\"center\",\n                fontsize=10,\n                fontweight=\"bold\",\n                zorder=1,\n                bbox=dict(\n                    boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8\n                ),\n            )\n\n        if not show_idle and hasattr(self, \"_compressed_cell_boundaries\"):\n            for cell in self._compressed_cell_boundaries:\n                draw_cell_rect(\n                    cell[\"start_time\"],\n                    cell[\"duration\"],\n                    int(cell[\"cell_index\"]),\n                    0.4,\n                )\n        else:\n            filtered_cells = self.cell_history.view()\n            if cell_range:\n                try:\n                    mask = (filtered_cells[\"cell_index\"] &gt;= cell_range[0]) &amp; (\n                        filtered_cells[\"cell_index\"] &lt;= cell_range[1]\n                    )\n                    cells = filtered_cells[mask]\n                except Exception:\n                    cells = filtered_cells\n            else:\n                cells = filtered_cells\n            for idx, cell in cells.iterrows():\n                start_time = cell[\"start_time\"] - self.monitor.start_time\n                draw_cell_rect(\n                    start_time, cell[\"duration\"], int(cell[\"cell_index\"]), 0.5\n                )\n\n    def plot(\n        self,\n        metric_subsets=(\"cpu\", \"mem\", \"io\"),\n        cell_range=None,\n        show_idle=False,\n        level=None,\n        save_jpeg=None,\n        pickle_file=None,\n    ):\n        metrics_missing = not metric_subsets\n        if metrics_missing:\n            metric_subsets = (\"cpu\", \"mem\", \"io\")\n            if self.monitor.num_gpus:\n                metric_subsets += (\n                    \"gpu\",\n                    \"gpu_all\",\n                )\n\n        \"\"\"Plot performance metrics with interactive widgets for\n        configuration.\"\"\"\n        valid_cells = self.cell_history.view()\n        if len(valid_cells) == 0:\n            logger.warning(\n                EXTENSION_ERROR_MESSAGES[ExtensionErrorCode.NO_CELL_HISTORY]\n            )\n            return\n\n        # Default to all cells if no range specified\n        try:\n            min_cell_idx = int(valid_cells[\"cell_index\"].min())\n            max_cell_idx = int(valid_cells[\"cell_index\"].max())\n        except Exception:\n            min_cell_idx, max_cell_idx = 0, len(valid_cells) - 1\n        if cell_range is None:\n            cell_start_index = 0\n            for cell_idx in range(len(valid_cells) - 1, -1, -1):\n                if valid_cells.iloc[cell_idx][\"duration\"] &gt; self.min_duration:\n                    cell_start_index = cell_idx\n                    break\n            start = int(valid_cells.iloc[cell_start_index][\"cell_index\"])\n            end = int(valid_cells[\"cell_index\"].max())\n            if start &gt; end:\n                start, end = end, start\n            cell_range = (start, end)\n\n        # If level is specified, plot directly without widgets\n        if level is not None:\n            metric_subsets = self._resolve_metric_subsets(metric_subsets)\n            return self._plot_direct(metric_subsets, cell_range, show_idle,\n                                     level, save_jpeg, pickle_file)\n\n        # Create interactive widgets\n        style = {\"description_width\": \"initial\"}\n        show_idle_checkbox = widgets.Checkbox(\n            value=show_idle, description=\"Show idle periods\"\n        )\n        # Sanitize slider value within bounds and ordered\n        try:\n            s0, s1 = cell_range\n            if s0 &gt; s1:\n                s0, s1 = s1, s0\n            s0 = max(min_cell_idx, min(s0, max_cell_idx))\n            s1 = max(min_cell_idx, min(s1, max_cell_idx))\n            slider_value = (s0, s1)\n        except Exception:\n            slider_value = (min_cell_idx, max_cell_idx)\n        cell_range_slider = widgets.IntRangeSlider(\n            value=slider_value,\n            min=min_cell_idx,\n            max=max_cell_idx,\n            step=1,\n            description=\"Cell range:\",\n            style=style,\n        )\n\n        logo_widget = widgets.HTML(\n            value=f\"&lt;img src=\"\n            f'\"{logo_image}\"'\n            f'alt=\"JUmPER Logo\" style=\"height: auto; width: 100px;\"&gt;'\n        )\n\n        box_layout = Layout(\n            display=\"flex\",\n            flex_flow=\"row wrap\",\n            align_items=\"center\",\n            justify_content=\"space-between\",\n            width=\"100%\",\n        )\n\n        config_widgets = widgets.HBox(\n            [\n                widgets.HTML(\"&lt;b&gt;Plot Configuration:&lt;/b&gt;\"),\n                show_idle_checkbox,\n                cell_range_slider,\n                logo_widget,\n            ],\n            layout=box_layout,\n        )\n        plot_output = widgets.Output()\n\n        # Store the plot wrapper instance for persistent updates\n        plot_wrapper = None\n\n        def update_plots():\n            nonlocal plot_wrapper\n            current_cell_range, current_show_idle = (\n                cell_range_slider.value,\n                show_idle_checkbox.value,\n            )\n            start_idx, end_idx = current_cell_range\n            cells_all = self.cell_history.view()\n            try:\n                mask = (cells_all[\"cell_index\"] &gt;= start_idx) &amp; (\n                    cells_all[\"cell_index\"] &lt;= end_idx\n                )\n                filtered_cells = cells_all[mask]\n            except Exception:\n                filtered_cells = cells_all\n            # Store all level data for subplot access\n            perfdata_by_level = {}\n            for available_level in get_available_levels():\n                perfdata_by_level[available_level] = filter_perfdata(\n                    filtered_cells,\n                    self.monitor.data.view(level=available_level),\n                    not current_show_idle,\n                )\n\n            if all(df.empty for df in perfdata_by_level.values()):\n                with plot_output:\n                    plot_output.clear_output()\n                    logger.warning(\n                        EXTENSION_ERROR_MESSAGES[\n                            ExtensionErrorCode.NO_PERFORMANCE_DATA\n                        ]\n                    )\n                    # Clear plot wrapper when no data\n                    plot_wrapper = None\n                return\n\n            # Handle time compression or show idle for all levels\n            processed_perfdata = {}\n            for level_key, perfdata in perfdata_by_level.items():\n                if not perfdata.empty:\n                    if not current_show_idle:\n                        processed_data, self._compressed_cell_boundaries = (\n                            self._compress_time_axis(\n                                perfdata, current_cell_range\n                            )\n                        )\n                        processed_perfdata[level_key] = processed_data\n                    else:\n                        processed_data = perfdata.copy()\n                        processed_data[\"time\"] -= self.monitor.start_time\n                        processed_perfdata[level_key] = processed_data\n                else:\n                    processed_perfdata[level_key] = perfdata\n\n            # Get metrics for subsets and build labeled dropdown options\n            metrics = []\n            labeled_options = []\n            for subset in metric_subsets:\n                if subset in self.subsets:\n                    for metric_key, cfg in self.subsets[subset].items():\n                        metrics.append(metric_key)\n                        label = (\n                            cfg.get(\"label\")\n                            if isinstance(cfg, dict)\n                            else metric_key\n                        )\n                        labeled_options.append(\n                            (label or metric_key, metric_key)\n                        )\n                else:\n                    logger.warning(\n                        EXTENSION_ERROR_MESSAGES[\n                            ExtensionErrorCode.INVALID_METRIC_SUBSET\n                        ].format(\n                            subset=subset,\n                            supported_subsets=\", \".join(self.subsets.keys()),\n                        )\n                    )\n\n            with plot_output:\n                if plot_wrapper is None:\n                    # Create new plot wrapper only if it doesn't exist\n                    plot_output.clear_output()\n                    plot_wrapper = InteractivePlotWrapper(\n                        self._plot_metric,\n                        metrics,\n                        labeled_options,\n                        processed_perfdata,\n                        current_cell_range,\n                        current_show_idle,\n                        self.figsize,\n                    )\n                    plot_wrapper.display_ui()\n                else:\n                    # Update existing plot wrapper with new data\n                    plot_wrapper.update_data(\n                        processed_perfdata,\n                        current_cell_range,\n                        current_show_idle,\n                    )\n\n        # Set up observers and display\n        for widget in [show_idle_checkbox, cell_range_slider]:\n            widget.observe(lambda change: update_plots(), names=\"value\")\n\n        display(widgets.VBox([config_widgets, plot_output]))\n        update_plots()\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.visualizer.PerformanceVisualizer.attach","title":"<code>attach(monitor)</code>","text":"<p>Attach started PerformanceMonitor.</p> Source code in <code>jumper_extension/adapters/visualizer.py</code> <pre><code>def attach(\n    self,\n    monitor: PerformanceMonitorProtocol,\n):\n    \"\"\"Attach started PerformanceMonitor.\"\"\"\n    self.monitor = monitor\n    self.min_duration = self.monitor.interval\n    # Smooth IO with ~1s rolling window based on sampling interval\n    try:\n        self._io_window = max(\n            1, int(round(1.0 / (self.monitor.interval or 1.0)))\n        )\n    except Exception:\n        self._io_window = 1\n    self._build_subsets()\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.visualizer.PerformanceVisualizerProtocol","title":"<code>PerformanceVisualizerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Structural protocol for visualizers used by the service.</p> Source code in <code>jumper_extension/adapters/visualizer.py</code> <pre><code>@runtime_checkable\nclass PerformanceVisualizerProtocol(Protocol):\n    \"\"\"Structural protocol for visualizers used by the service.\"\"\"\n    def attach(self, monitor: PerformanceMonitorProtocol) -&gt; None: ...\n    def plot(\n        self,\n        metric_subsets=(\"cpu\", \"mem\", \"io\"),\n        cell_range=None,\n        show_idle=False,\n        level=None,\n        save_jpeg=None,\n        pickle_file=None,\n    ) -&gt; None: ...\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.visualizer.UnavailableVisualizer","title":"<code>UnavailableVisualizer</code>","text":"<p>A stub that type-checks against PerformanceVisualizerProtocol but only logs that visualization is unavailable.</p> Source code in <code>jumper_extension/adapters/visualizer.py</code> <pre><code>class UnavailableVisualizer:\n    \"\"\"\n    A stub that type-checks against PerformanceVisualizerProtocol but\n    only logs that visualization is unavailable.\n    \"\"\"\n    def __init__(self, reason: str = \"Plotting not available.\"):\n        self._reason = reason\n\n    def attach(self, monitor: PerformanceMonitorProtocol) -&gt; None: ...\n\n    def plot(\n        self,\n        metric_subsets=(\"cpu\", \"mem\", \"io\"),\n        cell_range=None,\n        show_idle=False,\n    ) -&gt; None:\n        logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.PLOTS_NOT_AVAILABLE].format(\n                reason=self._reason\n            )\n        )\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.visualizer.build_performance_visualizer","title":"<code>build_performance_visualizer(cell_history, plots_disabled=False, plots_disabled_reason='Plotting not available.')</code>","text":"<p>Build PerformanceVisualizer object. Allows building a visualizer that degrades to a no-op when plots are disabled.</p> Source code in <code>jumper_extension/adapters/visualizer.py</code> <pre><code>def build_performance_visualizer(\n    cell_history: CellHistory,\n    plots_disabled: bool = False,\n    plots_disabled_reason: str = \"Plotting not available.\",\n) -&gt; PerformanceVisualizerProtocol:\n    \"\"\"\n    Build PerformanceVisualizer object.\n    Allows building a visualizer that degrades to a no-op when plots are disabled.\n    \"\"\"\n    if plots_disabled:\n        return UnavailableVisualizer(reason=plots_disabled_reason)\n    return PerformanceVisualizer(cell_history)\n</code></pre>"},{"location":"internals/adapters/#sessions-and-scripts","title":"Sessions and scripts","text":""},{"location":"internals/adapters/#jumper_extension.adapters.session.SessionExporter","title":"<code>SessionExporter</code>","text":"<p>Handles exporting a monitoring session to directory/ZIP.</p> Source code in <code>jumper_extension/adapters/session.py</code> <pre><code>class SessionExporter:\n    \"\"\"Handles exporting a monitoring session to directory/ZIP.\"\"\"\n\n    def __init__(self, monitor, cell_history, visualizer, reporter, logger):\n        self.monitor = monitor\n        self.cell_history = cell_history\n        self.visualizer = visualizer\n        self.reporter = reporter\n        self.logger = logger\n\n    def export(self, path: Optional[str] = None) -&gt; str:\n        \"\"\"Export session to a directory or, if path ends with .zip, to a zip archive.\n\n        Returns the path to the exported directory or created archive.\n        \"\"\"\n        export_dir, zip_target = self._determine_export_paths(path)\n        os.makedirs(export_dir, exist_ok=True)\n\n        schemas_perf = self._export_performance_data(export_dir)\n        ch_df = self._export_cell_history(export_dir)\n        manifest = self._build_manifest(schemas_perf, ch_df)\n        self._write_manifest(export_dir, manifest)\n\n        if zip_target:\n            return self._create_zip_archive(export_dir, zip_target)\n\n        self.logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.EXPORT_SUCCESS].format(\n                filename=export_dir\n            )\n        )\n        return export_dir\n\n    def _determine_export_paths(self, path: Optional[str]) -&gt; tuple:\n        \"\"\"Determine the export directory and optional ZIP target path.\n\n        Returns:\n            tuple: (export_dir, zip_target) where zip_target is None if not creating a ZIP\n        \"\"\"\n        zip_target = None\n\n        if path and path.lower().endswith(\".zip\"):\n            export_dir = tempfile.mkdtemp(prefix=\"jumper-session-\")\n            zip_target = path\n        else:\n            export_dir = os.path.abspath(path or self._default_session_dirname())\n\n        return export_dir, zip_target\n\n    def _export_performance_data(self, export_dir: str) -&gt; Dict[str, List[str]]:\n        \"\"\"Export performance data CSVs for each monitoring level.\n\n        Args:\n            export_dir: Directory to write CSV files to\n\n        Returns:\n            Dict mapping level names to their column schemas\n        \"\"\"\n        schemas_perf: Dict[str, List[str]] = {}\n        level_filenames = {\n            \"process\": \"perf_process.csv\",\n            \"user\": \"perf_user.csv\",\n            \"system\": \"perf_system.csv\",\n            \"slurm\": \"perf_slurm.csv\",\n        }\n\n        for level, df in self.monitor.data.data.items():\n            try:\n                df_out = self.monitor.data.view(level=level, cell_history=self.cell_history)\n            except Exception:\n                df_out = df\n            schemas_perf[level] = list(df_out.columns)\n            if not df_out.empty:\n                fname = level_filenames.get(level, f\"perf_{level}.csv\")\n                df_out.to_csv(os.path.join(export_dir, fname), index=False)\n\n        return schemas_perf\n\n    def _export_cell_history(self, export_dir: str) -&gt; pd.DataFrame:\n        \"\"\"Export cell history to CSV.\n\n        Args:\n            export_dir: Directory to write the cell history CSV to\n\n        Returns:\n            DataFrame containing the cell history\n        \"\"\"\n        ch_df = self.cell_history.view()\n        if not ch_df.empty:\n            ch_df.to_csv(os.path.join(export_dir, \"cell_history.csv\"), index=False)\n        return ch_df\n\n    def _build_manifest(self, schemas_perf: Dict[str, List[str]], ch_df: pd.DataFrame) -&gt; dict:\n        \"\"\"Build the manifest dictionary containing session metadata.\n\n        Args:\n            schemas_perf: Performance data schemas by level\n            ch_df: Cell history DataFrame\n\n        Returns:\n            Manifest dictionary\n        \"\"\"\n        return {\n            \"version\": \"1.0\",\n            \"app\": {\"name\": \"JUmPER\", \"version\": self._app_version()},\n            \"monitor\": {\n                \"interval\": getattr(self.monitor, \"interval\", 1.0),\n                \"start_time\": getattr(self.monitor, \"start_time\", None),\n                \"stop_time\": getattr(self.monitor, \"stop_time\", None),\n                \"num_cpus\": getattr(self.monitor, \"num_cpus\", 0),\n                \"num_system_cpus\": getattr(self.monitor, \"num_system_cpus\", 0),\n                \"num_gpus\": getattr(self.monitor, \"num_gpus\", 0),\n                \"gpu_memory\": getattr(self.monitor, \"gpu_memory\", 0.0),\n                \"gpu_name\": getattr(self.monitor, \"gpu_name\", \"\"),\n                \"memory_limits\": getattr(self.monitor, \"memory_limits\", {}),\n                \"cpu_handles\": getattr(self.monitor, \"cpu_handles\", []),\n                \"pid\": getattr(self.monitor, \"pid\", None),\n                \"uid\": getattr(self.monitor, \"uid\", None),\n                \"slurm_job\": getattr(self.monitor, \"slurm_job\", None),\n                \"os\": os.name,\n                \"python\": sys.version.split(\" \")[0],\n            },\n            \"levels\": list(self.monitor.data.data.keys()),\n            \"schemas\": {\n                \"perf\": schemas_perf,\n                \"cell_history\": list(ch_df.columns),\n            },\n            \"visualizer\": {\n                \"default_metric_subsets\": [\n                    \"cpu\",\n                    \"mem\",\n                    \"io\",\n                ] + ([\"gpu\", \"gpu_all\"] if getattr(self.monitor, \"num_gpus\", 0) else []),\n                \"figsize\": list(getattr(self.visualizer, \"figsize\", (5, 3))),\n                \"io_window\": getattr(self.visualizer, \"_io_window\", None),\n                \"last_state\": {},\n            },\n            \"reporter\": {\n                \"level\": getattr(self.reporter, \"level\", \"process\") if hasattr(self.reporter, \"level\") else \"process\",\n                \"format\": \"text\",\n                \"thresholds\": getattr(self.reporter.printer.analyzer, \"thresholds\", {}),\n            },\n            \"time_origin\": \"perf_counter\",\n            \"timezone\": time.tzname[0] if time.tzname else \"\",\n        }\n\n    def _write_manifest(self, export_dir: str, manifest: dict) -&gt; None:\n        \"\"\"Write the manifest JSON file to the export directory.\n\n        Args:\n            export_dir: Directory to write the manifest to\n            manifest: Manifest dictionary to serialize\n        \"\"\"\n        with open(os.path.join(export_dir, \"manifest.json\"), \"w\", encoding=\"utf-8\") as f:\n            json.dump(manifest, f, indent=2)\n\n    def _create_zip_archive(self, export_dir: str, zip_target: str) -&gt; str:\n        \"\"\"Create a ZIP archive from the export directory and clean up.\n\n        Args:\n            export_dir: Directory containing exported files\n            zip_target: Path to the ZIP file to create\n\n        Returns:\n            Path to the created ZIP file\n        \"\"\"\n        with zipfile.ZipFile(zip_target, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n            for root, _, files in os.walk(export_dir):\n                for name in files:\n                    ap = os.path.join(root, name)\n                    rel = os.path.relpath(ap, export_dir)\n                    zf.write(ap, rel)\n\n        self.logger.info(\n            EXTENSION_INFO_MESSAGES[ExtensionInfoCode.EXPORT_SUCCESS].format(\n                filename=zip_target\n            )\n        )\n\n        # Clean up temp dir\n        try:\n            shutil.rmtree(export_dir)\n        except Exception:\n            pass\n\n        return zip_target\n\n    def _default_session_dirname(self) -&gt; str:\n        ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        return f\"jumper-session-{ts}\"\n\n    def _app_version(self) -&gt; str:\n        try:\n            here = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n            pyproject = os.path.join(here, \"..\", \"pyproject.toml\")\n            pyproject = os.path.normpath(pyproject)\n            if os.path.exists(pyproject):\n                with open(pyproject, \"r\", encoding=\"utf-8\") as f:\n                    for line in f:\n                        s = line.strip()\n                        if s.startswith(\"version\") and \"=\" in s:\n                            val = s.split(\"=\", 1)[1].strip().strip('\"')\n                            if val:\n                                return val\n        except Exception:\n            pass\n        return \"unknown\"\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.session.SessionExporter.export","title":"<code>export(path=None)</code>","text":"<p>Export session to a directory or, if path ends with .zip, to a zip archive.</p> <p>Returns the path to the exported directory or created archive.</p> Source code in <code>jumper_extension/adapters/session.py</code> <pre><code>def export(self, path: Optional[str] = None) -&gt; str:\n    \"\"\"Export session to a directory or, if path ends with .zip, to a zip archive.\n\n    Returns the path to the exported directory or created archive.\n    \"\"\"\n    export_dir, zip_target = self._determine_export_paths(path)\n    os.makedirs(export_dir, exist_ok=True)\n\n    schemas_perf = self._export_performance_data(export_dir)\n    ch_df = self._export_cell_history(export_dir)\n    manifest = self._build_manifest(schemas_perf, ch_df)\n    self._write_manifest(export_dir, manifest)\n\n    if zip_target:\n        return self._create_zip_archive(export_dir, zip_target)\n\n    self.logger.info(\n        EXTENSION_INFO_MESSAGES[ExtensionInfoCode.EXPORT_SUCCESS].format(\n            filename=export_dir\n        )\n    )\n    return export_dir\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.session.SessionImporter","title":"<code>SessionImporter</code>","text":"<p>Handles importing a monitoring session from directory/ZIP.</p> Source code in <code>jumper_extension/adapters/session.py</code> <pre><code>class SessionImporter:\n    \"\"\"Handles importing a monitoring session from directory/ZIP.\"\"\"\n\n    def __init__(self, logger):\n        self.logger = logger\n\n    def import_(self, path: str, service) -&gt; bool:\n        \"\"\"Import a session into the given service. Returns True on success.\"\"\"\n        if not path:\n            return False\n\n        work_dir, cleanup_dir = self._prepare_work_directory(path)\n\n        try:\n            manifest = self._load_manifest(work_dir)\n            self._load_cell_history(work_dir, service)\n            perf_dfs = self._load_performance_data(work_dir)\n\n            self._setup_offline_monitor(manifest, perf_dfs, service, source=path)\n            self._setup_reporter(manifest, service)\n            self._apply_visualizer_settings(manifest, service)\n\n            return True\n        finally:\n            if cleanup_dir and work_dir and os.path.isdir(work_dir):\n                try:\n                    shutil.rmtree(work_dir)\n                except Exception:\n                    pass\n\n    def _prepare_work_directory(self, path: str) -&gt; tuple:\n        \"\"\"Prepare the work directory from ZIP or direct path.\n\n        Args:\n            path: Path to ZIP file or directory\n\n        Returns:\n            tuple: (work_dir, cleanup_dir) where cleanup_dir indicates if temp dir should be cleaned\n        \"\"\"\n        if path.lower().endswith(\".zip\"):\n            work_dir = tempfile.mkdtemp(prefix=\"jumper-session-import-\")\n            with zipfile.ZipFile(path, \"r\") as zf:\n                zf.extractall(work_dir)\n            return work_dir, True\n        else:\n            return path, False\n\n    def _load_manifest(self, work_dir: str) -&gt; dict:\n        \"\"\"Load the manifest JSON file from the work directory.\n\n        Args:\n            work_dir: Directory containing the manifest file\n\n        Returns:\n            Manifest dictionary\n        \"\"\"\n        manifest_path = os.path.join(work_dir, \"manifest.json\")\n        with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    def _load_cell_history(self, work_dir: str, service) -&gt; None:\n        \"\"\"Load cell history data from CSV into the service.\n\n        Args:\n            work_dir: Directory containing the cell history CSV\n            service: Service object to load data into\n        \"\"\"\n        ch_csv = os.path.join(work_dir, \"cell_history.csv\")\n        if os.path.exists(ch_csv):\n            try:\n                service.cell_history.data = pd.read_csv(ch_csv)\n            except Exception:\n                pass\n\n    def _load_performance_data(self, work_dir: str) -&gt; Dict[str, pd.DataFrame]:\n        \"\"\"Load performance data CSVs from the work directory.\n\n        Args:\n            work_dir: Directory containing performance CSV files\n\n        Returns:\n            Dict mapping level names to their DataFrames\n        \"\"\"\n        level_files = {\n            \"process\": \"perf_process.csv\",\n            \"user\": \"perf_user.csv\",\n            \"system\": \"perf_system.csv\",\n            \"slurm\": \"perf_slurm.csv\",\n        }\n        perf_dfs: Dict[str, pd.DataFrame] = {}\n\n        for level, fname in level_files.items():\n            fpath = os.path.join(work_dir, fname)\n            if os.path.exists(fpath):\n                try:\n                    perf_dfs[level] = pd.read_csv(fpath)\n                except Exception:\n                    continue\n\n        return perf_dfs\n\n    def _setup_offline_monitor(self, manifest: dict, perf_dfs: Dict[str, pd.DataFrame], service, source: Optional[str]) -&gt; None:\n        \"\"\"Create and attach an offline performance monitor to the service.\n\n        Args:\n            manifest: Manifest dictionary with monitor configuration\n            perf_dfs: Performance data DataFrames by level\n            service: Service object to attach monitor to\n        \"\"\"\n        offline = OfflinePerformanceMonitor(\n            manifest=manifest,\n            perf_dfs=perf_dfs,\n            source=source,\n        )\n        service.monitor = offline\n        service.visualizer.attach(service.monitor)\n\n    def _setup_reporter(self, manifest: dict, service) -&gt; None:\n        \"\"\"Rebuild and attach the performance reporter with thresholds from manifest.\n\n        Args:\n            manifest: Manifest dictionary with reporter configuration\n            service: Service object to attach reporter to\n        \"\"\"\n        thresholds = None\n        try:\n            thresholds = manifest.get(\"reporter\", {}).get(\"thresholds\")\n        except Exception:\n            thresholds = None\n\n        from jumper_extension.adapters.reporter import build_performance_reporter\n\n        service.reporter = build_performance_reporter(\n            service.cell_history,\n            display_disabled=False,\n            display_disabled_reason=\"Display not available.\",\n            thresholds=thresholds,\n        )\n        service.reporter.attach(service.monitor)\n\n    def _apply_visualizer_settings(self, manifest: dict, service) -&gt; None:\n        \"\"\"Apply visualizer settings from the manifest to the service.\n\n        Args:\n            manifest: Manifest dictionary with visualizer configuration\n            service: Service object with visualizer to configure\n        \"\"\"\n        try:\n            viz = manifest.get(\"visualizer\", {})\n            if isinstance(viz.get(\"figsize\"), list) and len(viz.get(\"figsize\")) == 2:\n                service.visualizer.figsize = (viz[\"figsize\"][0], viz[\"figsize\"][1])\n            if viz.get(\"io_window\"):\n                try:\n                    service.visualizer._io_window = int(viz.get(\"io_window\"))\n                except Exception:\n                    pass\n        except Exception:\n            pass\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.session.SessionImporter.import_","title":"<code>import_(path, service)</code>","text":"<p>Import a session into the given service. Returns True on success.</p> Source code in <code>jumper_extension/adapters/session.py</code> <pre><code>def import_(self, path: str, service) -&gt; bool:\n    \"\"\"Import a session into the given service. Returns True on success.\"\"\"\n    if not path:\n        return False\n\n    work_dir, cleanup_dir = self._prepare_work_directory(path)\n\n    try:\n        manifest = self._load_manifest(work_dir)\n        self._load_cell_history(work_dir, service)\n        perf_dfs = self._load_performance_data(work_dir)\n\n        self._setup_offline_monitor(manifest, perf_dfs, service, source=path)\n        self._setup_reporter(manifest, service)\n        self._apply_visualizer_settings(manifest, service)\n\n        return True\n    finally:\n        if cleanup_dir and work_dir and os.path.isdir(work_dir):\n            try:\n                shutil.rmtree(work_dir)\n            except Exception:\n                pass\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.script_writer.NotebookScriptWriter","title":"<code>NotebookScriptWriter</code>","text":"<p>Class for writing notebook content to a Python script.</p> <p>Collects code from cells and saves it to a Python file with optional metadata about execution time and cell numbers.</p> Source code in <code>jumper_extension/adapters/script_writer.py</code> <pre><code>class NotebookScriptWriter:\n    \"\"\"\n    Class for writing notebook content to a Python script.\n\n    Collects code from cells and saves it to a Python file with optional\n    metadata about execution time and cell numbers.\n    \"\"\"\n\n    def __init__(self, cell_history: CellHistory):\n        self.cell_history = cell_history\n        self.output_path = None\n        # recording state\n        self._recording = False\n        self._start_time = None\n        self._start_cell_index: Optional[int] = None\n        self._settings_state = Settings()\n        # names of magics that start/stop script writing (to exclude their cells)\n        self._control_magics = {\"start_write_script\", \"end_write_script\"}\n\n    def is_recording_active(self) -&gt; bool:\n        \"\"\"Check if cell is being recorded.\"\"\"\n        return self._recording\n\n    def start_recording(self, settings_state: Settings, output_path: Optional[str] = None):\n        \"\"\"\n        Start recording code from cells.\n\n        Args:\n            settings_state: Extension settings at the time of recording started\n            output_path: Path to the output file (overrides value from __init__)\n        \"\"\"\n        self._settings_state = settings_state\n        if output_path:\n            self.output_path = output_path\n        else:\n            # Generate default filename\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            self.output_path = f\"notebook_script_{timestamp}.py\"\n\n        # mark the current tail of CellHistory; everything after this point is \"to be written\"\n        self._recording = True\n        self._start_time = datetime.now()\n        # exclude the cell that triggered the start magic itself\n        self._start_cell_index = len(self.cell_history)\n\n    def stop_recording(self) -&gt; Optional[str]:\n        \"\"\"\n        Stop recording and save accumulated code to file.\n\n        Returns:\n            Path to the created file or None on error\n        \"\"\"\n        if not self._recording:\n            logger.warning(\"[JUmPER]: Recording was not started\")\n            return None\n\n        # collect cells recorded since start, excluding start/end control magic cells\n        try:\n            history = self.cell_history.view()\n        except Exception as e:\n            logger.error(f\"[JUmPER]: Failed to access CellHistory: {e}\")\n            return None\n\n        if history is None or history.empty:\n            logger.warning(\"[JUmPER]: No cells in CellHistory\")\n            return None\n\n        selected = []\n        for _, row in history.iterrows():\n            try:\n                idx = int(row.get(\"cell_index\"))\n            except Exception:\n                continue\n            if self._start_cell_index is not None and idx &lt; self._start_cell_index:\n                continue\n            if self.is_control_cell(row.get(\"cell_magics\")):\n                continue\n            selected.append(\n                {\n                    \"index\": idx,\n                    \"timestamp\": datetime.fromtimestamp(row[\"start_time\"])\n                    if isinstance(row.get(\"start_time\"), (int, float))\n                    else self._start_time or datetime.now(),\n                    \"raw_cell\": row.get(\"raw_cell\", \"\"),\n                    \"cell_magics\": row.get(\"cell_magics\") or [],\n                }\n            )\n\n        if not selected:\n            logger.warning(\"[JUmPER]: No recorded cells to save\")\n            # reset state\n            self._recording = False\n            self._start_cell_index = None\n            return None\n\n        try:\n            self._write_to_file(selected)\n            logger.info(\n                f\"[JUmPER]: Recorded {len(selected)} cells \"\n                f\"to file '{self.output_path}'\"\n            )\n            return self.output_path\n        except Exception as e:\n            logger.error(\n                f\"[JUmPER]: Error writing file: {e}\"\n            )\n            return None\n        finally:\n            # reset state\n            self._recording = False\n            self._start_cell_index = None\n\n    def is_control_cell(self, cell_magics):\n        \"\"\"Select cells with index &gt;= start and exclude cells that contain control magics\"\"\"\n        if cell_magics is None:\n            return False\n        try:\n            for m in cell_magics:\n                # m may be like \"%perfmonitor_start ...\" or \"perfmonitor_start ...\"\n                name = m.lstrip(\"%\")\n                name = name.split(maxsplit=1)[0]\n                if name in self._control_magics:\n                    return True\n        except Exception:\n            pass\n        return False\n    def _write_to_file(self, recorded_cells: List[dict]):\n        \"\"\"\n        Write accumulated cells to Python file.\n        \"\"\"\n        output_path = Path(self.output_path)\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            # File header\n            header = dedent(f\"\"\"\\\n                #!/usr/bin/env python3\n                \\\"\\\"\\\"\n                Auto-generated script from Jupyter notebook\n                Generated: {datetime.now():%Y-%m-%d %H:%M:%S}\n                Recording started: {self._start_time:%Y-%m-%d %H:%M:%S} if self._start_time else \"\"\n                Total cells: {len(recorded_cells)}\n                \\\"\\\"\\\"\n\n                from jumper_extension.core.service import build_perfmonitor_magic_adapter\n                magic_adapter = build_perfmonitor_magic_adapter(\n                    plots_disabled=True,\n                    plots_disabled_reason=\"Plotting disabled in generated script.\",\n                    display_disabled=True,\n                    display_disabled_reason=\"Display disabled in generated script.\"\n                )\n\n                {self._restore_perfmonitor()}\n            \"\"\")\n            f.write(header)\n\n            # Write code from each recorded cell\n            for cell in recorded_cells:\n                f.write(f\"# Cell {cell['index']}\\n\")\n                ts = cell['timestamp']\n                f.write(f\"# Recorded at: {ts.strftime('%H:%M:%S') if isinstance(ts, datetime) else ts}\\n\")\n                raw_cell = cell.get(\"raw_cell\", \"\")\n                f.write(\"# --- Cell print ---\\n\")\n                f.write(f\"raw_cell = {raw_cell!r}\\n\")\n                f.write(f\"print('-' * 40)\\n\")\n                f.write(f\"print('Cell {cell['index']}')\\n\")\n                f.write(f\"print('-' * 40)\\n\")\n                f.write(f\"print(raw_cell)\\n\")\n                f.write(\"print('-' * 13 + ' Cell output ' + '-' * 14)\\n\")\n                cell_magics = cell.get(\"cell_magics\") or []\n                # compute should_skip_report: True if cell contains only line magics (non-empty lines start with '%')\n                non_empty_lines = [ln for ln in raw_cell.splitlines() if ln.strip()]\n                is_pure_magic = bool(non_empty_lines) and all(ln.lstrip().startswith(\"%\") for ln in non_empty_lines)\n                f.write(\n                    \"magic_adapter.on_pre_run_cell(\"\n                    f\"raw_cell, \"\n                    f\"{cell_magics!r}, \"\n                    f\"{is_pure_magic!r}\"\n                    \")\\n\"\n                )\n                f.write(\"# --- Cell content ---\\n\")\n                transformed = self._transform_cell_code(\n                    raw_cell,\n                    cell_magics\n                )\n                f.write(f\"{transformed}\\n\")\n                f.write(\"# --- Cell End -------\\n\")\n                f.write(\"magic_adapter.on_post_run_cell('')\\n\")\n                f.write(\"\\n\")\n            base_name = output_path.stem\n            perf_csv = f\"{base_name}_perfdata.csv\"\n            cell_csv = f\"{base_name}_cell_history.csv\"\n            footer = dedent(\n                f\"\"\"\\\n                # --- Export results to CSV ---\n                # Performance data by level (default level from settings)\n                magic_adapter.perfmonitor_export_perfdata(\"--file {perf_csv}\")\n                # Cell execution history\n                magic_adapter.perfmonitor_export_cell_history(\"--file {cell_csv}\")\n                \"\"\"\n            )\n            f.write(footer)\n\n    def _restore_perfmonitor(self) -&gt; str:\n        if self._settings_state.monitoring.running:\n            settings = self._settings_state\n\n            # Determine interval to restore\n            interval = settings.monitoring.user_interval\n            if not interval:\n                interval = settings.monitoring.default_interval\n\n            # If auto-reports were enabled, a single enable call will both start monitoring\n            # (if needed) and configure reports consistently with original settings.\n            if settings.perfreports.enabled:\n                level = settings.perfreports.level\n                args = f\"--level {level} --interval {interval}\"\n                if settings.perfreports.text:\n                    args += \" --text\"\n                return f\"magic_adapter.perfmonitor_enable_perfreports({args!r})\\n\"\n\n            # Otherwise just restore monitor start with the same interval\n            return f\"magic_adapter.perfmonitor_start({str(interval)!r})\\n\"\n\n        return \"\"\n\n    def _transform_cell_code(self, raw_cell: str, cell_magics: List[str]) -&gt; str:\n        \"\"\"\n        Replace captured magic commands with magic_adapter calls while keeping\n        the rest of the code intact.\n        \"\"\"\n        if not raw_cell:\n            return \"\"\n\n        # Build a lookup from magic line prefix to magic_adapter call string\n        # We rely on CellHistory.cell_magics entries having the original magic lines (e.g. \"%perfmonitor_start 1.0\")\n        replacements = {}\n        for magic in cell_magics:\n            # Normalize leading '%'\n            stripped_no_pct = magic[1:] if magic.startswith(\"%\") else magic\n            parts = stripped_no_pct.split(maxsplit=1)\n            cmd = parts[0]\n            args = parts[1] if len(parts) &gt; 1 else \"\"\n            # construct a Python call to the magic_adapter method\n            # prefer passing the whole \"line\" string of arguments\n            if args:\n                call = f\"magic_adapter.{cmd}({args!r})\"\n            else:\n                # Methods generally accept a single 'line' argument; pass empty string for uniformity\n                call = f'magic_adapter.{cmd}(\"\")'\n            # map original magic literal (with or without %) to replacement\n            replacements[magic] = call\n            # also allow matching without the leading '%', just in case\n            replacements[stripped_no_pct] = call\n\n        # Now transform the cell line by line\n        out_lines: List[str] = []\n        for line in raw_cell.splitlines():\n            lstrip = line.lstrip()\n            # Only attempt replacement if line starts with a magic marker\n            if lstrip.startswith(\"%\"):\n                # Exact match by full line (common for bare magic lines)\n                rep = replacements.get(lstrip)\n                if rep is None:\n                    # Try by the first token\n                    key = lstrip.split(\"#\", 1)[0].strip()  # drop trailing inline comments if any\n                    rep = replacements.get(key)\n                if rep is None:\n                    # As a fallback, try to parse and replace if it's one of captured commands\n                    token = lstrip[1:].split(maxsplit=1)[0]\n                    for k, v in replacements.items():\n                        if k.lstrip(\"%\").split(maxsplit=1)[0] == token:\n                            rep = v\n                            break\n                if rep is not None:\n                    # keep original indentation\n                    indent = line[: len(line) - len(lstrip)]\n                    out_lines.append(f\"{indent}{rep}\")\n                    continue\n            out_lines.append(line)\n        return \"\\n\".join(out_lines)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.script_writer.NotebookScriptWriter.is_control_cell","title":"<code>is_control_cell(cell_magics)</code>","text":"<p>Select cells with index &gt;= start and exclude cells that contain control magics</p> Source code in <code>jumper_extension/adapters/script_writer.py</code> <pre><code>def is_control_cell(self, cell_magics):\n    \"\"\"Select cells with index &gt;= start and exclude cells that contain control magics\"\"\"\n    if cell_magics is None:\n        return False\n    try:\n        for m in cell_magics:\n            # m may be like \"%perfmonitor_start ...\" or \"perfmonitor_start ...\"\n            name = m.lstrip(\"%\")\n            name = name.split(maxsplit=1)[0]\n            if name in self._control_magics:\n                return True\n    except Exception:\n        pass\n    return False\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.script_writer.NotebookScriptWriter.is_recording_active","title":"<code>is_recording_active()</code>","text":"<p>Check if cell is being recorded.</p> Source code in <code>jumper_extension/adapters/script_writer.py</code> <pre><code>def is_recording_active(self) -&gt; bool:\n    \"\"\"Check if cell is being recorded.\"\"\"\n    return self._recording\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.script_writer.NotebookScriptWriter.start_recording","title":"<code>start_recording(settings_state, output_path=None)</code>","text":"<p>Start recording code from cells.</p> <p>Parameters:</p> Name Type Description Default <code>settings_state</code> <code>Settings</code> <p>Extension settings at the time of recording started</p> required <code>output_path</code> <code>Optional[str]</code> <p>Path to the output file (overrides value from init)</p> <code>None</code> Source code in <code>jumper_extension/adapters/script_writer.py</code> <pre><code>def start_recording(self, settings_state: Settings, output_path: Optional[str] = None):\n    \"\"\"\n    Start recording code from cells.\n\n    Args:\n        settings_state: Extension settings at the time of recording started\n        output_path: Path to the output file (overrides value from __init__)\n    \"\"\"\n    self._settings_state = settings_state\n    if output_path:\n        self.output_path = output_path\n    else:\n        # Generate default filename\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        self.output_path = f\"notebook_script_{timestamp}.py\"\n\n    # mark the current tail of CellHistory; everything after this point is \"to be written\"\n    self._recording = True\n    self._start_time = datetime.now()\n    # exclude the cell that triggered the start magic itself\n    self._start_cell_index = len(self.cell_history)\n</code></pre>"},{"location":"internals/adapters/#jumper_extension.adapters.script_writer.NotebookScriptWriter.stop_recording","title":"<code>stop_recording()</code>","text":"<p>Stop recording and save accumulated code to file.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Path to the created file or None on error</p> Source code in <code>jumper_extension/adapters/script_writer.py</code> <pre><code>def stop_recording(self) -&gt; Optional[str]:\n    \"\"\"\n    Stop recording and save accumulated code to file.\n\n    Returns:\n        Path to the created file or None on error\n    \"\"\"\n    if not self._recording:\n        logger.warning(\"[JUmPER]: Recording was not started\")\n        return None\n\n    # collect cells recorded since start, excluding start/end control magic cells\n    try:\n        history = self.cell_history.view()\n    except Exception as e:\n        logger.error(f\"[JUmPER]: Failed to access CellHistory: {e}\")\n        return None\n\n    if history is None or history.empty:\n        logger.warning(\"[JUmPER]: No cells in CellHistory\")\n        return None\n\n    selected = []\n    for _, row in history.iterrows():\n        try:\n            idx = int(row.get(\"cell_index\"))\n        except Exception:\n            continue\n        if self._start_cell_index is not None and idx &lt; self._start_cell_index:\n            continue\n        if self.is_control_cell(row.get(\"cell_magics\")):\n            continue\n        selected.append(\n            {\n                \"index\": idx,\n                \"timestamp\": datetime.fromtimestamp(row[\"start_time\"])\n                if isinstance(row.get(\"start_time\"), (int, float))\n                else self._start_time or datetime.now(),\n                \"raw_cell\": row.get(\"raw_cell\", \"\"),\n                \"cell_magics\": row.get(\"cell_magics\") or [],\n            }\n        )\n\n    if not selected:\n        logger.warning(\"[JUmPER]: No recorded cells to save\")\n        # reset state\n        self._recording = False\n        self._start_cell_index = None\n        return None\n\n    try:\n        self._write_to_file(selected)\n        logger.info(\n            f\"[JUmPER]: Recorded {len(selected)} cells \"\n            f\"to file '{self.output_path}'\"\n        )\n        return self.output_path\n    except Exception as e:\n        logger.error(\n            f\"[JUmPER]: Error writing file: {e}\"\n        )\n        return None\n    finally:\n        # reset state\n        self._recording = False\n        self._start_cell_index = None\n</code></pre>"},{"location":"internals/architecture/","title":"Architecture","text":"<p>The JUmPER IPython extension is organized as a set of layers that separate public APIs from internal monitoring, visualization, and storage components. The diagrams in the <code>Public API</code> and <code>Underlying Structure</code> images, together with the internal documentation, describe how these layers fit together.</p>"},{"location":"internals/architecture/#public-api-layers","title":"Public API layers","text":"<p>The <code>Public API</code> diagram shows how user\u2011facing entry points build on top of a single core service:</p> <ul> <li> <p>IPython.core.magic.Magics   The base IPython API for defining line magics. The <code>PerfmonitorMagics</code> class subclasses this type.</p> </li> <li> <p>PerfmonitorMagics   A thin bridge between IPython and the monitoring stack. Each magic (such as <code>%perfmonitor_start</code> or <code>%perfmonitor_plot</code>) lives here and forwards calls to the adapter layer.</p> </li> <li> <p>PerfmonitorMagicAdapter (string\u2011based API)   An adapter that accepts raw command strings, parses them with argument parsers, and translates them into structured calls on <code>PerfmonitorService</code>. It also serves as the target for the notebook script writer when generating <code>monitored_script.py</code>.</p> </li> <li> <p>PerfmonitorService (Python API)   The central orchestration class with a standalone Python interface. It handles magic\u2011level operations, wires in adapters, and provides methods that can be called directly from Python code.</p> </li> </ul> <p>Together, these components allow the same core logic to be reused from notebooks, scripts, and direct Python APIs.</p>"},{"location":"internals/architecture/#underlying-structure","title":"Underlying structure","text":"<p>The <code>Underlying Structure</code> diagram focuses on the internal levels that support the public API:</p> <ul> <li> <p>API level   Entry points such as IPython, generated scripts (<code>monitored_script.py</code>), and direct Python API usage. All of them ultimately call into <code>PerfmonitorService</code>.</p> </li> <li> <p>Service level   The service coordinates configuration and delegates work to adapters. It is free of IPython\u2011specific concepts and can be used in non\u2011notebook contexts.</p> </li> <li> <p>Top\u2011level adapters   User\u2011facing features that operate on monitoring data:</p> </li> <li><code>reporter</code> \u2014 builds text and HTML performance reports using templates.  </li> <li><code>visualizer</code> \u2014 renders interactive plots and dashboards on top of collected metrics.  </li> <li><code>session</code> \u2014 handles export/import of complete sessions, including performance data and cell history.  </li> <li> <p><code>script_writer</code> \u2014 records cells and monitoring calls into reproducible Python scripts.</p> </li> <li> <p>Low\u2011level adapters   Components that directly interact with the runtime environment and raw data:</p> </li> <li><code>monitor</code> \u2014 collects metrics such as CPU, memory, GPU, and I/O usage. Supports both live and offline modes.  </li> <li><code>data</code> \u2014 stores performance samples and exposes them as pandas <code>DataFrame</code> objects for higher\u2011level components.  </li> <li><code>cell_history</code> \u2014 records executed cells, timestamps, durations, and metadata, allowing reports and plots to be aligned with notebook cells.  </li> <li><code>analyzer</code> \u2014 performs higher\u2011level analysis and classification on top of recorded metrics.</li> </ul> <p>These layers are wired together by the <code>jumper_extension.core</code> package, as summarized in <code>INTERNAL_DOCS.md</code>.</p>"},{"location":"internals/architecture/#package-layout","title":"Package layout","text":"<p>The directory layout of the main package is:</p> <pre><code>jumper_extension/ \u2014 main Python package  \n\u251c\u2500 __init__.py \u2014 package initialization and public exports  \n\u251c\u2500 utilities.py \u2014 shared helper functions used across core and adapters  \n\u251c\u2500 logging_config.py \u2014 logging configuration helpers for the extension  \n\u251c\u2500 logo.py \u2014 ASCII/logo utilities for branding and display  \n\u251c\u2500 core/ \u2014 stable domain model and orchestration (no feature-specific logic)  \n\u2502  \u251c\u2500 __init__.py  \n\u2502  \u251c\u2500 service.py \u2014 PerfmonitorService and PerfmonitorMagicAdapter (central orchestration)  \n\u2502  \u251c\u2500 state.py \u2014 state management, settings dataclasses and snapshots of user configuration  \n\u2502  \u251c\u2500 parsers.py \u2014 argument parsers for magics and CLI-like flows  \n\u2502  \u2514\u2500 messages.py \u2014 centralized user-facing messages and formatting  \n\u251c\u2500 adapters/ \u2014 feature implementations and integrations  \n\u2502  \u251c\u2500 __init__.py  \n\u2502  \u251c\u2500 monitor.py \u2014 live and offline performance monitors (PerformanceMonitor, OfflinePerformanceMonitor)  \n\u2502  \u251c\u2500 cell_history.py \u2014 capture and persistence of executed notebook cells  \n\u2502  \u251c\u2500 data.py \u2014 performance data model and CSV/JSON import/export  \n\u2502  \u251c\u2500 reporter.py \u2014 text/HTML performance reporting built on templates  \n\u2502  \u251c\u2500 analyzer.py \u2014 performance classification logic  \n\u2502  \u251c\u2500 visualizer.py \u2014 plotting and interactive visualization  \n\u2502  \u251c\u2500 session.py \u2014 session export/import (CSV/JSON + manifest, offline monitor wiring)  \n\u2502  \u2514\u2500 script_writer.py \u2014 notebook-to-script recording based on cell history and settings snapshots  \n\u251c\u2500 ipython/ \u2014 thin IPython integration layer  \n\u2502  \u251c\u2500 __init__.py  \n\u2502  \u251c\u2500 extension.py \u2014 load/unload hooks for the IPython extension  \n\u2502  \u251c\u2500 magics.py \u2014 line magics delegating into PerfmonitorMagicAdapter  \n\u2502  \u2514\u2500 utilities.py \u2014 IPython-specific helper utilities  \n\u2514\u2500 templates/ \u2014 frontend components (HTML templates, CSS, assets)  \n   \u251c\u2500 __init__.py  \n   \u2514\u2500 report/ \u2014 performance report templates, styles, and static assets\n</code></pre> <p>For details on individual public methods and usage patterns, see the Public API section.</p>"},{"location":"internals/core/","title":"Core","text":"<p>The core package (<code>jumper_extension.core</code>) defines the domain model, configuration, and parsing logic that underpin the JUmPER IPython extension. For the public Python API of <code>PerfmonitorService</code>, see the Python API section; the content below focuses on supporting modules and helper functions and is generated directly from the code.</p>"},{"location":"internals/core/#state","title":"State","text":"<p>The <code>state</code> module contains dataclasses describing runtime settings for monitoring, automatic reports, and exported or loaded variables.</p> <p>Configuration and state models for the JUmPER core.</p> <p>This module defines dataclasses that hold runtime configuration for monitoring, performance reports, and names of exported or loaded variables.</p>"},{"location":"internals/core/#jumper_extension.core.state.ExportVars","title":"<code>ExportVars</code>  <code>dataclass</code>","text":"<p>Names of variables used when exporting data frames.</p> <p>Attributes:</p> Name Type Description <code>perfdata</code> <code>str</code> <p>Variable name for exported performance data.</p> <code>cell_history</code> <code>str</code> <p>Variable name for exported cell history.</p> Source code in <code>jumper_extension/core/state.py</code> <pre><code>@dataclass\nclass ExportVars:\n    \"\"\"Names of variables used when exporting data frames.\n\n    Attributes:\n        perfdata: Variable name for exported performance data.\n        cell_history: Variable name for exported cell history.\n    \"\"\"\n\n    perfdata: str = \"perfdata_df\"\n    cell_history: str = \"cell_history_df\"\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.state.LoadedVars","title":"<code>LoadedVars</code>  <code>dataclass</code>","text":"<p>Names of variables used when loading data frames.</p> <p>Attributes:</p> Name Type Description <code>perfdata</code> <code>str</code> <p>Variable name for loaded performance data.</p> <code>cell_history</code> <code>str</code> <p>Variable name for loaded cell history.</p> Source code in <code>jumper_extension/core/state.py</code> <pre><code>@dataclass\nclass LoadedVars:\n    \"\"\"Names of variables used when loading data frames.\n\n    Attributes:\n        perfdata: Variable name for loaded performance data.\n        cell_history: Variable name for loaded cell history.\n    \"\"\"\n\n    perfdata: str = \"loaded_perfdata_df\"\n    cell_history: str = \"loaded_cell_history_df\"\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.state.PerfomanceReports","title":"<code>PerfomanceReports</code>  <code>dataclass</code>","text":"<p>Configuration for automatic per-cell performance reports.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether per-cell reports are enabled.</p> <code>level</code> <code>str</code> <p>Monitoring level used when generating reports.</p> <code>text</code> <code>bool</code> <p>If True, use text reports instead of HTML.</p> Source code in <code>jumper_extension/core/state.py</code> <pre><code>@dataclass\nclass PerfomanceReports:\n    \"\"\"Configuration for automatic per-cell performance reports.\n\n    Attributes:\n        enabled: Whether per-cell reports are enabled.\n        level: Monitoring level used when generating reports.\n        text: If True, use text reports instead of HTML.\n    \"\"\"\n\n    enabled: bool = False\n    level: str = \"process\"\n    text: bool = False\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.state.PerformanceMonitoring","title":"<code>PerformanceMonitoring</code>  <code>dataclass</code>","text":"<p>Configuration for the performance monitoring loop.</p> <p>Attributes:</p> Name Type Description <code>default_interval</code> <code>float</code> <p>Default sampling interval in seconds.</p> <code>user_interval</code> <code>Optional[float]</code> <p>User-provided interval overriding the default.</p> <code>running</code> <code>bool</code> <p>Whether monitoring is currently running.</p> Source code in <code>jumper_extension/core/state.py</code> <pre><code>@dataclass\nclass PerformanceMonitoring:\n    \"\"\"Configuration for the performance monitoring loop.\n\n    Attributes:\n        default_interval: Default sampling interval in seconds.\n        user_interval: User-provided interval overriding the default.\n        running: Whether monitoring is currently running.\n    \"\"\"\n\n    default_interval: float = 1.0\n    user_interval: Optional[float] = None\n    running: bool = False\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.state.Settings","title":"<code>Settings</code>  <code>dataclass</code>","text":"<p>Top-level configuration container for the extension.</p> <p>Groups performance reports, monitoring configuration, and variable names used when exporting or loading data.</p> <p>Attributes:</p> Name Type Description <code>perfreports</code> <code>PerfomanceReports</code> <p>Settings for per-cell performance reports.</p> <code>monitoring</code> <code>PerformanceMonitoring</code> <p>Settings for the monitoring loop.</p> <code>export_vars</code> <code>ExportVars</code> <p>Names for exported data variables.</p> <code>loaded_vars</code> <code>LoadedVars</code> <p>Names for loaded data variables.</p> Source code in <code>jumper_extension/core/state.py</code> <pre><code>@dataclass\nclass Settings:\n    \"\"\"Top-level configuration container for the extension.\n\n    Groups performance reports, monitoring configuration, and variable\n    names used when exporting or loading data.\n\n    Attributes:\n        perfreports: Settings for per-cell performance reports.\n        monitoring: Settings for the monitoring loop.\n        export_vars: Names for exported data variables.\n        loaded_vars: Names for loaded data variables.\n    \"\"\"\n\n    perfreports: PerfomanceReports = field(default_factory=PerfomanceReports)\n    monitoring: PerformanceMonitoring = field(default_factory=PerformanceMonitoring)\n    export_vars: ExportVars = field(default_factory=ExportVars)\n    loaded_vars: LoadedVars = field(default_factory=LoadedVars)\n\n    def snapshot(self) -&gt; \"Settings\":\n        \"\"\"Return a deep copy of the current settings.\n\n        Returns:\n            Settings: Independent copy of the current configuration.\n        \"\"\"\n        return copy.deepcopy(self)\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.state.Settings.snapshot","title":"<code>snapshot()</code>","text":"<p>Return a deep copy of the current settings.</p> <p>Returns:</p> Name Type Description <code>Settings</code> <code>Settings</code> <p>Independent copy of the current configuration.</p> Source code in <code>jumper_extension/core/state.py</code> <pre><code>def snapshot(self) -&gt; \"Settings\":\n    \"\"\"Return a deep copy of the current settings.\n\n    Returns:\n        Settings: Independent copy of the current configuration.\n    \"\"\"\n    return copy.deepcopy(self)\n</code></pre>"},{"location":"internals/core/#parsers","title":"Parsers","text":"<p>Module containing parser utilities for the JUmPER extension.</p>"},{"location":"internals/core/#jumper_extension.core.parsers.ArgParsers","title":"<code>ArgParsers</code>  <code>dataclass</code>","text":"<p>Configuration for command-line argument parsers.</p> Source code in <code>jumper_extension/core/parsers.py</code> <pre><code>@dataclass\nclass ArgParsers:\n    \"\"\"Configuration for command-line argument parsers.\"\"\"\n    perfreport: argparse.ArgumentParser\n    auto_perfreports: argparse.ArgumentParser\n    perfmonitor_plot: argparse.ArgumentParser\n    export_perfdata: argparse.ArgumentParser\n    export_cell_history: argparse.ArgumentParser\n    import_perfdata: argparse.ArgumentParser\n    import_cell_history: argparse.ArgumentParser\n    export_session: argparse.ArgumentParser\n    import_session: argparse.ArgumentParser\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.parsers.build_export_session_parser","title":"<code>build_export_session_parser()</code>","text":"<p>Build parser for exporting a full session package.</p> Usage examples in magics <p>%export_session                        # uses default directory name %export_session my_dir                 # export into directory %export_session my_session.zip         # export and zip (auto-detected by .zip extension)</p> Source code in <code>jumper_extension/core/parsers.py</code> <pre><code>def build_export_session_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"Build parser for exporting a full session package.\n\n    Usage examples in magics:\n      %export_session                        # uses default directory name\n      %export_session my_dir                 # export into directory\n      %export_session my_session.zip         # export and zip (auto-detected by .zip extension)\n    \"\"\"\n    parser = argparse.ArgumentParser(add_help=False)\n    parser.add_argument(\n        \"path\",\n        nargs=\"?\",\n        default=None,\n        help=\"Target directory or .zip path (defaults to jumper-session-&lt;timestamp&gt;)\",\n    )\n    return parser\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.parsers.build_import_session_parser","title":"<code>build_import_session_parser()</code>","text":"<p>Build parser for importing a full session package from directory or zip.</p> Source code in <code>jumper_extension/core/parsers.py</code> <pre><code>def build_import_session_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"Build parser for importing a full session package from directory or zip.\"\"\"\n    parser = argparse.ArgumentParser(add_help=False)\n    parser.add_argument(\n        \"path\",\n        type=str,\n        help=\"Path to exported session directory or .zip archive\",\n    )\n    return parser\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.parsers.build_perfreport_parser","title":"<code>build_perfreport_parser()</code>","text":"<p>Build an ArgumentParser instance for JUmPER commands.</p> Source code in <code>jumper_extension/core/parsers.py</code> <pre><code>def build_perfreport_parser() -&gt; argparse.ArgumentParser:\n    \"\"\"Build an ArgumentParser instance for JUmPER commands.\"\"\"\n    parser = argparse.ArgumentParser(add_help=False)\n    parser.add_argument(\n        \"--cell\",\n        type=str,\n        help=\"Cell index or range (e.g., 5, 2:8, :5)\"\n    )\n    parser.add_argument(\n        \"--level\",\n        default=\"process\",\n        choices=get_available_levels(),\n        help=\"Performance level\",\n    )\n    parser.add_argument(\n        \"--text\",\n        action=\"store_true\",\n        help=\"Show report in text format\"\n    )\n    return parser\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.parsers.parse_arguments","title":"<code>parse_arguments(parser, line)</code>","text":"<p>Parse common command line arguments for JUmPER commands.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>The command line string to parse</p> required <code>parser</code> <code>ArgumentParser</code> <p>Optional existing ArgumentParser instance</p> required <p>Returns:</p> Type Description <code>Optional[Namespace]</code> <p>Parsed arguments or None if parsing failed</p> Source code in <code>jumper_extension/core/parsers.py</code> <pre><code>def parse_arguments(parser: argparse.ArgumentParser, line: str) -&gt; Optional[argparse.Namespace]:\n    \"\"\"Parse common command line arguments for JUmPER commands.\n\n    Args:\n        line: The command line string to parse\n        parser: Optional existing ArgumentParser instance\n\n    Returns:\n        Parsed arguments or None if parsing failed\n    \"\"\"\n    try:\n        args = (\n            parser.parse_args(shlex.split(line))\n            if line\n            else parser.parse_args([])\n        )\n    except Exception:\n        args = None\n    return args\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.parsers.parse_cell_range","title":"<code>parse_cell_range(cell_str, cell_history_length)</code>","text":"<p>Parse a cell range string into start and end indices.</p> <p>Parameters:</p> Name Type Description Default <code>cell_str</code> <code>str</code> <p>String representing cell range (e.g., \"1:3\", \"5\", \":10\")</p> required <code>cell_history_length</code> <code>int</code> <p>Length of cell history</p> required <p>Returns:</p> Type Description <code>Optional[Tuple[int, int]]</code> <p>Tuple of (start_idx, end_idx) or None if invalid</p> Source code in <code>jumper_extension/core/parsers.py</code> <pre><code>def parse_cell_range(cell_str: str, cell_history_length: int) -&gt; Optional[Tuple[int, int]]:\n    \"\"\"Parse a cell range string into start and end indices.\n\n    Args:\n        cell_str: String representing cell range (e.g., \"1:3\", \"5\", \":10\")\n        cell_history_length: Length of cell history\n\n    Returns:\n        Tuple of (start_idx, end_idx) or None if invalid\n    \"\"\"\n    if not cell_str:\n        return None\n\n    try:\n        max_idx = cell_history_length - 1\n        if \":\" in cell_str:\n            start_str, end_str = cell_str.split(\":\", 1)\n            start_idx = 0 if not start_str else int(start_str)\n            end_idx = max_idx if not end_str else int(end_str)\n        else:\n            start_idx = end_idx = int(cell_str)\n\n        if 0 &lt;= start_idx &lt;= end_idx &lt;= max_idx:\n            return start_idx, end_idx\n    except (ValueError, IndexError, AttributeError):\n        pass\n\n    return None\n</code></pre>"},{"location":"internals/core/#messages","title":"Messages","text":"<p>The <code>messages</code> module defines error and info codes together with their human-readable message templates.</p> <p>Message codes and templates used by the JUmPER extension.</p> <p>This module defines enums for error and info codes, maps them to human-readable message templates, and exposes helpers for working with those messages.</p>"},{"location":"internals/core/#jumper_extension.core.messages.ExtensionErrorCode","title":"<code>ExtensionErrorCode</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Error codes emitted by the extension.</p> Source code in <code>jumper_extension/core/messages.py</code> <pre><code>class ExtensionErrorCode(Enum):\n    \"\"\"Error codes emitted by the extension.\"\"\"\n\n    PYNVML_NOT_AVAILABLE = auto()\n    NVIDIA_DRIVERS_NOT_AVAILABLE = auto()\n    ADLX_NOT_AVAILABLE = auto()\n    AMD_DRIVERS_NOT_AVAILABLE = auto()\n    NO_PERFORMANCE_DATA = auto()\n    INVALID_CELL_RANGE = auto()\n    INVALID_INTERVAL_VALUE = auto()\n    INVALID_METRIC_SUBSET = auto()\n    NO_ACTIVE_MONITOR = auto()\n    MONITOR_ALREADY_RUNNING = auto()\n    UNSUPPORTED_FORMAT = auto()\n    INVALID_LEVEL = auto()\n    DEFINE_LEVEL = auto()\n    NO_CELL_HISTORY = auto()\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.messages.ExtensionInfoCode","title":"<code>ExtensionInfoCode</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Informational codes emitted by the extension.</p> Source code in <code>jumper_extension/core/messages.py</code> <pre><code>class ExtensionInfoCode(Enum):\n    \"\"\"Informational codes emitted by the extension.\"\"\"\n\n    IMPRECISE_INTERVAL = auto()\n    MISSED_MEASUREMENTS = auto()\n    PERFORMANCE_REPORTS_DISABLED = auto()\n    EXTENSION_LOADED = auto()\n    PERFORMANCE_REPORTS_ENABLED = auto()\n    MONITOR_STARTED = auto()\n    MONITOR_STOPPED = auto()\n    EXPORT_SUCCESS = auto()\n    PERFORMANCE_DATA_AVAILABLE = auto()\n    HTML_REPORTS_NOT_AVAILABLE = auto()\n    PLOTS_NOT_AVAILABLE = auto()\n    SESSION_IMPORTED = auto()\n    IMPORTED_SESSION_PLOT = auto()\n    IMPORTED_SESSION_RESOURCES = auto()\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.messages.get_jumper_process_error_hint","title":"<code>get_jumper_process_error_hint()</code>","text":"<p>Return a hint pointing to the error log file.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Human-readable hint with the path to the error log file.</p> Source code in <code>jumper_extension/core/messages.py</code> <pre><code>def get_jumper_process_error_hint() -&gt; str:\n    \"\"\"Return a hint pointing to the error log file.\n\n    Returns:\n        str: Human-readable hint with the path to the error log file.\n    \"\"\"\n    jumper_process_error_hint = (\n        \"\\nHint: full error info saved to log file: \"\n        f\"{LOGGING['handlers']['error_file']['filename']}\"\n    )\n    return jumper_process_error_hint\n</code></pre>"},{"location":"internals/core/#service-helpers","title":"Service helpers","text":"<p>The service itself is documented in the public API; this section exposes the helper functions that construct it.</p>"},{"location":"internals/core/#jumper_extension.core.service.build_perfmonitor_service","title":"<code>build_perfmonitor_service(plots_disabled=False, plots_disabled_reason='Plotting not available.', display_disabled=False, display_disabled_reason='Display not available.')</code>","text":"<p>Build a new :class:<code>PerfmonitorService</code> instance.</p> <p>This factory configures the default monitor, visualizer, reporter, cell history, and script writer for use in Python code.</p> <p>Parameters:</p> Name Type Description Default <code>plots_disabled</code> <code>bool</code> <p>If <code>True</code>, disable plotting in the visualizer.</p> <code>False</code> <code>plots_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when plots are disabled.</p> <code>'Plotting not available.'</code> <code>display_disabled</code> <code>bool</code> <p>If <code>True</code>, disable rich display for reports.</p> <code>False</code> <code>display_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when rich display is disabled.</p> <code>'Display not available.'</code> <p>Returns:</p> Name Type Description <code>PerfmonitorService</code> <code>PerfmonitorService</code> <p>A fully initialized service instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from jumper_extension.core.service import build_perfmonitor_service\n&gt;&gt;&gt; service = build_perfmonitor_service()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def build_perfmonitor_service(\n        plots_disabled: bool = False,\n        plots_disabled_reason: str = \"Plotting not available.\",\n        display_disabled: bool = False,\n        display_disabled_reason: str = \"Display not available.\"\n) -&gt; PerfmonitorService:\n    \"\"\"Build a new :class:`PerfmonitorService` instance.\n\n    This factory configures the default monitor, visualizer, reporter,\n    cell history, and script writer for use in Python code.\n\n    Args:\n        plots_disabled: If ``True``, disable plotting in the visualizer.\n        plots_disabled_reason: Human-readable reason shown when plots\n            are disabled.\n        display_disabled: If ``True``, disable rich display for reports.\n        display_disabled_reason: Human-readable reason shown when rich\n            display is disabled.\n\n    Returns:\n        PerfmonitorService: A fully initialized service instance.\n\n    Examples:\n        &gt;&gt;&gt; from jumper_extension.core.service import build_perfmonitor_service\n        &gt;&gt;&gt; service = build_perfmonitor_service()\n    \"\"\"\n    settings = Settings()\n    monitor = PerformanceMonitor()\n    cell_history = CellHistory()\n    visualizer = build_performance_visualizer(\n        cell_history,\n        plots_disabled=plots_disabled,\n        plots_disabled_reason=plots_disabled_reason,\n    )\n    reporter = build_performance_reporter(\n        cell_history,\n        display_disabled=display_disabled,\n        display_disabled_reason=display_disabled_reason,\n    )\n    script_writer = NotebookScriptWriter(cell_history)\n\n    return PerfmonitorService(\n        settings=settings,\n        monitor=monitor,\n        visualizer=visualizer,\n        reporter=reporter,\n        cell_history=cell_history,\n        script_writer=script_writer,\n    )\n</code></pre>"},{"location":"internals/core/#jumper_extension.core.service.build_perfmonitor_magic_adapter","title":"<code>build_perfmonitor_magic_adapter(plots_disabled=False, plots_disabled_reason='Plotting not available.', display_disabled=False, display_disabled_reason='Display not available.')</code>","text":"<p>Build a new :class:<code>PerfmonitorMagicAdapter</code> instance.</p> <p>This factory constructs a :class:<code>PerfmonitorService</code> and wraps it with a string-based adapter suitable for IPython magics or other command-style interfaces.</p> <p>Parameters:</p> Name Type Description Default <code>plots_disabled</code> <code>bool</code> <p>If <code>True</code>, disable plotting in the visualizer.</p> <code>False</code> <code>plots_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when plots are disabled.</p> <code>'Plotting not available.'</code> <code>display_disabled</code> <code>bool</code> <p>If <code>True</code>, disable rich display for reports.</p> <code>False</code> <code>display_disabled_reason</code> <code>str</code> <p>Human-readable reason shown when rich display is disabled.</p> <code>'Display not available.'</code> <p>Returns:</p> Name Type Description <code>PerfmonitorMagicAdapter</code> <code>PerfmonitorMagicAdapter</code> <p>Adapter instance wrapping the service.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from jumper_extension.core.service import (\n...     build_perfmonitor_magic_adapter,\n... )\n&gt;&gt;&gt; adapter = build_perfmonitor_magic_adapter()\n</code></pre> Source code in <code>jumper_extension/core/service.py</code> <pre><code>def build_perfmonitor_magic_adapter(\n        plots_disabled: bool = False,\n        plots_disabled_reason: str = \"Plotting not available.\",\n        display_disabled: bool = False,\n        display_disabled_reason: str = \"Display not available.\"\n) -&gt; PerfmonitorMagicAdapter:\n    \"\"\"Build a new :class:`PerfmonitorMagicAdapter` instance.\n\n    This factory constructs a :class:`PerfmonitorService` and wraps it\n    with a string-based adapter suitable for IPython magics or other\n    command-style interfaces.\n\n    Args:\n        plots_disabled: If ``True``, disable plotting in the visualizer.\n        plots_disabled_reason: Human-readable reason shown when plots\n            are disabled.\n        display_disabled: If ``True``, disable rich display for reports.\n        display_disabled_reason: Human-readable reason shown when rich\n            display is disabled.\n\n    Returns:\n        PerfmonitorMagicAdapter: Adapter instance wrapping the service.\n\n    Examples:\n        &gt;&gt;&gt; from jumper_extension.core.service import (\n        ...     build_perfmonitor_magic_adapter,\n        ... )\n        &gt;&gt;&gt; adapter = build_perfmonitor_magic_adapter()\n    \"\"\"\n    service = build_perfmonitor_service(\n        plots_disabled=plots_disabled,\n        plots_disabled_reason=plots_disabled_reason,\n        display_disabled=display_disabled,\n        display_disabled_reason=display_disabled_reason,\n    )\n\n    parsers = ArgParsers(\n        perfreport=build_perfreport_parser(),\n        auto_perfreports=build_auto_perfreports_parser(),\n        perfmonitor_plot=build_perfmonitor_plot_parser(),\n        export_perfdata=build_export_perfdata_parser(),\n        export_cell_history=build_export_cell_history_parser(),\n        import_perfdata=build_import_perfdata_parser(),\n        import_cell_history=build_import_cell_history_parser(),\n        export_session=build_export_session_parser(),\n        import_session=build_import_session_parser(),\n    )\n\n    return PerfmonitorMagicAdapter(\n        service=service,\n        parsers=parsers,\n    )\n</code></pre>"},{"location":"internals/ipython/","title":"IPython Integration","text":"<p>The IPython integration layer under <code>jumper_extension.ipython</code> connects the core service to notebooks and IPython shells. For user\u2011facing usage of magic commands, see the Jupyter API; the sections below provide code\u2011level reference generated via mkdocstrings.</p>"},{"location":"internals/ipython/#extension-entry-points","title":"Extension entry points","text":""},{"location":"internals/ipython/#jumper_extension.ipython.extension.DropCellTransformer","title":"<code>DropCellTransformer</code>","text":"<p>Drop the entire cell if it is being recorded.</p> Source code in <code>jumper_extension/ipython/extension.py</code> <pre><code>class DropCellTransformer:\n    \"\"\"\n    Drop the entire cell if it is being recorded.\n    \"\"\"\n    def __init__(\n        self,\n        is_control_cell: Callable,\n        is_recording_active: Callable\n    ):\n        self.is_control_cell = is_control_cell\n        self.is_recording_active = is_recording_active\n\n    def __call__(self, lines: list[str]) -&gt; list[str]:\n        \"\"\"\n        IPython cleanup_transforms expects a callable: (lines) -&gt; lines.\n        \"\"\"\n        cell = \"\".join(lines)\n        new_cell = self.transform_cell(cell)\n\n        # Keep IPython expectations: return list[str] with line endings preserved.\n        if new_cell == \"\":\n            return []\n        return new_cell.splitlines(keepends=True)\n\n    def transform_cell(self, cell: str) -&gt; str:\n        \"\"\"\n        Return an empty string to drop the whole cell.\n        \"\"\"\n        if not self.is_recording_active():\n            return cell\n\n        called_line_magics = get_called_line_magics(cell)\n        if self.is_control_cell(called_line_magics):\n            return cell  # Allow control magics cell to execute\n\n        return \"print('[JUmPER]: Cell execution skipped during script recording')\\n\"\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.extension.DropCellTransformer.__call__","title":"<code>__call__(lines)</code>","text":"<p>IPython cleanup_transforms expects a callable: (lines) -&gt; lines.</p> Source code in <code>jumper_extension/ipython/extension.py</code> <pre><code>def __call__(self, lines: list[str]) -&gt; list[str]:\n    \"\"\"\n    IPython cleanup_transforms expects a callable: (lines) -&gt; lines.\n    \"\"\"\n    cell = \"\".join(lines)\n    new_cell = self.transform_cell(cell)\n\n    # Keep IPython expectations: return list[str] with line endings preserved.\n    if new_cell == \"\":\n        return []\n    return new_cell.splitlines(keepends=True)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.extension.DropCellTransformer.transform_cell","title":"<code>transform_cell(cell)</code>","text":"<p>Return an empty string to drop the whole cell.</p> Source code in <code>jumper_extension/ipython/extension.py</code> <pre><code>def transform_cell(self, cell: str) -&gt; str:\n    \"\"\"\n    Return an empty string to drop the whole cell.\n    \"\"\"\n    if not self.is_recording_active():\n        return cell\n\n    called_line_magics = get_called_line_magics(cell)\n    if self.is_control_cell(called_line_magics):\n        return cell  # Allow control magics cell to execute\n\n    return \"print('[JUmPER]: Cell execution skipped during script recording')\\n\"\n</code></pre>"},{"location":"internals/ipython/#magic-commands","title":"Magic commands","text":"<p>               Bases: <code>Magics</code></p> <p>IPython line magics for the JUmPER extension.</p> <p>This class defines the <code>%perfmonitor_*</code> family of magics and a few helpers. Each magic forwards its work to a :class:<code>PerfmonitorMagicAdapter</code> instance, which in turn delegates to :class:<code>PerfmonitorService</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shell</code> <code>Any</code> <p>The current IPython shell instance.</p> required <code>magic_adapter</code> <code>PerfmonitorMagicAdapter</code> <p>Adapter that implements the string-based public API used by these magics.</p> required <p>Examples:</p> <p>Load the extension in a notebook::</p> <pre><code>%load_ext jumper_extension\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@magics_class\nclass PerfmonitorMagics(Magics):\n    \"\"\"IPython line magics for the JUmPER extension.\n\n    This class defines the ``%perfmonitor_*`` family of magics and a\n    few helpers. Each magic forwards its work to a\n    :class:`PerfmonitorMagicAdapter` instance, which in turn delegates\n    to :class:`PerfmonitorService`.\n\n    Args:\n        shell: The current IPython shell instance.\n        magic_adapter: Adapter that implements the string-based public\n            API used by these magics.\n\n    Examples:\n        Load the extension in a notebook::\n\n            %load_ext jumper_extension\n    \"\"\"\n\n    def __init__(\n        self,\n        shell: Any,\n        magic_adapter: PerfmonitorMagicAdapter,\n    ) -&gt; None:\n        \"\"\"Initialize the magics wrapper.\n\n        Args:\n            shell: IPython shell the magics are registered on.\n            magic_adapter: Adapter used to execute the underlying\n                commands.\n        \"\"\"\n        super().__init__(shell)\n        self.magic_adapter = magic_adapter\n\n    def pre_run_cell(self, info: Any) -&gt; None:\n        \"\"\"Hook executed before each cell.\n\n        This inspects the raw cell source, extracts any magic commands,\n        and informs the underlying adapter so that monitoring and\n        reporting state can be updated.\n\n        Args:\n            info: IPython pre-run information object that contains\n                ``raw_cell``.\n        Returns:\n            None\n        \"\"\"\n        raw_cell = info.raw_cell\n        called_line_magics = get_called_line_magics(raw_cell)\n        should_skip_report = is_pure_line_magic_cell(raw_cell)\n        self.magic_adapter.on_pre_run_cell(\n            raw_cell,\n            called_line_magics,\n            should_skip_report,\n        )\n\n    def post_run_cell(self, result: Any) -&gt; None:\n        \"\"\"Hook executed after each cell has run.\n\n        Delegates to the magic adapter so that post-cell reporting and\n        bookkeeping can be performed.\n\n        Args:\n            result: IPython execution result object.\n        Returns:\n            None\n        \"\"\"\n        self.magic_adapter.on_post_run_cell(result.result)\n\n    @line_magic\n    def perfmonitor_resources(self, line: str) -&gt; None:\n        \"\"\"Show hardware resources available to the current session.\n\n        This magic prints CPUs, memory, and GPU information for either\n        a live or imported monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Show resources for the current session::\n\n                %perfmonitor_resources\n        \"\"\"\n        self.magic_adapter.perfmonitor_resources(line)\n\n    @line_magic\n    def perfmonitor_start(self, line: str) -&gt; None:\n        \"\"\"Start performance monitoring.\n\n        If an interval is provided as a single numeric argument, it is\n        interpreted as the sampling interval in seconds; otherwise the\n        default interval is used.\n\n        Args:\n            line: Optional interval argument, for example ``\"1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Start monitoring with the default interval::\n\n                %perfmonitor_start\n\n            Start monitoring with a 0.5 second interval::\n\n                %perfmonitor_start 0.5\n        \"\"\"\n        self.magic_adapter.perfmonitor_start(line)\n\n    @line_magic\n    def perfmonitor_stop(self, line: str) -&gt; None:\n        \"\"\"Stop the active performance monitoring session.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_stop\n        \"\"\"\n        self.magic_adapter.perfmonitor_stop(line)\n\n    @line_magic\n    def perfmonitor_plot(self, line: str) -&gt; None:\n        \"\"\"Open an interactive performance plot.\n\n        This magic opens interactive widgets for exploring collected\n        performance data.\n\n        Args:\n            line: Raw argument string forwarded to the adapter.\n        Returns:\n            None\n\n        Examples:\n            Open an interactive plot for the current session::\n\n                %perfmonitor_plot\n        \"\"\"\n        self.magic_adapter.perfmonitor_plot(line)\n\n    @line_magic\n    def perfmonitor_enable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Enable automatic performance reports after each cell.\n\n        The line string is parsed for options such as monitoring level,\n        interval, and whether to use text or HTML output.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--level process --interval 1.0\"``.\n        Returns:\n            None\n\n        Examples:\n            Enable HTML reports at process level::\n\n                %perfmonitor_enable_perfreports --level process\n\n            Enable text reports for user level with custom interval::\n\n                %perfmonitor_enable_perfreports --level user --interval 0.5 --text\n        \"\"\"\n        self.magic_adapter.perfmonitor_enable_perfreports(line)\n\n\n    @line_magic\n    def perfmonitor_disable_perfreports(self, line: str) -&gt; None:\n        \"\"\"Disable automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_disable_perfreports\n        \"\"\"\n        self.magic_adapter.perfmonitor_disable_perfreports(line)\n\n    @line_magic\n    def perfmonitor_perfreport(self, line: str) -&gt; None:\n        \"\"\"Show a performance report for the current session.\n\n        The line string may include cell range and monitoring level\n        options to restrict the report.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--cell 2:5 --level system\"``.\n        Returns:\n            None\n\n        Examples:\n            Show a report for all cells::\n\n                %perfmonitor_perfreport\n\n            Show a report for cells 2\u20135 at system level::\n\n                %perfmonitor_perfreport --cell 2:5 --level system\n        \"\"\"\n        self.magic_adapter.perfmonitor_perfreport(line)\n\n    @line_magic\n    def perfmonitor_export_perfdata(self, line: str) -&gt; None:\n        \"\"\"Export performance data or push it into the notebook.\n\n        If ``--file`` is provided, data is written to disk. Otherwise,\n        the resulting data frames are pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, such as\n                ``\"--file perf.csv --level process\"``.\n        Returns:\n            None\n\n        Examples:\n            Export process-level data to CSV::\n\n                %perfmonitor_export_perfdata --file perf.csv --level process\n\n            Push a DataFrame into the notebook::\n\n                %perfmonitor_export_perfdata --level user\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_export_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_export_cell_history(self, line: str) -&gt; None:\n        \"\"\"Export cell history or push it into the notebook.\n\n        If ``--file`` is provided, the cell history is written to disk.\n        Otherwise, a data frame is pushed into the user namespace.\n\n        Args:\n            line: Raw argument string, for example\n                ``\"--file cells.csv\"``.\n        Returns:\n            None\n\n        Examples:\n            Export cell history to CSV::\n\n                %perfmonitor_export_cell_history --file cells.csv\n\n            Push the cell history DataFrame::\n\n                %perfmonitor_export_cell_history\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_export_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def perfmonitor_load_perfdata(self, line: str) -&gt; None:\n        \"\"\"Load performance data from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_perfdata --file perf.csv\n        \"\"\"\n        perfdata = self.magic_adapter.perfmonitor_load_perfdata(line)\n        self.shell.push(perfdata)\n\n    @line_magic\n    def perfmonitor_load_cell_history(self, line: str) -&gt; None:\n        \"\"\"Load cell history from disk and push it to the notebook.\n\n        Args:\n            line: Raw argument string containing ``--file``.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_load_cell_history --file cells.csv\n        \"\"\"\n        cell_history_data = self.magic_adapter.perfmonitor_load_cell_history(line)\n        self.shell.push(cell_history_data)\n\n    @line_magic\n    def export_session(self, line: str) -&gt; None:\n        \"\"\"Export the full monitoring session to a directory or zip.\n\n        When the target ends with ``.zip``, a temporary directory is\n        created and compressed into that archive.\n\n        Args:\n            line: Raw argument string containing an optional target\n                path.\n        Returns:\n            None\n\n        Examples:\n            Export into a directory::\n\n                %export_session my_dir\n\n            Export into a zip archive::\n\n                %export_session my_session.zip\n        \"\"\"\n        self.magic_adapter.export_session(line)\n\n    @line_magic\n    def import_session(self, line: str) -&gt; None:\n        \"\"\"Import a monitoring session from a directory or zip.\n\n        Args:\n            line: Raw argument string with the source path.\n        Returns:\n            None\n\n        Examples:\n            %import_session my_session.zip\n        \"\"\"\n        self.magic_adapter.import_session(line)\n\n    @line_magic\n    def perfmonitor_fast_setup(self, line: str) -&gt; None:\n        \"\"\"Run a quick setup for interactive monitoring.\n\n        This helper enables ``ipympl`` interactive plots (if available),\n        starts monitoring, and turns on automatic performance reports.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            Quickly prepare interactive monitoring in a notebook::\n\n                %perfmonitor_fast_setup\n        \"\"\"\n        # Enable ipympl interactive plots\n        try:\n            self.shell.run_line_magic('matplotlib', 'ipympl')\n            print(\"[JUmPER]: Enabled ipympl interactive plots\")\n        except Exception as e:\n            logger.warning(f\"Failed to enable ipympl interactive plots: {e}\")\n        self.magic_adapter.perfmonitor_fast_setup(line)\n\n    @line_magic\n    def show_cell_history(self, line: str) -&gt; None:\n        \"\"\"Show an interactive table of executed cells.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %show_cell_history\n        \"\"\"\n        self.magic_adapter.show_cell_history(line)\n\n    @line_magic\n    def perfmonitor_help(self, line: str) -&gt; None:\n        \"\"\"Show comprehensive help for all available magics.\n\n        Args:\n            line: Unused argument string.\n        Returns:\n            None\n\n        Examples:\n            %perfmonitor_help\n        \"\"\"\n        self.magic_adapter.perfmonitor_help(line)\n\n    @line_magic\n    def start_write_script(self, line: str) -&gt; None:\n        \"\"\"Start recording code from subsequent cells to a Python script.\n\n        If no path is provided, the script writer chooses a default\n        filename based on the current time.\n\n        Args:\n            line: Optional output path, for example\n                ``\\\"my_script.py\\\"``.\n\n        Examples:\n            Start recording to a generated filename::\n\n                %start_write_script\n\n            Record to a specific file::\n\n                %start_write_script my_script.py\n        \"\"\"\n        self.magic_adapter.start_write_script(line)\n\n    @line_magic\n    def end_write_script(self, line: str) -&gt; None:\n        \"\"\"Stop recording and save accumulated code to a script file.\n\n        Args:\n            line: Unused argument string.\n\n        Examples:\n            %end_write_script\n        \"\"\"\n        self.magic_adapter.end_write_script(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.__init__","title":"<code>__init__(shell, magic_adapter)</code>","text":"<p>Initialize the magics wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>shell</code> <code>Any</code> <p>IPython shell the magics are registered on.</p> required <code>magic_adapter</code> <code>PerfmonitorMagicAdapter</code> <p>Adapter used to execute the underlying commands.</p> required Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>def __init__(\n    self,\n    shell: Any,\n    magic_adapter: PerfmonitorMagicAdapter,\n) -&gt; None:\n    \"\"\"Initialize the magics wrapper.\n\n    Args:\n        shell: IPython shell the magics are registered on.\n        magic_adapter: Adapter used to execute the underlying\n            commands.\n    \"\"\"\n    super().__init__(shell)\n    self.magic_adapter = magic_adapter\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.end_write_script","title":"<code>end_write_script(line)</code>","text":"<p>Stop recording and save accumulated code to a script file.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Examples:</p> <p>%end_write_script</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef end_write_script(self, line: str) -&gt; None:\n    \"\"\"Stop recording and save accumulated code to a script file.\n\n    Args:\n        line: Unused argument string.\n\n    Examples:\n        %end_write_script\n    \"\"\"\n    self.magic_adapter.end_write_script(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.export_session","title":"<code>export_session(line)</code>","text":"<p>Export the full monitoring session to a directory or zip.</p> <p>When the target ends with <code>.zip</code>, a temporary directory is created and compressed into that archive.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string containing an optional target path.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Export into a directory::</p> <pre><code>%export_session my_dir\n</code></pre> <p>Export into a zip archive::</p> <pre><code>%export_session my_session.zip\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef export_session(self, line: str) -&gt; None:\n    \"\"\"Export the full monitoring session to a directory or zip.\n\n    When the target ends with ``.zip``, a temporary directory is\n    created and compressed into that archive.\n\n    Args:\n        line: Raw argument string containing an optional target\n            path.\n    Returns:\n        None\n\n    Examples:\n        Export into a directory::\n\n            %export_session my_dir\n\n        Export into a zip archive::\n\n            %export_session my_session.zip\n    \"\"\"\n    self.magic_adapter.export_session(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.import_session","title":"<code>import_session(line)</code>","text":"<p>Import a monitoring session from a directory or zip.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string with the source path.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%import_session my_session.zip</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef import_session(self, line: str) -&gt; None:\n    \"\"\"Import a monitoring session from a directory or zip.\n\n    Args:\n        line: Raw argument string with the source path.\n    Returns:\n        None\n\n    Examples:\n        %import_session my_session.zip\n    \"\"\"\n    self.magic_adapter.import_session(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_disable_perfreports","title":"<code>perfmonitor_disable_perfreports(line)</code>","text":"<p>Disable automatic performance reports.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_disable_perfreports</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_disable_perfreports(self, line: str) -&gt; None:\n    \"\"\"Disable automatic performance reports.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_disable_perfreports\n    \"\"\"\n    self.magic_adapter.perfmonitor_disable_perfreports(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_enable_perfreports","title":"<code>perfmonitor_enable_perfreports(line)</code>","text":"<p>Enable automatic performance reports after each cell.</p> <p>The line string is parsed for options such as monitoring level, interval, and whether to use text or HTML output.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, for example <code>\"--level process --interval 1.0\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Enable HTML reports at process level::</p> <pre><code>%perfmonitor_enable_perfreports --level process\n</code></pre> <p>Enable text reports for user level with custom interval::</p> <pre><code>%perfmonitor_enable_perfreports --level user --interval 0.5 --text\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_enable_perfreports(self, line: str) -&gt; None:\n    \"\"\"Enable automatic performance reports after each cell.\n\n    The line string is parsed for options such as monitoring level,\n    interval, and whether to use text or HTML output.\n\n    Args:\n        line: Raw argument string, for example\n            ``\"--level process --interval 1.0\"``.\n    Returns:\n        None\n\n    Examples:\n        Enable HTML reports at process level::\n\n            %perfmonitor_enable_perfreports --level process\n\n        Enable text reports for user level with custom interval::\n\n            %perfmonitor_enable_perfreports --level user --interval 0.5 --text\n    \"\"\"\n    self.magic_adapter.perfmonitor_enable_perfreports(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_export_cell_history","title":"<code>perfmonitor_export_cell_history(line)</code>","text":"<p>Export cell history or push it into the notebook.</p> <p>If <code>--file</code> is provided, the cell history is written to disk. Otherwise, a data frame is pushed into the user namespace.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, for example <code>\"--file cells.csv\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Export cell history to CSV::</p> <pre><code>%perfmonitor_export_cell_history --file cells.csv\n</code></pre> <p>Push the cell history DataFrame::</p> <pre><code>%perfmonitor_export_cell_history\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_export_cell_history(self, line: str) -&gt; None:\n    \"\"\"Export cell history or push it into the notebook.\n\n    If ``--file`` is provided, the cell history is written to disk.\n    Otherwise, a data frame is pushed into the user namespace.\n\n    Args:\n        line: Raw argument string, for example\n            ``\"--file cells.csv\"``.\n    Returns:\n        None\n\n    Examples:\n        Export cell history to CSV::\n\n            %perfmonitor_export_cell_history --file cells.csv\n\n        Push the cell history DataFrame::\n\n            %perfmonitor_export_cell_history\n    \"\"\"\n    cell_history_data = self.magic_adapter.perfmonitor_export_cell_history(line)\n    self.shell.push(cell_history_data)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_export_perfdata","title":"<code>perfmonitor_export_perfdata(line)</code>","text":"<p>Export performance data or push it into the notebook.</p> <p>If <code>--file</code> is provided, data is written to disk. Otherwise, the resulting data frames are pushed into the user namespace.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, such as <code>\"--file perf.csv --level process\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Export process-level data to CSV::</p> <pre><code>%perfmonitor_export_perfdata --file perf.csv --level process\n</code></pre> <p>Push a DataFrame into the notebook::</p> <pre><code>%perfmonitor_export_perfdata --level user\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_export_perfdata(self, line: str) -&gt; None:\n    \"\"\"Export performance data or push it into the notebook.\n\n    If ``--file`` is provided, data is written to disk. Otherwise,\n    the resulting data frames are pushed into the user namespace.\n\n    Args:\n        line: Raw argument string, such as\n            ``\"--file perf.csv --level process\"``.\n    Returns:\n        None\n\n    Examples:\n        Export process-level data to CSV::\n\n            %perfmonitor_export_perfdata --file perf.csv --level process\n\n        Push a DataFrame into the notebook::\n\n            %perfmonitor_export_perfdata --level user\n    \"\"\"\n    perfdata = self.magic_adapter.perfmonitor_export_perfdata(line)\n    self.shell.push(perfdata)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_fast_setup","title":"<code>perfmonitor_fast_setup(line)</code>","text":"<p>Run a quick setup for interactive monitoring.</p> <p>This helper enables <code>ipympl</code> interactive plots (if available), starts monitoring, and turns on automatic performance reports.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Quickly prepare interactive monitoring in a notebook::</p> <pre><code>%perfmonitor_fast_setup\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_fast_setup(self, line: str) -&gt; None:\n    \"\"\"Run a quick setup for interactive monitoring.\n\n    This helper enables ``ipympl`` interactive plots (if available),\n    starts monitoring, and turns on automatic performance reports.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        Quickly prepare interactive monitoring in a notebook::\n\n            %perfmonitor_fast_setup\n    \"\"\"\n    # Enable ipympl interactive plots\n    try:\n        self.shell.run_line_magic('matplotlib', 'ipympl')\n        print(\"[JUmPER]: Enabled ipympl interactive plots\")\n    except Exception as e:\n        logger.warning(f\"Failed to enable ipympl interactive plots: {e}\")\n    self.magic_adapter.perfmonitor_fast_setup(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_help","title":"<code>perfmonitor_help(line)</code>","text":"<p>Show comprehensive help for all available magics.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_help</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_help(self, line: str) -&gt; None:\n    \"\"\"Show comprehensive help for all available magics.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_help\n    \"\"\"\n    self.magic_adapter.perfmonitor_help(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_load_cell_history","title":"<code>perfmonitor_load_cell_history(line)</code>","text":"<p>Load cell history from disk and push it to the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string containing <code>--file</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_load_cell_history --file cells.csv</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_load_cell_history(self, line: str) -&gt; None:\n    \"\"\"Load cell history from disk and push it to the notebook.\n\n    Args:\n        line: Raw argument string containing ``--file``.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_load_cell_history --file cells.csv\n    \"\"\"\n    cell_history_data = self.magic_adapter.perfmonitor_load_cell_history(line)\n    self.shell.push(cell_history_data)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_load_perfdata","title":"<code>perfmonitor_load_perfdata(line)</code>","text":"<p>Load performance data from disk and push it to the notebook.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string containing <code>--file</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_load_perfdata --file perf.csv</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_load_perfdata(self, line: str) -&gt; None:\n    \"\"\"Load performance data from disk and push it to the notebook.\n\n    Args:\n        line: Raw argument string containing ``--file``.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_load_perfdata --file perf.csv\n    \"\"\"\n    perfdata = self.magic_adapter.perfmonitor_load_perfdata(line)\n    self.shell.push(perfdata)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_perfreport","title":"<code>perfmonitor_perfreport(line)</code>","text":"<p>Show a performance report for the current session.</p> <p>The line string may include cell range and monitoring level options to restrict the report.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string, for example <code>\"--cell 2:5 --level system\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Show a report for all cells::</p> <pre><code>%perfmonitor_perfreport\n</code></pre> <p>Show a report for cells 2\u20135 at system level::</p> <pre><code>%perfmonitor_perfreport --cell 2:5 --level system\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_perfreport(self, line: str) -&gt; None:\n    \"\"\"Show a performance report for the current session.\n\n    The line string may include cell range and monitoring level\n    options to restrict the report.\n\n    Args:\n        line: Raw argument string, for example\n            ``\"--cell 2:5 --level system\"``.\n    Returns:\n        None\n\n    Examples:\n        Show a report for all cells::\n\n            %perfmonitor_perfreport\n\n        Show a report for cells 2\u20135 at system level::\n\n            %perfmonitor_perfreport --cell 2:5 --level system\n    \"\"\"\n    self.magic_adapter.perfmonitor_perfreport(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_plot","title":"<code>perfmonitor_plot(line)</code>","text":"<p>Open an interactive performance plot.</p> <p>This magic opens interactive widgets for exploring collected performance data.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Raw argument string forwarded to the adapter.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Open an interactive plot for the current session::</p> <pre><code>%perfmonitor_plot\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_plot(self, line: str) -&gt; None:\n    \"\"\"Open an interactive performance plot.\n\n    This magic opens interactive widgets for exploring collected\n    performance data.\n\n    Args:\n        line: Raw argument string forwarded to the adapter.\n    Returns:\n        None\n\n    Examples:\n        Open an interactive plot for the current session::\n\n            %perfmonitor_plot\n    \"\"\"\n    self.magic_adapter.perfmonitor_plot(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_resources","title":"<code>perfmonitor_resources(line)</code>","text":"<p>Show hardware resources available to the current session.</p> <p>This magic prints CPUs, memory, and GPU information for either a live or imported monitoring session.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Show resources for the current session::</p> <pre><code>%perfmonitor_resources\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_resources(self, line: str) -&gt; None:\n    \"\"\"Show hardware resources available to the current session.\n\n    This magic prints CPUs, memory, and GPU information for either\n    a live or imported monitoring session.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        Show resources for the current session::\n\n            %perfmonitor_resources\n    \"\"\"\n    self.magic_adapter.perfmonitor_resources(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_start","title":"<code>perfmonitor_start(line)</code>","text":"<p>Start performance monitoring.</p> <p>If an interval is provided as a single numeric argument, it is interpreted as the sampling interval in seconds; otherwise the default interval is used.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Optional interval argument, for example <code>\"1.0\"</code>.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>Start monitoring with the default interval::</p> <pre><code>%perfmonitor_start\n</code></pre> <p>Start monitoring with a 0.5 second interval::</p> <pre><code>%perfmonitor_start 0.5\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_start(self, line: str) -&gt; None:\n    \"\"\"Start performance monitoring.\n\n    If an interval is provided as a single numeric argument, it is\n    interpreted as the sampling interval in seconds; otherwise the\n    default interval is used.\n\n    Args:\n        line: Optional interval argument, for example ``\"1.0\"``.\n    Returns:\n        None\n\n    Examples:\n        Start monitoring with the default interval::\n\n            %perfmonitor_start\n\n        Start monitoring with a 0.5 second interval::\n\n            %perfmonitor_start 0.5\n    \"\"\"\n    self.magic_adapter.perfmonitor_start(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.perfmonitor_stop","title":"<code>perfmonitor_stop(line)</code>","text":"<p>Stop the active performance monitoring session.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%perfmonitor_stop</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef perfmonitor_stop(self, line: str) -&gt; None:\n    \"\"\"Stop the active performance monitoring session.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        %perfmonitor_stop\n    \"\"\"\n    self.magic_adapter.perfmonitor_stop(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.post_run_cell","title":"<code>post_run_cell(result)</code>","text":"<p>Hook executed after each cell has run.</p> <p>Delegates to the magic adapter so that post-cell reporting and bookkeeping can be performed.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>Any</code> <p>IPython execution result object.</p> required <p>Returns:     None</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>def post_run_cell(self, result: Any) -&gt; None:\n    \"\"\"Hook executed after each cell has run.\n\n    Delegates to the magic adapter so that post-cell reporting and\n    bookkeeping can be performed.\n\n    Args:\n        result: IPython execution result object.\n    Returns:\n        None\n    \"\"\"\n    self.magic_adapter.on_post_run_cell(result.result)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.pre_run_cell","title":"<code>pre_run_cell(info)</code>","text":"<p>Hook executed before each cell.</p> <p>This inspects the raw cell source, extracts any magic commands, and informs the underlying adapter so that monitoring and reporting state can be updated.</p> <p>Parameters:</p> Name Type Description Default <code>info</code> <code>Any</code> <p>IPython pre-run information object that contains <code>raw_cell</code>.</p> required <p>Returns:     None</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>def pre_run_cell(self, info: Any) -&gt; None:\n    \"\"\"Hook executed before each cell.\n\n    This inspects the raw cell source, extracts any magic commands,\n    and informs the underlying adapter so that monitoring and\n    reporting state can be updated.\n\n    Args:\n        info: IPython pre-run information object that contains\n            ``raw_cell``.\n    Returns:\n        None\n    \"\"\"\n    raw_cell = info.raw_cell\n    called_line_magics = get_called_line_magics(raw_cell)\n    should_skip_report = is_pure_line_magic_cell(raw_cell)\n    self.magic_adapter.on_pre_run_cell(\n        raw_cell,\n        called_line_magics,\n        should_skip_report,\n    )\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.show_cell_history","title":"<code>show_cell_history(line)</code>","text":"<p>Show an interactive table of executed cells.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Unused argument string.</p> required <p>Returns:     None</p> <p>Examples:</p> <p>%show_cell_history</p> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef show_cell_history(self, line: str) -&gt; None:\n    \"\"\"Show an interactive table of executed cells.\n\n    Args:\n        line: Unused argument string.\n    Returns:\n        None\n\n    Examples:\n        %show_cell_history\n    \"\"\"\n    self.magic_adapter.show_cell_history(line)\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.magics.PerfmonitorMagics.start_write_script","title":"<code>start_write_script(line)</code>","text":"<p>Start recording code from subsequent cells to a Python script.</p> <p>If no path is provided, the script writer chooses a default filename based on the current time.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Optional output path, for example <code>\"my_script.py\"</code>.</p> required <p>Examples:</p> <p>Start recording to a generated filename::</p> <pre><code>%start_write_script\n</code></pre> <p>Record to a specific file::</p> <pre><code>%start_write_script my_script.py\n</code></pre> Source code in <code>jumper_extension/ipython/magics.py</code> <pre><code>@line_magic\ndef start_write_script(self, line: str) -&gt; None:\n    \"\"\"Start recording code from subsequent cells to a Python script.\n\n    If no path is provided, the script writer chooses a default\n    filename based on the current time.\n\n    Args:\n        line: Optional output path, for example\n            ``\\\"my_script.py\\\"``.\n\n    Examples:\n        Start recording to a generated filename::\n\n            %start_write_script\n\n        Record to a specific file::\n\n            %start_write_script my_script.py\n    \"\"\"\n    self.magic_adapter.start_write_script(line)\n</code></pre>"},{"location":"internals/ipython/#ipython-utilities","title":"IPython utilities","text":""},{"location":"internals/ipython/#jumper_extension.ipython.utilities.get_called_line_magics","title":"<code>get_called_line_magics(raw_cell)</code>","text":"<p>Get the list of line magics called in a cell</p> Source code in <code>jumper_extension/ipython/utilities.py</code> <pre><code>def get_called_line_magics(raw_cell: str) -&gt; list:\n    \"\"\"\n    Get the list of line magics called in a cell\n    \"\"\"\n    line_magics = get_line_magics_cached()\n    called_line_magics = []\n    # Get the list of available line magics, names without '%'\n    lines = raw_cell.splitlines()\n    for line in lines:\n        stripped = line.strip()\n        if not stripped:\n            # skip empty lines\n            continue\n        if stripped.startswith(\"#\"):\n            # skip comments\n            continue\n        if is_known_line_magic(line, line_magics):\n            called_line_magics.append(stripped[1:])\n    return called_line_magics\n</code></pre>"},{"location":"internals/ipython/#jumper_extension.ipython.utilities.is_pure_line_magic_cell","title":"<code>is_pure_line_magic_cell(raw_cell)</code>","text":"<p>A pure line-magic cell = each non-empty line is either:   - starts with % (optionally with arguments),   - or is a comment (#...). Source code in <code>jumper_extension/ipython/utilities.py</code> <pre><code>def is_pure_line_magic_cell(raw_cell: str) -&gt; bool:\n    \"\"\"\n    A pure line-magic cell = each non-empty line is either:\n      - starts with %&lt;known_magic&gt; (optionally with arguments),\n      - or is a comment (#...).\n    \"\"\"\n    line_magics = get_line_magics_cached()\n    # Get the list of available line magics, names without '%'\n    lines = raw_cell.splitlines()\n    for line in lines:\n        stripped = line.strip()\n        if not stripped:\n            # skip empty lines\n            continue\n        if stripped.startswith(\"#\"):\n            # skip comments\n            continue\n        if is_known_line_magic(line, line_magics):\n            # skip line magic\n            continue\n        # any other non-empty line is considered code -&gt; not \"pure\"\n        return False\n    return True\n</code></pre>"}]}